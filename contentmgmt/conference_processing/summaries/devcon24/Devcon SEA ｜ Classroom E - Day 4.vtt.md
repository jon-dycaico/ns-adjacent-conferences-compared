[Music]
[Applause]
a
oh
y
e
is
sh
n
bule bule
o
w
oh e
m
the
d
h
oh oh
yeah pH away
laptops we're ready
all right everyone thank you so much for
coming thank you for being here and
welcome to this session on popup cities
so my name is tour we have an amazing
set of uh folks here up on stage and we
want to make this a very interactive
session so um we'll be passing around
the mic for some uh feedback from the
folks here if you're tuning in on the
live stream welcome as well it's so
wonderful to have you so just a quick um
overview of the agenda for today I'm
going to start with a little bit of
context on the history of social
Gatherings which will ground Us in the
the the context and the lineage of
what's Happening here we'll talk a
little bit about zalu we'll share some
fun stories and then we'll get into the
relevance of this movement for crypto
and crypto adoption then we'll talk
about the design space for popups and
then some of the challenges and
opportunities but I'd love to start just
so you know who's up here just a quick
set of intros I'll kick off myself my
name is teore I'm one of the co-founders
of edge city um my background is in uh
building startups which I did for about
partner at a VC fund for 2 years I was
lucky enough to go to zalu and had a
very kind of personally meaningful
experience which pilled me on this
concept and pretty much from that point
decided to do this full-time so that's
me
Nicole hey um I'm Nicole I'm currently
working on zoo Thailand but before this
I helped start Zulu um and yeah that's
how I met everyone
here hi I'm Janine ler um I'm one of the
co-founders of AG City and I helped with
getting zuu off the ground so got really
excited about this movement last year um
have been sessed with communities and
what can happen with social dynamics um
and how we can actually like progress
the future in some way because of
it hey uh yeah great to see everyone uh
my name is DC Posh and I'm a co-founder
of Dao uh daop pay and uh it actually
Dao started at a POA Village started
like came out of uh zalu which was an
amazing experience uh and and I I helped
build the the vzero first prototype of
of zup pass um about that in a bit and
yeah great glad to be here yeah awesome
so we have quite a range of perspectives
here uh from some of the folks who
really started this movement to uh DC
who's been one of the the quickest uh
Tech development stories to come out of
the space the space is only a year and a
half old which is an interesting bit of
uh context to have so yeah that's that's
um
that's that's that there so okay I think
a really good place to start here will
be to talk about the lineage and the
history of this movement and the point
that I really want to come across here
is that humans and human societies have
had a long history of coming together to
talk about new ideas about how Society
should be structured humans have a lot
of uh creativity and Collective agency
in this process of shaping Society and
it often looks like taking some space
away from mainstream Society to gather
in a space that will allow for
discussions about new ideas that can
then spread and permeate through the
rest of
society these movements have through
history been critical and very important
in incubating new ideas and new
technology and I think this gives us a
bit of an idea about what is actually
happening with pop-up cities my personal
assertion is that popup cities are a new
surface area for this type of
experimentation especially for a lot of
the ideas that we're developing in the
crypto space to find actual meaningful
ground for tangible in real life
experimentation a lot of the things
we're doing are quite he they're quite
um abstract and so what we've seen
already in the last couple of years is
that it's a very it's it's kind of
fertile ground for um for tangible
application for how to live how to build
new tech and how to ultimately improve
Society so I I I went deep down this
Rabbit Hole I originally had maybe 20
different examples I picked five just to
give us a little bit of a sense um for
what's happening here so the first one
is The Enlightenment salons in 17th and
Paris they were social Gatherings they
were often hosted by mostly hosted by
women and they were kind of a safe space
for new ideas about philosophy politics
and science this was you know France at
the time was a monarchy but it was the
the general prevailing sense of the
Enlightenment was is there actually a
new way to structure Society right now
that feels a little trivial maybe kind
of obvious to us but at the time it was
really uh very I mean literally
revolutionary to even be talking about
ideas of moving beyond a
monarchy and the I mean the impact of
these environments was was huge right
they spread ideas uh from the
enlightenment kind of the
classical uh ideas we think of about
liberalism like individual liberty uh
Freedom individual rights human rights
and this is kind of the the birthplace
of modern democracy um and obviously if
you study the history of the French
Revolution you see that this was
critical in making France a uh
constitutional monarchy for a brief
moment and then obviously um a full
repblic repu so that's kind of one one
example that we can hearken back to
another one that's slightly less welln
but I think is potentially even closer
to what's Happening Here is What's
called the chiaka movement so this
started in late 19th century us in a
place called Chaka in Upstate New York
but it very quickly spread throughout
the country so I think it's actually a
really cool model for What's Happening
Here essentially it was um a adult and
kind of family education movement so
every summer in this town they would
bring uh University professors they
would bring folks and families to come
together and and teach each other it was
kind of like a long unconference that
happened over the course of once two
months um and this and and it had folks
like Henry Ford who's pictured here and
a bunch of the other kind of big
innovators of the time who would come
and spend their Summers there and this
eventually spread around the country so
pretty much every city in the US had a
chataka in the summer some of them
happened throughout the year and it
actually kind of approximates very
closely what's happening with things
like Zulu things like Edge City Zoo
Thailand where we have these 1 to two
month temporary Gatherings that are then
now starting to pick up steam again um
so yeah it's just a really cool example
of a small idea that became a national
movement the next one is Black Mountain
College which was a a experimental
College it was a reaction to kind of the
industrial education movement um in the
early 20th century
it had a lot of interesting folks like
John Cage Buckminster Fuller actually
invented the geodesic dome while he was
at Black Mountain College um it was the
center of American avanguard art and
poetry so it influenced a lot of
American culture um but again it was
this it was uh it was a permanent place
but for most people their experience of
it was that they would go there for one
to two months they would go deep on some
ideas they would collaborate with other
folks who were there
and out of that came a lot of
interesting philosophy art um technology
like uh like buckminster's work that's
actually him pictured here um it's a
little bit pixelated on the screen but
uh yeah just really interesting history
it's even less than just 100 years
ago oraville so orille is an interesting
example in India it's actually a
permanent new town that's still going um
and it was created as an attempt to uh
to figure out a place focused on human
unity and sustainable living and uh
especially human flourishing there are
people that live there full-time but
again for a lot of people their
experience is ephemeral so they come for
a month or two they stay there they
learn they develop ideas um at the time
this kind of came out of the' 60s you
know uh cultural Revolution happening in
the US so uh the hippie movement a lot
of talk about peace and Harmony
obviously the Vietnam War was happening
at the time um it's it's it's big
there's you know 3,000 people but uh
they' I think they've had over 100,000
terms of like folks that have been there
um and it's a really interesting
experiment that shows that these things
can have a lot of longevity over time
and one oh yeah so the last one here is
the Santa Fe Institute which is a little
bit of a more contemporary example but I
think gives a really good sense of
what's possible here when people come
together around a particular concept of
study so SFI is um focused on the idea
of complexity science it was started by
folks that were part of the Manhattan
Project and um yeah it's a space for
people to tackle complex problems it's a
very multidisciplinary research space
which I think is very interesting they
actually incubated a new way of bringing
together scientists and tech people and
thinkers from a variety of different
fields and finding ways to kind of uh
create collaboration points between them
um huge impact again it has influenced a
lot of scientific thinking in modern
times a lot of mathematics economics
biology and and especially computer
science so uh yeah and there is one
honorable mention which is Burning Man
um I I wanted to include this because I
think when people think of popup cities
this is probably the first thing that
people think of it's It's a literal
pop-up City for you know 10 months of
the year there's nothing but desert in
this place and then um people start
building and for a week there are close
to 100,000 people there um it has had a
huge cultural impact it has spawned a
really a global movement of of burns
there are now Burns in most uh regions
around the world it's obviously quite
radical in the experience that people
have it's it's quite different from
people's traditional Lifestyles I think
so I've I've been going for a long time
I do think it's a very interesting
experiment but I do want to call out
that I think it's ultimately very
different to what we're trying to do and
I think that's important to note because
again it's like a a
um it's it's an association that people
have and that they come to quite easily
but I see the burn as a a chance for
people to very momentarily kind of LARP
or um yeah like roleplay a completely
different lifestyle to the one that they
currently live whereas I think the thing
we're trying to do with pop-up cities
and obviously there's there's infinite
variety of what people will do with this
format but um it's much more
approximating what does what could life
actually look like if it was thought Yul
designed um yeah so that's that's that
and the the question is so where do we
go from here we you know our generation
has a whole set of new problems some of
these old institutions or movements were
the the answer to a prior set of
problems we have our own there's a lot
going on I I don't need to tell you um
but we also have new tools there are
things that have been developed in the
last couple of decades that have reached
maturity that are now usable um obvious
examples internet Ai and and ultimately
blockchains which we believe are very
kind of foundational tool for this kind
of experimentation we'll get into some
of that later there are new experiments
starting to happen there's new ideas
like the network State there's Zulu
there's Edge City Zoo Thailand and so I
I really see these pop-up cities as a
way to prototype new Solutions like I've
been saying and each experiment kind of
brings us closer and closer to what a uh
a resilient inclusive and flourishing
Community could look like um yeah so
that's that's my little bit great yeah
thank you awesome that was amazing um
and I think this is like something so
important for us to do generally is like
look at history of movements and so much
of them have been pretty low Tech and by
the way if you guys want to come over
feel free to um
so much of them have been the sort of
lower Tech type environments and really
focused on just how do we get people
together and I think right now we've got
this very interesting opportunity with
like technology has progressed
substantially and can actually benefit
from and connect to a lot of these sort
of low te environments to bring like low
te and Hightech together in some magical
way that makes some of these movements
like actually long lasting or spread and
proliferate in ways that technology is
able to help with um that didn't happen
previously
so this section oh we're going to have
to do little exit because I did a did a
whole update of these um yeah
refresh this section we're going to try
and make a little bit more interactive
with all of you um we'll go through a
little bit of the history of zulu I
think Nicole and I haven't really like
sat and spoke to a lot of people about
what that all looked like and and why
and how we were doing things so firstly
before we sort of get to that one thing
that you know I wanted to profile is
this was a really great slide that
someone put together um Bob Haywood had
put together at uh Edge C Lana this year
which was just last month and he sort of
was like okay what am I seeing seeing
you know these popup where are they
fitting in the stack and this this idea
of sort of these popup Villages being
between you know we've got hours of time
together few days together 5 to 10 days
together and that the 30day onward Mark
or at least you know a month maybe it's
amount it's like it really is where that
like IRL community and culture actually
start to form so there's something
interesting you know when you look at
the ethereum industry where if you pack
up all of the different crypto
conferences that we all attend we're
starting to get to that amount of time
and there's like a real culture that has
developed as part of ethereum and this
what we're almost trying to do in these
poet Villages is like can we speedrun
culture building and what does that
actually look like and how do we how do
you spend this you know period of 30 to
something different culturally and
something that I think we can go through
as a group is just how each of these
popups in a way are creating their own
culture that is slightly different and
unique um in in some
capacity the other was is just kind of
where vitalic ended up really spending
his time thinking was like we've seen
the dates and the meetups and the
conferences and like that structure
we've iterated on a lot um but then
universities and cities and towns and
countries like those are also like very
ingrained in a specific way and this was
a um a 2 by two that I mean a graph that
biology had originally put together and
vitalic really kind of looked at this
and was like wait a minute there's sort
of this open Gap and we should maybe
just be experimenting there so a large
part of this was just like cool that's a
space for experiment ation um and that's
where that kind of
started and sort of the the next piece
is like why like why even begin to start
experimenting in that space one it's
like this dissonance with governments
like a lot of people aren't necessarily
resonating with the countries that they
living in the network State movement
sort of got that kicked off in in a in a
major way along with many other things
that were happening um
just work environments are actually
pretty stale like when you actually
start to think about just corporate work
environments there was sort of this open
question that Co really put in the air
of like okay people working remotely
what does this look like um as well as a
shift from closed Source type company
environments to more open- Source
ecosystems and how do you actually build
spaces for these open source ecosystems
versus a company that's it's a very
clear box let's all go into the space
and and work in this
office the other pieces that like we've
you know seen both ourselves experiment
with at age city and what we
experimented with at Zulu and some
others are working around it's just like
The Chronic Health disease crisis is
pretty real um across the world in like
healthy living environments has not
necessarily been a Focus but it has
become a real big
issue and then when you actually look at
education it has just gotten
progressively more expensive over the
years and not necessarily solved more
problems or made people smarter and
iterate in an interesting way um and
lastly just like innovation in general
is is expensive but th those were sort
of like starts of some of the why um to
stop building SIDS experiment and then
we got to where it all started so do you
want to go through a little bit of the
beginning yeah so when zzu came about um
I can say it from like my perspective of
how I got involved um I ran into vitalic
at a little me Hacker House and there
were like 200 people around him but no
one was talking to him so I walked up
and I was like hey I read your recent
blog on crypto cities um and we had a
little bit of a discussion and I invited
him to a hacker house that I was hosting
to which he surprisingly came um and
then there we talked rifted on
everything from like ethereum related
like account abstraction things to what
his personal life was going um to like
how can we potentially do a crypto City
so was actually last Devcon in Bogata
where we sat down and he finally asked
me like for 200 do you want to do an
experiment that's 200 people for 2
months um so like the rationale there
was there's so much Theory going around
why don't we just try and do something
in practice um and that was a very
casual start and from there we pulled in
a lot of different contributors um Milos
who represented Montenegro locally and
helped us connect to for example the
Prime Minister who is a very young world
leader I think the youngest at 35 at the
time and had a background in crypto um
so that's kind of why we chose
Montenegro for the first experiment we
thought we would get like a lot of Visa
support um and it was also a place where
we happened to have a venue ready to go
and we planned the whole thing in 2
months so it was not perfect by by any
means but Scrappy in a fun way um and
then from there we brought on Vincent
who is like a very curious guy so he
knew a lot of people in biotech of which
vitalic was very interested and he
helped be an inviter and he brought in
Janine and Lawrence and they also helped
contribute and like well Janine ended up
doing a lot of things operationally um
but that's sort of like the beginning of
the core team um so the core team helped
drive this experiment to start but I
think the experiment itself is very
co-created by a lot of different people
so we had Tech teams um we'll talk about
about this a little bit more later but
ZX Park helped start zoo pass which is a
really interesting Tech identity
experiment um and then Alia and psse
team helped start the z.c permissionless
website so that became a core basis for
how we did permissionless culture um and
yeah a lot of other teams helped build
this experiment
together so when we look at some of kind
of like the original thinking a piece of
it was like okay can we make this
cheaper than living in sort of a San
Francisco or New York like what does it
actually look like to build a place that
is awesome in some capacity with like
intellectual rigor as well as
interesting people cuz like ultimately
at the end of the day we all just want
to be around interesting people um and
the there was a sense of like okay can
we experiment in that area so we
decreased the price of um and had some
subsidy to make sure that that was the
case we also were like wow 8 weeks long
time what do we do with this um and
ultimately decided to sort of like bring
in all of these different contributors
that Nicole was mentioning to help
structure different weeks throughout the
time that we were together one learning
that we had from that is weeks are it's
a great way to bring people in that are
kind of interested in pop-ups generally
but the longevity of some of that
learning then sort of like dissipates
once that sort of like concentrated week
of programming is gone so figuring out
how we can do like extensive learning in
some capacity has been something we've
iterated on this year but this was kind
of the original start and we just
brought so many different people in um
and this was so valuable because it
brought in many different leaders and it
made sort of how we started Su not about
a team that did it all but about how do
we Empower many leaders in this
community to go and do other things
themselves to build and contribute and
think about like what they would
structure and how they would structure
it so there's kind of this tension that
exists now that's interesting around how
much do you let different groups as we
learn and figure out like oh this type
of program worked or that type of
program worked how much do you create
structure around that versus allow
people to come and and still build their
own unique programming that like
contributes to the culture of the space
and and the people that bring it
in this is just a early um stage like
this was the website to begin with and
sort of a start of like there's
different projects and there's different
things that we're working on and there's
different ways that you can add sessions
to the calendar and this has been
iterated on a ton so everyone in this
room who's like
who here is interested in building like
pop-up City Tech or kind of social
technology in some
capacity there is so much room for
experimentation they and there is so
much room to build um this was the start
last year and now we've got things like
social layer and everything at simplify
is doing and stuff that um cursive is
doing and stuff that lemonade is doing
and the all these different projects
that are now trying to build and I think
it's a very interesting space that is
going to have a lot more people
operating popup Villages and popup
cities around the world and like if we
can actually just get a lot of
technology that helps with that
coordination that would be super
interesting about tech yeah get a story
of how so with that let's get the story
of zupa started yeah sure oh man um so
my okay all right um
uh my my story with uh with zalu started
just a bit after um what Nicole and
Janine were just talking about and it
was through uh some of my friends at
zerox Park I was talking to them
about uh this event so I heard about it
through them and then I was you know
immediately interested okay this sounds
like something out of Neil Stevenson
right this is a lot of like you know
know ethereum core I was very fascinated
with ethereum at that time I was working
on a like you know a Bitcoin like client
that runs on ethereum so I was like uh
something I've been building
and a lot of people in you know core R&amp;D
and people who are digital Nomads and
they're moving to this like you know
post Yugoslav micro state for two months
like this is an incredible thing to be
happening and um then you know a bit
into this
I I also realized that that uh you know
there was a lot of scramble to to make
it happen um I was talking to you know
Ivan chub good friend of mine um over at
zerox Park and uh he saying yeah we need
to to build this zero knowledge proof
based passport for
zalu um okay like and when does this
start 3 weeks uh
right uh so I ended up saying okay you
know I can help ship this if if I can
join if I can come to this right uh and
uh then we ended up just you know in the
uh like sort of like lowering ourselves
down the M shaft for for those three
weeks and and and doing this uh a lot of
good memories that was really fun
actually um actually I'm curious I'm
with like you know so zass has sort of
iterated and evolved a ton since then I
I was part of just the initial
prototyping the version of it that I
built built the version of it that
existed for zalu like number
one how many people here have used any
of the zero knowledge proof stuff in
zpass the answer is probably everyone
here because Devon's actually using it
well Devon's using it but I think it's
Devon's using it in like a scan the QR
capacity exactly um for zalu we were
actually doing things where so like one
of the original things and the where the
Z and Zoo like part of it where comes
from is uh I
mean you could make zero knowledge
proofs that you are a zalu resident
without revealing which one and so we
ended up doing some really fun
experiments um at uh at the event that
were related to this around you know
Anonymous polls Anonymous messaging um
but not you know like internet wide
Anonymous messaging like you know
everyone who's writing on there is is
people who you're living with they're
they're one of the you know two 300
people um
so yeah I think we'll talk about a
little bit more about that in in in just
a bit but I think one of the ways that
you know we're here at an ethereum
conference I think one of the ways this
really relates is that um popup cities
popup Villages are an amazing way to
basically um bootstrap critical mass for
new ideas and they're an amazing
prototyping tool and you can try things
that you know would be very hard to like
get it to work sort of like on the open
internet and would also be very hard to
get it to work with just five people if
you need to do something with a thousand
people this is a pretty amazing way to
do it so DC is the founder of an
incredible startup called Doo you should
check it out if you haven't but I'm
curious DC if you're open to sharing how
you had the idea for Doo and then the
kind of progressive steps of developing
it at Progressive uh pop-up
cities sure totally
um it's funny actually you know it kind
of can connect the dots looking
backwards more easily at the time right
uh so one of the
things zalo was was an amazing time
um one interesting thing is that a lot
of the people there even though they're
like a lot of these people are people
are like dedicating their lives to
ethereum right like that's like they're
deep in it the amount that people are
actually using ethereum day today was
not very much um and you would see
people you know uh and and we sort of we
you know there's a few of us there who
are looking at this and saying like you
know how do we just make this much
easier to use how to make this more
useful and uh Doo V1 came out of that
where it's like all right let's make
something that is like uh you know
PayPal revolute like we pay whatever it
is but runs on stable coin rails runs on
rollups like this was actually we were
kind of leading it off a little bit you
know so skate where the puck is going
like at the time you know we
were saying okay like this is going to
be like free instant transactions one to
one we were actually sponsoring like 50
cents of gas for each one but we knew
that that was going to come down and
then you know like a year later 4844 now
it's like 1 cent one second transactions
it's like okay if this is about to
happen let's build the thing for that
World um and then you know like what
we're doing now daop pay I think it's
funny part of that came out of the the
subsequent you know Zoo connect right we
spent a a couple of weeks in uh
Turkey right before uh Dev connect that
was a sort of the the the start of it
and then we like really like you know
figured that out
in we had conviction about that like
later when we went to you know Argentina
you go to places where people use a lot
of stable coins and where people are
like doing uh you know know I think the
the sort of most widely distributed
version of what you could call real
world ethereum or real world crypto
right it's places like turkey it's
places like Argentina it's we talked to
a bunch of people in Africa who are
working remote getting paid in Stables
um and and this is like uh it's a whole
different world from I think a lot of
what you see in like Western crypto
world where sort of like you know
outside of the like core like sort of
intellectually curious R&amp;D audience
there's a lot of people who just like
want to buy something they wanted to go
up right like for those people no this
is like they're using the permissionless
nature of the chain to be able to do
things they couldn't otherwise do I
thought that was very compelling the
really hard part there was a lot of
those people you know are not deeply
into self- custody they're like yeah we
love lemon for example in Argentina
lemon being a like custodial staple coin
app that will give you you know certain
like nice features that rely on it being
custodial actually that people really
like um same in Turkey same in AR
and so uh what we're doing now is
something it's like okay if you want to
do anything on ethereum in like one
transfer right even if it's from a
custodial app how do you facilitate that
someone wants to place a poly Market pet
how do you let them do it directly from
lemon so that that's what daop pay is so
we had our whole like Arc of of of what
we're up to closely related to things
that we learned from these sort of like
intensive
experiments I think that's an amazing
segue into the relevance of this entire
movement for crypto adoption and
accelerating crypto adoption which is
what um this talk is about it's it's
such a good example of a product that
was developed in the context of where
people will actually use it so inside a
pop-up City and then with Progressive
pop-up cities you know you have like
four months 5 months in between them you
can actually develop the product and
then the next time you go so between
zalu and zconnect you were able to build
something for for this new market where
we were going to be suddenly and for the
City to actually use it iterate it they
had a baklava stand we had to use Dao
and you'd spend a dollar on some amazing
Baka which was really really cool and
then actually be able to start to expand
your reach and go out to progressively
bigger and bigger markets until you get
somewhere like Argentina where it's like
wow not just the people in the city but
everyone here actually needs something
like
this now I wish I threw that picture the
slide deck of of Nan and sitting there
with the the the red hats with the buaka
stand that was a good
time yeah and and that that goes to sort
of some of the recognition here have
this
building building Tech e like what does
an ecosystem need versus a company right
like with ethereum is an ecosystem with
many different projects in it and this
push towards open source and kind of
like thinking what is that type of way
of working need and way of living need
that's different to the current
constructive of um companies where it's
like shipping a space and then send it
out to to customers it's we're in a spot
of like iteration and you know getting
feedback getting people to build in one
another's ecosystems getting people to
build on um and use the open source
technology that we've got so these
pop-up City environments are space
to test and iterate and share what we
are doing um and what you are working on
in a way that we haven't necessarily had
previously and we're just seeing teams
come to life with that like they are so
excited about this idea of like being
able to build a thing have users
instantly that are totally captive and
excited to support and build on and
connect them with other groups and
there's just sort of this network that
grows which is quite similar to what we
have seen grow with the popup City
Network so instead of us being a project
that you know with Zulu there was this
kind of open question of like can we
actually progressively decentralize but
then have a call what does that look
like do we do we run zuu do we not there
was sort of this big open question and
after Zulu Montenegro which sort of how
we structured it was you know there was
chaos it was absolute
this last sort of last minute of 6 weeks
of planning to give um to give you guys
context there it was like you know they
had found a spot but when when I came
onto the team it was we we had like 10
weeks before susulu had started my
wedding was the first week of zulu um I
was very excited to I you know my plan
was like I was planning other events at
the time and I was working at getcoin
and like my what I really cared about
was bringing together um folks to think
about like how can we fund Community
shared needs and that was sort of this
focus of like public goods it's like
public goods are fascinating for
communities funding people's shared
needs should happen in some capacity um
and I wanted to bring it IRL like
ethereum was a space that was just doing
this in an interesting way online but I
very distinctly remember coming into the
space and saying like I never really
wanted to have a Twitter presence I was
like I don't understand that world I
understand like the inperson and like
tangible world and that's what I want to
build for and it's just going to take
longer um but then zuu sort of popped up
as this thing and I was like this is
definitely exactly aligned with like
what I've been trying to think about
working on um at the time I was building
IRL community in Austin and then looking
at like how ethereum could be supporting
that type of structure so um when
vitalic and Vincent
asked me to join the team and was like
oh this is great but I have my wedding
in 10 weeks time so my wedding was the
first week of zuu the the team really
held down the for with that um and we
all just like scrambled to make it
happen and I think what was beautiful
about zzu was how much we had to rely on
the community from the beginning because
we had so little planned like I remember
when we started you know people were
like accept you you know wanting to join
for 2 months we were like wow someone
actually wants to come we've we've got
people this is amazing then we were like
do we open the Discord do we not we
don't have any plans yet um and there
was sort of this push towards like build
and public build with everyone and that
building with everyone sort of led to a
culture from the beginning that
developed around letting many
different flowers bloom and letting many
different projects sort of come out of
this and many different people
contribute so after zuu
Montenegro everyone was like when's the
next zzu when the next Zulu and we're
like well let's try and like build
something that's not Zulu but it's just
a using the zoo to get to have people um
have attention but doing we called it
Zoo connect um because it was a lot of
us from the same team everyone was like
that's zuu and there was this idea of
like like okay well I want to go to the
zuu thing moving forward versus like
allowing many different projects to come
out of it so there was this hard
decision that was made around just
decentralize in a way that like
generally had no no call to zzu and it
was scary to so many people because it
was like this thing that we had built as
a community was it going to disappear
forever was it going to like become
something else like there there was
definitely a lot of fear there for
people um and for for us as a team as
well and it was a decision that was like
so beautiful because you start looking
at this ecosystem and this is a year in
um and you've we've got in here it's
like so from Zulu
Montenegro there was zuo connect that
happened that spun-off um the moo is
kind of connected to being part of the
Coe actually this should be a line that
goes across here this is still someone
mapped this out for us um and they've
sort of spun out a whole bunch of
different things that also spun out
megazoo that you've got now sort of Meda
camp and what's being built there um
seeing Network State generally like the
network State book is kind of like a
core that uh spun off sort of zulu
Montenegro and network school was
something that um in speaking to biology
earlier this year he was not sure what
he was going to when or how he was going
to sort of build Network school but
because of zuu and because of edges
meralda that we did earlier this year he
was like I've now got two proof points
that sort of have me like wanting to
test in this sort of way so there's a
couple of things that have spurred out
from this side of it then when you start
of look at the like what we said of zulu
as a name shouldn't be used but like use
zoo and get people to build Zoo villages
all over being you know something we
wanted to see there's just been so many
different projects that have been built
and have their own beautiful culture
that's like super super unique um some
some kind of different like pieces of
culture like some people are diving into
the health stuff some people are diving
into like we only want ethereum
developers and they've got a ship and
they've got a ship the whole time um
some are trying to focus on a specific
group of diaspora like forsees is really
focused on how do we support the Chinese
diaspora and like making sure that is
the core one of the core values that
they hold true uh so recognizing that
like new Society gets built with so many
different like small nuances but having
a you know Nar some way um to help rally
people around has been beautiful to see
and like that collection I think will
only take will take many many years to
kind of figure out who's doing what and
how do we connect them all together but
that was a bit of bit of backstory over
there I can add a little bit more um I
feel like a lot of things that look like
happy accidents were like small
decisions that vitalic made in a split
second which ended up making a lot of
sense like he was always right at the
end of the day so even at the first ever
zizu Montenegro opening ceremony and the
way that was set up all of us were just
like seated on bean bags or like eight
people on a stage um and he already
welcomed Forks he was was like I want
you guys to Fork this I want you guys to
take this however you want I want to see
more leaders um and the reason being the
first Zulu was very Broad and almost by
intention and there was no centrally set
vision and that was very deliberate um
because we want people to take this in
different ways um and that's been like I
think what's most powerful about pop-up
cities is what you've seen is like
strong leaders people movements and
people that rally around certain values
have been able to use this as a conduit
and as a framework to build community so
we've seen that like Ed has been able to
build a very strong community and do
repeat events we've seen moo do that um
moo is a entirely Grassroots um sort of
fork of zulu and they've done like three
four events now and they always involve
locals so what we've seen is like
individual leaders are good at different
things care about different things and
because of that they can take this in
different ways um so when vitalic
decided to decentralize this I think a
lot of people were scared but it's
definitely proven to be the right choice
because we've had 20 plus pop-ups just
this year and if it were just one team
there's like a 0% chance we could have
done 20 pop-ups ourselves um so yeah 20
popups um all italic did was he started
this press play on the experiment and he
provides funding so he matched a
quadratic funding round or two actually
um for both events and Tech teams and
that's been a nice little like um pool
of money that helps people kick off
their own pop-ups but for sure it
definitely is still biased towards
people who are high context who've done
these before but we almost want to
welcome more people to come in like we
want to grow this bigger we want more
pop-up City organizers we want more
initiatives um rallying around different
things
um and I think the last thing here
before we actually shift to like more of
a workshop type thing is zuu was really
just like a seed that was planted and
see it like as a seed versus an umbrella
um with so many different ideas that
we'd love to continue seeing being built
and different groups Building Technology
to support these building actual built
environments that can host popups
building operational teams that can
support pop-ups in different ways
bringing in different community members
um to you know actually drive things
forward like it it truly was the seed
that has allowed many different groups
and projects and ideas to flourish and
the hope is that there's just so much
more that comes out of this over the
next couple years I think social
technology is such a powerful idea and
it does take both low-fi and high-fi
environments to sort of like bring that
together so on that
note who has laptops cuz we had a fig
Jam planned but I'm only seeing a few
laptops in the
crowd so instead why don't we do a set
of questions and just kind of go around
and keep it a little bit more
informal questions are also if folks I
mean I guess something brought you here
this morning right unless you just
stumbled into the wrong room but even
then if you have thoughts or Curiosities
if maybe you haven't been to one of
these you want to build technology for
one of them you want to build one
yourself curious if anyone has anything
to
share yeah I can come around with a mic
as well so everyone on the stream okay
you shout and then we'll repeat what you
say yeah that's a good idea just to open
the floor we're building a network state
in Japan is our first back I want to
learn from you guys experience building
these opportunities try what is it
called yat yat is a new network state in
Japan yeah that sounds awesome what are
you guys going to be focused on what's
kind of a core idea yeah our our core
commandment is well moral
is that building is moral and so the
core commandment is we we build and so
we're bringing together foreign and
Native entrepreneurs and helping to do
crosscultural learning communication
over a six Monon to 10e period longterm
longterm thing starting with one site
and then we're going wide instead tall
so is doing Singapore 2.0 we're doing
all in Japan wow
cool the shape of that that sounds a bit
like uh cresimo Alf down in Argentina
I'm curious if that's something that you
were inspired by or is it's it's
different from that honestly I've heard
of them but I haven't ConEd with them
yet so I'd love to thank you for the
reference I'll try to look up with them
Lear them please p in front of you over
there totally very nice and they're
they're doing
something so cimento is a movement that
was incubated um at Edge City Denver in
the sauna actually which is some lore
and uh so that was around 10 months ago
and it very quickly spun very quickly
grew legs um props to Juan Ben and and
many many others who have been pushing
that forward um Janine organized a trip
to Argentina like a month later and then
they managed to do an incredible pop-up
city called Alf in August and the only
way that that actually happened was
because of tapping
into this whole group like at Edge City
we were literally in the sauna and Juan
was like I want to I think there's an
opportunity in Argentina and I was like
you are not
Argentine and neither am I so we need to
make sure that like this is something
that is led by locals um and the son
from the moo was actually at H City
Denver and he was just hanging out and I
was like like son I need you this you're
going down to Argentina in like 2 weeks
time and you're planning to sort of
build a pop-up of sorts down there can
you start like thinking about and
looping in different folks and they were
incredible um with just like quickly
bringing together people to do a call
and we had a call to share about like
the sort of opportunity in Argentina
that Juan um had sort of like identified
and some people locally had kind of
thought through and we had this call
like 2 weeks later with like 10
different Founders and Builders um and
creators that presented from like
Argentine folks that were just like
amazing um and we had like 300 people on
that call and we're like wow this is
just an amazing Community like we should
go down and spend spend time down there
so we went down while the move was still
happening Petra was someone who was at
Zulu
and you know I was able to be like Petra
can you help in some way like who who
should who should people here meet um
Petra is Argentine right okay yeah
great ra and we had sort of a series of
like breakfasts and workshops and meals
and there were just people in the
community there that were really
inspired to do something that we could
support get off the ground um and that
was something that you know then I was
like okay August timeline because
because this new government um in
Argentina doesn't have a huge window
it's like four years is a really short
amount of time like we need to do
something bigger in August and Juan had
spent a lot of time um at different Edge
City environments where he was just like
I want to like use this model to kick
off some of this like to spark these
initiatives and then it was just like a
local team and individuals that were so
passionate about the project there was
probably 70 people that were like
working on it um other people
internationally came in and helped as
well so it was really again like another
initiative that just spun up really
quickly because of this network getting
started and you know the the people who
are now carrying it Forward are within
the network but like doing it in their
own way like there's no you know there's
no top- down leadership that's that's
driving
that yeah I'd be interested you just
said uh like the model the model what is
the model what is the what stays
continues is it like for example
principles like berning man has or what
is the core and do you have a playbook
for different locations to get started
we've got a Playbook um we've got an
edge City Playbook we have an old zuu
Playbook I think when when we say the
model Loosely long amount of time with
many people and I actually I I've seen
some people get um you know want a model
of like they're like it has to be 150
people to be a Zulu and I'm like wait
what that was just what we had like that
was an idea that you know more than dun
Bar's number is useful um but I think
iteration around that is really
important but I do just think like
Loosely it is you know long long time
frame around some core values burning
man took 30 years to like come up with
their principles and I think this is
another thing of like coming up with
principles too early um can sometimes
sort of pigeon hole you into like it has
to be a specific way when there's still
a lot of learning that we have to
do so the you can take a look at the
playbooks we've tried to like be more
operational on those versus like this is
the the principles that you need to
follow yeah I think like every single
popup has completely different values
and the overall pop-up City movement is
just very very vaguely empowering people
to do their own experiments um and
that's why I think like I want to see
more people go crazier with it like I
want people to completely break the
current pop-up City model and do
something new that takes off um the
original format I think people just
enjoy um so I would elimin like to grow
this to something new like I would say
hacker houses if it's smaller than like
pop-up City you're probably a hacker
house if it's shorter than a month
you're probably more more of a
conference residency and if you only
have like one Focus then maybe that is
also considered a residency like the
core values of the original Zulu we sort
of playing at intersections and playing
like these new novel experiments so yeah
the experiment itself is to do more
novel
experiments yeah any uh a few minutes
left people have any more questions
comments
roast yes do we have some like online
element community so that like
city that you kind of stay connected and
you're s part of that online community
and you keep
on yeah con so uh to the prior point
we're still very much in the in the
process of experimentation around these
things we are very much IRL Maxis in the
sense that we feel like 99% of the
possible kind of connection moments
happen in person but people have
spontaneously started Ed to um you know
gather do little meetups around the
world in the cities that they happen to
share time in so that's something that's
being cultivated we don't necessarily
want to have we don't want to fall into
the same trap of some of the mistakes
that uh we've seen some communities make
of trying to lean too hard into like
okay everyone has to be on Discord you
know all the time you always have to
monitor what's happening there's a lot
of like cognitive load that happens
there but tldr we're experimenting ing
we're still going to yeah try new things
yeah there's not there's not like one
sort of shelling Point online community
where all of the even even just
specifically as all the folks
are Town Hall yeah actually okay so we
have open Town Halls that people can
join they happen monthly now um and it's
a lot of the different pop-ups coming
together and having discussions so
that's like a good place and maybe we
should share that link somewhere um and
I think like a separate thing I actually
think this is a big problem of zizu
because it's like very in illegible like
and there's no real way of like engaging
in long form contribution so one thing
so I'm hosting a popup after this called
zo Thailand and one thing we're doing
with that is trying to build it entirely
in public so we are going to have an
open discourse so not Discord just like
the standard Forum um for people to like
talk about po cities if they would like
um so that would be a potential starting
point and yeah some something that sort
of we've seen is people have tried to go
online after like people have tried to
build the community between and it's
there's still a lot of iteration that is
needed in order to sort of like keep the
momentum or actually like provide a lot
of value in the inets but I think that
there's also the side of things
happening more often in person something
that I've recognized is projects that
have tried to get off the ground in like
Edge City environments that we've had
and even at you know we didn't really
have Zoo connect I think was a was a
good one here or some some of the other
popups even with Cy Mento where they're
like hey can you use my tool like I
really want this tool to be used but
actually I don't I don't have the time
to come and be there and like there's a
tension between wanting to see a lot of
people's like projects out in the world
and and used and a deep recognition that
we've had is like people that are trying
to iterate from afar and build for a
popup but not being there have not
succeeded super well because there's a
there's the value is in the iteration on
the ground um so being being at these
spaces where you can iterate and get
feedback and like real feedback and you
know are dedicated to that I think is
super
valuable hi my name is Jason and uh um I
think today is my first time I genuinely
have a touch point with zu
so um I find it a very interesting
experiment I'd like to ask okay each and
every one of you what is where was the
the last zalu and what is one thing okay
that caught you off
guard
so there was a moment where I found
myself dejing with Grimes and that
definitely caught me off guard at zalu
this was a very strange set of
occurrences that had to happen for that
to be the case but there I was on the
montenegrin seaside with that happening
um and that kind of it's it's a funny
story but it illustrates the diversity
of experience that's possible in
environments like this it was a
diversity that led to me having a very
personally meaningful experience where I
felt like many sides of my personality
were activated in the time that I spent
in that space and I think that's kind of
a core strength of pop-up cities they
really allow for this just like breadth
and depth of of experience so yeah what
about you guys
um so I think to this point it's like
pop-up cities I I would actually say
that duu again was the seed versus the
umbrella and the umbrella is more cities
um so
okay um I think a moment that caught me
off guard recently was we just did City
Lana which was in um changai and it was
a really awesome experiment like seeing
the progression just even in the past 18
months of community of the technology of
people that are building of how people
are understanding these these spaces was
was truly amazing and a moment that I
had that call me off God
was an idea from last year was like oh
we should have more families in these
spaces cuz we don't want to create a
spot that no one actually wants to get
to the next step of life like we don't
want Peter Pans we want people that
actually like think about building a
better Society um and it was very much
so this recognition of like if we don't
have kids we will build a lot of Peter
Pan syndrome and we will fall into the
Trap of like what companies today and
what work environments today have almost
fallen into which is like many women
having to choose between work or
family and it's like it doesn't have to
be that way like we should be able to
participate in the workforce in whatever
way that we can contribute versus like
the stay-at-home mom syndrome and maybe
it's I just have a personal fear of
being a stay-at-home mom and never want
to do that um but the the moment that
sort of like really caught me off guard
was seeing that idea be seated at Zulu
of like I don't want a future of Peter
Pans I want a future of people building
something building the future together
and being at ed3 this year with many
families and one moment of a mother with
her two daughters um being at a workout
class which was also another thing that
I really wanted to push at Zulu was like
making sure we did have health and like
we we're broaden longevity folks but I
was like okay but like we have to like
stick if we are going to say that we're
a healthy place like we have to stick to
that which they had put sort of a
gym I remember this wow they put a gym
like a 45 minute walk up a hill in a
tent and they were like there's your gym
and I was like no one's going to go
there like you need to optimize for the
laziest self when it comes to working
out and I was like a probably 2:00 a.m.
and I was like you know what screw it we
need to put the gym in the town and they
would they wouldn't let us cuz they were
saying like well it's going to miss our
little pretty Marina rep and like
there's no way you can so I like mapped
out all of the apartments that we had um
like rented out for the time and I was
like which apartment has the largest
balcony and I was like fine I'll stay in
this apartment um so that like I I have
this we can use this balcony space and I
was like move the gym to the balcony
because that was private land that they
couldn't control they weren't stoked
about it but like they had to sort of
comply so had a gym on my balcony and it
was truly like you know a l Stitch
effort at like making sure we had a
space that at least people could work
out but getting to see the progression
this year of having many many workout
classes like one aspect that we want
with Ed city is to focus on like
building a healthy city um and having
you know workout classes having gyms
having access to you know you can be
active at any given time and seeing this
moment of like a mom with her two
daughters and a workout instructor that
we had brought out that was that had
become like this beloved relationship
where the mom and daughter were
attending every single morning with with
this um workout instructor and she was
leave the workout instructor was leaving
the next day and both daughters and Mom
were like in absolute tears after two
weeks of being able to do workout
classes together in a space and I was
like this is just a really cool moment
where we sort of engineered like a
completely different social environment
to something that was normal but it was
kind of this like seeds that had become
something
bigger yeah caught me off guard um a lot
of things but I guess like this time
when BAGI was planning the network
school um there was a moment where I was
just like answering all the questions
and they were like what else can we do
and I realized that like some of this
all of this is just so easy and all it
everyone just needs to do it and by
doing it you'll have experience so
seeing that like someone like him who
initiated this coming back and just
asking for operational advice is like
very surreal um seeing that there was
like 10 plus pop-ups before um Devcon in
changai that was surreal um there's just
this movement has really taken off and I
really did not think um it would do so
so quickly and yeah I don't know very
happy about
that this one's maybe a bit further a
field but uh
one one experience that definitely
caught me off guard U so I
mean we
were just to make it not make it sound
like this was like a big vacation people
were like pretty locked in we were
working for the most part at zalu um but
uh towards the end there you know
there's a group of us that went uh uh
wakeboarding uh wake surfing and I ended
up talking to the uh this Russian wake
surfing instructor um right and uh
completely like uh like unprompted he
was telling us you know like his stories
and he was telling us about how he
uh did a lot of things off of uh stable
coins usdt like paid his kids tuition in
usdt um because he's locked out of
regular banking right and he had escaped
basically to monegro uh you know at the
start of the conflict so that that he
wouldn't get embroiled in that
um and that was pretty visceral I'm
small boat with this guy right really
friendly guy and that was pretty amazing
you know seeing people who are sort of
using the uh you know permissionless
nature of of of the system
to permissionless nature of ethereum to
basically
Escape uh authoritarianism and claim
some freedom for themselves that was
really cool to
see all right I think we have to wrap up
there but thank you everyone so much for
joining us this was really wonderful
and yeah we'll be around a little bit
outside if anyone has any questions so
yeah thank you thanks for coming
I oh
you
all
for
I
[Laughter]
he
oo
B
okay I think we're good to get started
hello welcome to the workshop for rip
empowering low-level cross-chain calls
with minimal um trust assumptions my
name is Jack chuma I'm uh a senior
software engineer working in R&amp;D on the
base team at coinbase and I'm so ex
excited to share with you all a little
bit about this
project so a couple of goals for today
um first and foremost I want to promote
a deeper understanding of RP
works um second considerations for
adding new chain support in the future
as I foresee that being one of the uh
main opportunities for open source
contribution number three one of the
main um features of the standard is that
it minimizes trust assumptions and
that's done via a mechanism called what
we're calling nested storage proofs so
I'd like to do a deep dive there and uh
promote a deeper understanding um and
then lastly integration details so if
you're an app developer and you would
like to be able to facilitate some kind
of cross-chain call between l2s and the
ethereum ecosystem how would that work
um if you're if you're integrating with
standard so to give you some context in
a a highle purpose on where we're coming
from here I included a screenshot here
from L2 beat um sometime last week and
what it's showing is activity in
ethereum l2s
and more specifically how it surged by
over 500% in just the last year Alone um
and that's being spread out over many
different networks so that's why I chose
this screenshot specifically it shows um
a handful of networks this is just a
small subset of um how many l2s there
are already and that's only just going
to continue expanding um and this has
been great for scaling ethereum but it
has caused fragmentation in the
ecosystem um where if you're a user and
you want to interact with an app that's
deployed to a specific chain that you
maybe don't have funds on um there are
certain Hoops that you need to jump
through to get funds to the correct
location to be able to um you know
interact with that application and that
hurts the user experience it's a
critical problem that has to be solved
um and so to solve that problem uh we
believe that there should be a standard
between or for communication between
chains that uh checks the following
three boxes is public and decentralized
in the spirit of web 3 relies solely on
on validation data that is trustless
available on chain so minimal trust
assumptions and has built-in flexibility
to support any arbitrary message these
three uh bullet points were the three
North stars that uh we kept in mind as
as we developed the RP 7755 proposal and
uh we'll dive in
now so because ethereum l2s uh post some
sort of state representation to a shared
execution environment they are uniquely
positioned to solve this problem with
minimal um trust assumption
uh and this is done via a mechanism
called nested storage proofs as I
previously mentioned um this allows us
to prove State about one L2 from another
L2 even though they don't have a direct
line of
communication to understand storage
proofs um I think it makes sense to do a
quick refresher on Merkel trees uh of
course this is nothing new but uh a
required prere to understand um storage
proofs and how they work under the hood
so uh as a quick quick recap here um a
Merle tree is basically a tree data
structure where each node is a hash of
its direct descendant and so if you
wanted to represent uh like in this
diagram here I don't know if you can see
my mouse yeah um we have these four data
blocks a b c and d and if you wanted to
convert that into a Merkel tree each one
gets hashed uh respectively to create a
leaf node for the tree you group The the
nodes into groups of two hash
concatenate them hash them together that
creates their parent node and you do
that recursively until you reach the
root root node of the tree and
effectively what you've done is
generated a unique identifier um for the
entire data set that is just a single
hash so this has a couple of interesting
properties one being that if any of the
data blocks changes in any way
whatsoever the the root hash is going to
change completely um and then this also
like this property allows us to
efficiently prove inclusion or exclusion
of data within the larger data set so in
this example if we wanted to prove that
data block a it was in this larger data
set of a BC and D we first would need a
verifier to have trustless access to the
the root hash that is uh represented in
this root node up here if that's in
place all we'd have to supply to the
verifier is data block a and then this
node of hash of B and then this node
hash of HC HD and that data alone is all
the verifier would need to recreate the
the root hash at the top of the tree so
the verifier would then Hash A to create
this Hash a node combine Hash A with
hash B hash that together to create this
hash ha HB node and then do that again
for this this final level to recreate
the root node and if that is equivalent
to this the the stored root node that
the verifier already had then that's a
successful
proof so how does that apply to ethereum
storage um basically all of ethereum's
state is represented as a modified form
of that merkl tree data structure called
a Merkel Patricia try and the exact uh
details in terms of the difference
between the two data structures are out
of scope for this talk but um it's it's
basically a handful of optimizations for
theem specific use cases all we really
need to know or care about for this
application is that that Merkel proof uh
Paradigm applies here so for every block
in ethereum there's a handful of block
headers one of which being a state route
this is the the root hash for a Merle
Patricia try for all of ethereum state
where the values in that try are
ethereum account
um these accounts could be eoas so like
any offchain wallet like coinbase wallet
or or metamask or it could be smart
contract accounts um the like these
accounts as they're represented in the
try are represented by a array of four
pieces of metadata about the account and
that's what I have listed out here so
you have the account nons balance
storage route and code has for um yeah
so for smart contract accounts they it's
highly likely that they're managing some
type of state and if they are that is
stored um in that contract storage and
that contract storage is also
represented as a Merkel Patricia TR
under the hood and you guessed it the
root of that try is the storage route
that is uh stored with the account so if
we have access to a state route for a
network um we can supply a path down
that state try to a specific account
within the network and then using that
account's storage route which can be
extracted from the accounts metadata um
we can supply another path from the
storage route to a specific location in
that accounts storage and that's
basically the highle concept of how a
storage proof
works so how does that apply to
cross-chain messaging though because
that's just proving State like within a
specific Network so to explain that I
have this diagram here it's very
simplified obviously but um this meant
to represent two rollups in the ethereum
ecosystem that are both sharing state
with a a shared L1 um so this L1 at the
bottom would be like ethereum main net
and then chain a and chain B are two L2
Networks
what this diagram is depicting is
bidirectional communication between the
two layer 2 Chains and the shared layer
one um for this downward Arrow Direction
in both chains uh an ethereum L2 chain
wouldn't be an ethereum L2 chain if it
wasn't sharing state with L1 in some uh
context so that's what this is
representing here uh it's requiring that
both chains are sharing some
representation of their state with what
I'm calling a rollup contract on layer
one um this could be the state route
directly or could be some other
representation of State the only
requirement being that it has to be
verifiably linkable to its state route
at least for the way that um RP 7755 is
working thus far and then in the other
direction we need trustless access to a
layer one state representation within
the L2 chains as well so that's what
these upward arrows pointing to the
beacon Roots Oracle contracts are um
this is made possible by an improvement
proposal that's live today in many
networks called EIP 4788 which trustless
exposed is the most recent uh 8,191
Beacon routes for um the ethereum
consensus client within the L2 execution
environment it should be noted a beacon
route is not the same as a execution
client state route but it is verifiably
linkable to the L1 execution client
State Route via a very similar process
so from chain a if we were trying to
prove something about the state of chain
B um this diagram represents everything
that needs to be true for that to work
so if chain a starts with a uh trustless
access to a beacon route it can supply
uh like a Merle Patricia Tri based proof
um to verify the L1 execution client
State Route and then if we have a
verified L1 execution client State Route
that's that exact storage root or
storage proof process that I just went
through applies um so we could then
prove anything about the state of layer
one from chain
a in this context the first step would
be to go from the state route to um like
a path to an account within that state
try and the account here would be chain
B rollup contract and then using chain B
rollup contract storage route we can
supply another path to a specific
location in um in that contract what's
interesting here is if the value that
you're verifying inside of chain B
rollup contract is itself a state
representation for chain B you can then
recursively follow the same steps again
to prove something about chain B's State
try so then starting from chain B's um
State Route you can supply path to a
specific account within chain B and then
again a path to from the from that
account storage route to a specific
storage location and that effectively
allows us to prove uh verifiably a
location in storage in an account on
chain B from chain a even though there's
no direct line of
communication so that's cool but how
does that help us with cross chain calls
um this diagram is an overall
architecture for how rip 7755 is set up
to work
um and that should help answer this
question here so as you can see we have
two chains represented in origin in a
destination and then we have both
onchain and offchain components here um
every supported chain is going to have
some sort of inbox and outbox contract
that we're calling RP 7755 inbox and
outbox but I'll just stick with inbox
and outbox for for the rest of the talk
um the outbox contract is basically the
entry point into the standard so if a
user wants to request a cross chain call
they submit a request to the outbox
contract if the request settles properly
um it'll admit an event that some
offchain actor that we're calling
fulfillers should be listening for and
if there's sufficient incentive to
respond to that request then the
fulfiller will so that brings us back to
um a way to incentivize fulfillers to
respond to the request another key piece
of uh logic that happens here is the
user will also lock some kind of reward
Bounty um for the fulfiller to respond
to the request if the reward Bounty is
sufficiently like incentivizes the
fulfiller then it'll
respond so the fulfiller then assuming
it's a sufficient incentive will submit
the requested call to the destination
chain over
here um that routes through an RP 7755
inbox contract which will perform a
handful of validation steps mainly
confirming that the request is arriving
to the correct chain and uh the correct
location at the correct chain at that um
there's also this custom like optional
validation step called a pre-check
contract where this could be absolutely
anything as long as it adheres to a
specific pre-check contract interface
that the standard requires um and all
this is meant to do is allow the user to
encode any kind of arbitrary fulfillment
condition um that should be true in
order for the Fulfillment to to work out
but like I said it again it's totally
optional so if it's if it's not being
used this step will be skipped if all
the validation steps um are like
sufficiently check out properly um then
the requested calls will be routed from
there um so this could be a batch of any
low-level arbitrary call that goes to a
handful of addresses with encoded call
data um and any native currency value
that may be
included if all of those are
successfully um are successful the main
purpose of this inbox contract is to
then store a receipt of successful
execution um and this execution receipt
gets stored in a deterministic location
within this contract storage that is
derivable from the origin chain without
knowing anything about the state of the
destination chain um so that's important
and we'll come back to it in a second
after the call has been successfully
submitted the fulfiller then comes back
to the origin chain to say hey I I I did
the job now can I have my my payment and
what's unique about this standard is
that the payment will only be released
if the fulfiller can cryptographically
prove that they did actually submit the
request to the destination chain and
that's done via that nested storage
proof concept that we just walked
through um so from the origin chain the
uh origin chain would have to be able to
verify a specific storage location in
the uh inbox contract on destination
chain and because of the fact that the
outbox contract can derive exactly where
that location is supposed to be then um
the outbox contract has everything it
needs to be able to verify the
successful fulfillment of the call so
only if this nested storage proof um
checks out will the outbox contract
release the reward to the fulfiller and
that would close the loop on the full
process for how rip 7755 is
working
um yeah so for today's
Workshop I have a um example project for
us to go through together so if anyone's
interested in uh coding along there is a
starter repository on my GitHub that I
can show in a second um
if you're not interested in following
along I'll just I'll be doing it up here
as well so um we can go from there so
I'm going to start by walking through
all of the contracts and services that
are present in the starter project uh
this is going to be a self-contained
system that is mocking a multi- rollup
uh ecosystem that will run locally on
your on your machine so once you once
you clone the repository you should have
everything needed to run the entire app
into end
locally so after a brief walkr of all
the services and how they're working
together to make that work will
Implement and test a nested storage
proof validation contract as that is
where the bulk of the effort is going to
have to be applied to add new chain
support in the future I also just think
it's really cool um and then once that
is working properly we'll integrate with
an offchain client application so for
this demo it's just a simple nft mint
application where the nft owner wants to
be able to support users who uh don't
necessarily have funds on the chain that
the nft contract lives on so if they
don't it would be an rip 7755 request to
send the cross chain call to still mint
nft so once that is all set up we should
be good to run the app end to
end before we jump in I'll leave you uh
well I guess I'll leave this
presentation piece with that it's still
very early in the research phase that uh
a lot of these details are subject to
change but we have proven the concept on
live networks of this nested storage
proof and how that can be used to
trustless verify cross chain calls so
this seems to hold a lot of potential
it's something I'm very excited about
it's something the bass team's very
excited about um we do have an open
source proof of concept repository on
the base or GitHub that I fully invite
anyone and everyone to contribute to if
you have uh interesting ideas so with
that uh we should be good to dive into
code but as a quick gut check uh are
there any questions before doing
so and there will be time for questions
at the end too and and after this talk
so
okay so I didn't know the best way to
share the link but um my GitHub is is my
name Jack chuma and I have this Devcon
anyone's interested in coding along you
can clone this repository and uh and
follow along with me
I already have it cloned so um we can
start with a brief walk through
here so once you have the project what
you'll notice is there's two main
directories we have contracts and
services so this is onchain and offchain
um components from that architecture
diagram we can start by going through
contracts um I'll start with the nft
contract because it's very very simple
um but this is what our demo client is
going to be using the main piece here is
this mint function the only reason I'm
covering it is because this is going to
be needed to uh set up the integration
when we get there but there's nothing
too interesting happening
here
um next up we have a rollups directory
and this is used to mock the multi-
rollup system locally um I didn't want
to have to rely on good internet
connection for this to work so uh we got
a mock system running locally this
rollup contract is what would be
deployed to a Mach L1 and this is what
will be storing a state representation
for the Mach l2s in this context that
state representation is a hash of the L2
block timestamp and the L2 State Route
um and then on the L2 side of things we
have this Beacon Oracle contract which
is meant to mock the EIP 4788 interface
interface to query um one of the beacon
roots that are being stored in the L2
execution environment for this example
it's a simple ified example and this is
directly storing the L1 execution client
State Route so um we we are cutting out
a step of ver verification going from
Beacon route to State Route but um I
think it still gets the message
across and then we have all of our rip
through for what an actual request looks
like we have this RP 7755 stru file and
this is exactly what a request would
look look like so um all the fields are
we start with a requester so this is the
pretty self-explanatory the address
submitting the request we have a batch
of calls where each call is a low-level
um description of the exact address that
you'd like to send the call to encoded
call data and then any native currency
value that should be included with that
call and then we have a specified Pro
contract um the reason this is here is
because there's no standard way for L2
chains to post their state
representation to L1 um and because of
that the exact implementation details
for verifying State about a destination
chain will vary depending on what that
destination chain is so right now we
have the setup with the proving logic
abstracted into separate contracts this
very likely will change in the near
future if we baked that into the outbox
contract um that would require multiple
outbox contracts to be deployed to each
chain um so it's a trade-off but for
right now this is set up to be one outb
one outbox one inbox and then uh an
array of pro contracts deployed to each
chain that the user would have to
specify which one um should be used to
verify
fulfillment and this contract is what
we're going to be implementing in a few
minutes then we have destination chain
ID which is pretty
self-explanatory inbox contract is the
address of the RP 7755 inbox contract on
the destination chain um L2 Oracle
address that is the address of the
rollup contract that would get deployed
to L1 for the destination chain so this
is the user specifying where the prover
contract should be looking for the state
representation for the destination chain
when it's verifying that the call was
submitted um so the user is specifying
the address where that should be located
as well as the storage key within that
address um and then we have a reward
address this could be an erc20 address
or as specified by ERC 7528 there's a
special address value that can be used
to um depict native
currency then there's reward amount
which is the amount of the reward asset
that should be locked within the request
um should be noted that reward amount
should cover all of the value that's
included in these calls plus whatever
the gas cost would be for submitting the
call to the destination chain plus an
extra tip for the fulfiller and that
extra tip is what acts as the incentive
for the fulfiller to respond to the
request then we have finality delay
seconds this is uh the Gap after which
or after the call is successfully
fulfilled on the destination chain um
that has to pass before the fulfiller is
allowed to claim the reward this is
basically like destination chain reorg
protection for the user the lot like the
higher this delay is uh the more likely
the reorg chain or the destination chain
won't be reorg um and ensure that the
call was actually submitted and will
stay submitted and then we have a non
value for ensuring that every request is
unique as the way we're identifying
these requests is by hashing this entire
structure an exper field for uh when the
request should expire this is relevant
for um the user being able to reclaim
the reward if for whatever reason the
call was never submitted to the
destination chain um there should be a
mechanism for the user to to recover
those funds and that's what this xer
time stamp is if the call is not
submitted before the exper time stamp
then that's when the user can reclaim
and then we have these last two fields
for the pre-check contract so a
pre-check contract app address and an
arbitrary bytes array of uh encoded data
for that pre-check um this is for that
optional like arbitrary fil fulfillment
condition that should be true if this is
the zero address that is depicting that
we're not going to to use it and uh
we're not going to be doing a pre-check
step in today's demo but um figure it's
worth covering that it's it's there
anyways so then next up we'll do a quick
walk through of the Inbox and outbox
contracts so the outbox contract being
the entry point to the system um we have
one main function that we really care
about here request cross-chain call
that's where the user would submit the
request um and where the event would be
admitted that the fulfillers are
listening
for then we have a claim reward function
which is where the fulfiller comes to to
claim their reward after successfully uh
fulfilling the request and that calls
into the pro contract here on this line
and so this contract is again what we're
about to implement uh it is expected to
revert if the proof fails uh so there
there's no no return value or anything
here and then lastly the cancel request
function so this is like after the expir
time stamp if the reward has not been
claimed yet then the user gets to to
reclaim
it on the destination chain side we have
the inbox contract um the main piece of
information we care about here is this
fulfillment info struct so this is that
execution receipt that should be created
in storage and uh that will be the
target of the nested storage proof
validation um the whole point of of the
the the storage proof there is to prove
that this struct exists in storage for
the specific request and this is storing
the time stamp at which the request was
submitted as well as the filler address
that should be able to claim the reward
back on the um Source
chain and that gets created during this
fulfill function so we have all our
validation steps up here and then uh we
we route the calls here and if
everything's successful we're left with
the created fulfillment info struct
so this contract is fairly
simple um something a little bit more
interesting we have this State validator
library and if you in the future are
working on setting up a new prover
contract for a new destination chain
that's not currently supported by the
proposal um you likely would be
utilizing the State validator Library
the whole point of this is to abstract a
lot of the complexity involved with um
storage proofs away from the developer
um no need to reinvent the wheel every
time uh um so the way that this this is
set up there are two main functions that
we care about there's validate State and
then there's validate account storage
validate state is for if you're starting
from the beacon route on uh L1 and
you're trying to um verify the like the
L1 execution client State Route against
that Beacon route um that's what
validate state would do and then from
there using that the the the verified
State Route it would then prove uh
storage location for an account within
that state
because our example today is not using
Beacon Roots we don't need to use this
function but I figured I'd briefly cover
it the function we care about is this
validate account storage so this takes
in an account which is a specific
account within the network a state route
for the network and then a handful of
these account proof parameters and using
these account proof parameters which are
specified storage key an expected
storage value and then an account proof
and storage proof the account proof can
be thought of as the path down the state
try from the state route to the specific
account we care about and then the
storage proof would be thought of as
like a path from that account's storage
route to uh the storage location that
should that exists at storage key and
should be storing storage
value so it should be noted that all of
the the values in um the state try are
keyed by the hash of the ethereum
address of that account so that's what
we're doing here here we're uh deriving
the account key and then using that we
can do a merry.
getet to uh return an
encoded account an encoded account is
basically an encoded array of the
account metadata that I went through in
the slides earlier that have the the
nons the balance the storage rout Etc so
from that we can extract the storage
route and then using the storage route
we can verify that storage location
using the storage proof that exists in
the account proof progams struct that I
just went
through so at a high level that's how
that's working um there's a directory in
here called provs this is what we're
about to implement so we'll be coming
back to that in a
second just real quick before we dive
into the implementation details there um
I want to do just a quick summary of
what offchain services are running here
the demo is the app that uh is
facilitating the nft mints so we'll be
implementing some details in this
directory um but then these other two
directories are surrounding services
that are needed for the full system to
run locally the Sinker is in charge of
sharing State representations
bidirectionally between the mack L1 and
the mack l2s um and then the fulfiller
is the offchain agent that's listening
for requests and will uh validate their
requests and ensure that the incentive
uh is is enough to um to compensate them
for their time and we'll respond
accordingly and submit the request and
then we'll be generating a Full Nest
storage proof that gets validated
against the contract we're about to
implement and if that checks out we'll
be able to see the fulfiller claiming
its rewards in in real
time so with all of that being said um
we have enough here to dive into
beginning to implement a pro contract
um I have a handful of imports just set
up in here already just to save the time
from typing them out um you'll notice
the first import is an iover interface
uh so we can start here taking a look
and what it defines is a single function
and this is all the approver contract
needs because this is the the function
that the reward claim function from the
outbox contract is going to hit so we
can start by literally just copying this
entire thing into um into our prover
contract to initiate the implementation
of that function so I will replace this
comment with that function declaration
and uh add empty curly braces here
so oh and then we can extend that
interface is I
appr to take a quick uh skim through the
comments here that are explaining what
validate proof should even be doing um
it validates storage proofs and verifies
fulfillment okay makes sense it should
revert if the storage proof is invalid
also makes sense it should revert if
fulfillment info is not found at inbox
contract storage key on the specified
inbox contract um that is
kind of interesting here it should be
noted that the the storage key like I
was saying before is derivable from a
network that doesn't actually have
context of the destination chain and
because of that this is being done in
the um outbox contract before this
function is hit so this is not coming
from the offchain fulfiller we can trust
value lastly it should revert if the uh
fulfillment info time stamp is less than
the finality delay seconds amount of
time from the current destination chain
block timestamp so this is that that uh
destination chain reorg protection that
I was mentioning earlier um we need to
ensure that the finality delay second is
not currently like still in
progress then we have a note about that
the implementation should vary by
destination L2 this is due to the the
lack of standardization around how l2s
uh post their state representations to
L1 like I was saying um and then a quick
summary of the input parameter that we
have to work with here so inbox contract
storage key I just kind of mentioned is
the storage location in the inbox
contract on the destination chain where
we expect the uh execution receipt to be
next up is the Fulfillment info um
struct so this is that uh exact
execution uh receipt that should be
existing at inbox contract storage key
on the destination chains inbox contract
then we have the initial request uh that
came from the user and then we have an
arbitrary encoded proof data byes
array this is because of the fact that
um like I was saying before the lack of
standardization around the state the
state posting um there could be subtle
differences in the exact data that is
needed for the prover to verify that
state so there's no enforced structure
to this data at the outbox level this is
being implemented here within the prover
so we'll start to set that up uh in just
moment okay so with all of that gone
through we have enough here to start to
set this up so we can think about uh
what the steps are for validating a
nested storage
proof for starters we'll want to enforce
a structure to proof data so we can
decode this into some defined um struct
that we'll we'll Define in storage up
here so uh decode proof
data next with the decoded proof data uh
we can use some supplied data to uh
trustless access the beacon route from
L1 so I want to query L1 state
representation in a real Network this
likely would be or if the network is
supporting EIP
today's example it's the state route
directly so I'll just make a brief
comment explaining that um in real
Network likely be Beacon route in 2 days
demo State
Route okay so then step three um once we
have a state representation for L1 um
using L1 State
Route we'll verify uh storage location
on L1 and that storage location will be
the destination chains rollup contract
so verify storage Lo
in DST chains rollup contract on
L1 step four we'll need to verifiably
link a destination chain state route to
that uh yeah let's see using L1 State
Route verified storage location this
should be DST chain State
Rep we'll need to use that verified
value to link a state route for the
destination chain um so we can do that
as its own step here um
verif
link to uh chain State
Rep after that step we should have a
verified state route for the destination
chain so then we can essentially repeat
step three again so this would be using
L2 State
rot
verify execution
receipt in inbox contract on DST
chain and then lastly the only step that
we haven't covered is the uh this revert
statement that's saying if finality
delay second is still in progress this
function should be reverting so we can
check that as our final step whoops
step
six revert
if finality delay seconds in
progress okay so if we can successfully
set up these six steps then we should be
good to go to verify these nested
storage
proofs if we take a look up here you
might have noticed that uh this contract
is expecting to be deployed with an
address in the Constructor this address
is for the beacon Roots orle contract in
a live Network you wouldn't have to do
this um because thep
pre-compile address that you could just
hard hard code into your contract
storage but for this to work in both
tests and deployed to our local network
um I have it being deployed with the
address specified here so as our first
step we can store this as an immutable
variable in storage so this will be
address
private
immutable and then call it Beacon Roots
Oracle something like that Beacon
roots and then assign that within the
Constructor and then if we start to
think about how these steps are are
working um the first step being that we
want to decode proof data into some
specified structure that we're going to
Define we you can start by defining a
struct for what that structure should be
so uh for this context we should call it
um this will be a
struct rip 7755
proof and the compiler is going to be
mad about the struct being empty but
we'll come back to that in a
second we can set up this first step uh
with that in place by decoding the proof
data into a local variable that we can
call proof that is um adhering to this
RP 7755 proof struct so if we copy
this paste it here this will be in
memory is equal to ai.
decode proof data and then pass in the
name of the struct as the second
argument here and then this will decode
the proof data bytes into whatever
structure we Define at the top of the
file
here so
for step two we want to then query the
L1 state representation um this is going
to come from that Beacon Oracle contract
from the rollups directory that I
covered briefly so if we pull that up to
take a look at the storage layout here
of how exactly we should query that um
this has a fallback function in here and
that's to mimic the um the interface
that would be used to query a beacon
rout from like the real Beacon Roots
Oracle contract on a live network uh and
all this takes is an encoded block
timestamp so that's actually the first
piece of data that we need to add into
our RP 7755 proof struct is we need to
know the L1 block Tim stamp that we're
um going to be using for the proof so we
can add that in as a u
timestamp and then using that we can set
up a static call into the beacon Oracle
contract if you remember we have the
address stored as the IM able variable
here so we can take this copy
that and under step
two paste that that'll be
uh yeah Beacon Roots Oracle you do
static
call which is like a low-l call but kind
of like a view function where it's
expected to not um mutate any state in
the destination address that you're
calling so uh and then we're passing in
the encoded block Tim stamp for the L1
chain which we just added to proof so
this should be available via ABI do
encode with proof.
L1 timestamp pass
in
whoops this static call will return a
tuple where the first value is a Boolean
so we can call that bu
success and the second value is uh bytes
array and memory so bytes memory data
with any low-l call in an evm chain you
need to confirm that success comes back
is true because if something weird
happens with this address or the static
call fails for some unexpected reason um
and success comes back false we need to
uh ensure that we revert the transaction
here so uh for that case we can add a
custom error at the top of the file for
if um the the static call fails we can
call it
error Beacon root Oracle call
failed copy that and then underneath
this line we can do if not
success revert with that custom
error so if we get past this if
statement then we have a returned um
data bytes array where the data is
representing an encoded um version of
the state route for L1
so after this if statement we can then
decode data into a bytes 32 State root
so this would be bytes 32 L1 State
root is equal to another ai.
dcode with uh data passed in and then uh
the data type is bytes
two so so at this point we have an L1
state route that we can then use in a
storage proof to verify something about
the state of L1 um and that's exactly
what step three is laying out here so
using L1 state route we want to verify
the storage location um in the
destination chains rollup contract on L1
and this is going to be the state
so in order to get some more context for
how that should
work uh let's take a look at the RO up
contract because that's where the
destination chain will be posting its
state representation so that'll be
inside of this rollup
contract what's kind of interesting here
is in a lot of live networks the exact
storage location that the state
representation is going to exist is not
necessarily um known at the time of
request um in that case the request just
knows the storage slot maybe where the
data structure is located so like in
this example the mapping storing output
routes exist at uh storage slot one so
in this context the request specifying
the um destination chains storage
location for their rollup contract on L1
would just be specifying storage slot
one and then we'd have to take that and
derive uh the location of the value for
the mapping based off of the destination
chains L2 block timestamp so that brings
us to the next piece of data that we
need for this proof is it's going to be
the the block time stamp for the
destination chain um so we can add that
as another U 256 instead of the
proof and this can be L2 block
timestamp by the way for anyone
following along try to stick to the
exact names I have here for the um
fulfiller proof to work properly um the
logic by itself should should work fine
either way but in order for this to be
compatible with the the surrounding
system we have to we have to use the
correct names
so if we have the L2 block Tim stamp
here then we have enough to um derive
the storage location of the output route
associated with that block Tim stamp
inside of the rollup contract so how do
we do that if we take a look down here
so for step three we're going to be
using the L1 State rout and this is the
first example of an actual storage proof
that we're going to
use so this is where we would maybe want
to to take a look at that State
validator Library again because this has
a bunch of utility functions for um
facilitating storage proofs
directly be namely being this account
proof parameter struct this is going to
come in handy um and then that second
function I mentioned for validating
account storage so um we'll actually be
using this function here this takes in
an account a state rout and then a proof
parameters that should be provided by
the fulfiller so we can start to set
that up now starting with state
validator
and then validate account
storage my autocomplete added the names
of the variables here so for the account
what what's the account here this is the
rollup contract for the destination
chain and if you remember from whoops if
you remember from the stru file that I
walked through at the beginning one of
the fields that is specified by the
requester is this L2 Oracle address and
this is exactly the account that we care
about for this first storage proof so so
we can pass that in here um this is
going to come from request which is
being passed in so this will be
request.
L2 Oracle for the
account the state rout is the L1 State
rout that we just decoded here so we can
use this for State
rout and then the account proof
parameters uh this is this account proof
parameter struct inside of the state
validator this is going to be supplied
by the offchain fulfiller so this is the
next piece of information we need in our
proof struct so if we copy
this add it as a third argument in the
proof struct or third field oops um this
will be state validator do account proof
parameters and we're going to call this
one DST L2 State root proof or
Rams so then we can copy that variable
name and this will be the last argument
passed into our validate account storage
function so this will be proof Dot and
then that copied field
name if you take a look at the validate
account storage function here you can
see that it returns a Boolean value um
so we need to ensure that the Boolean
value returned is true so we can capture
that in a local variable here uh we can
bu um is valid L1 state
is equal to the state validator validate
account
storage and then for when it's not a
valid L1 State we can define a custom
error up
here this will be error invalid L1
State copy
that and then
if not is valid L1 State we'll revert
with that custom error
and there we
go as uh all right so what we have
Happening Here is after this step we
should have a verified um storage
location in
L1 to jog your memory on the prams that
are being passed in by the fulfiller
there is something kind of fishy
happening with the way we currently have
it set up these account proof parameters
specify an exact storage location and
expected value um so if this check out
and returns true it means we've
successfully validated that location but
what if that location's the wrong
location like what if it's not the state
that would be a problem so um this is
where we'd want to override the storage
key um we could either derive what it
should be and confirm that it's
equivalent or we could override it um
for this example we we'll override it
but uh maybe there's a a subtle gas
optimization one way over the other um
but for St
will want to create a helper function
for deriving what the L1 storage key
should be so we can create that down
here as a private helper
function derive L1 storage key this will
be a private
Pier returns bytes
memory because as you see up here the
storage key is a by string not a bytes
um yeah so this is the storage key of
where the state state representation
should be in the rollup contract on L1
so we can take a look at this rollup
contract again to see uh how that
storage layout is set up we have a
mapping located at the first storage
slot which likely is going to be the um
inside of the stru file this likely is
going to be the L2 Oracle storage key so
I would expect this to be the bites 32
representation of the number one um and
then we can take that and hash that with
the L2 block timestamp which under the
hood is what solidity is doing to
generate the storage location for the
value that should be um keyed by the
block timestamp so that's exactly what
we can recreate
here in order to do that we need a
couple of pieces of information here one
of them is the L2 Oracle storage key
which comes from the request so we can
pass in the request here copy this whole
thing pass that in and then the other
piece of information is the L2 block
timestamp which if you'll remember we
added to the uh proof struct up here so
we can pass that in as well so if we
copy this
declaration we can paste that here as a
second input
argument and then so what does this
return so this is going to return a
derived value for the storage key where
um the L2 chose output root should exist
that is going to use so we'll return an
ai.
encode
packed with the block time stamp passed
in so this is going to be proof.
L2
block
timestamp and then um the storage key
location so then it's going to be
L2 Oracle storage
key so this concatenates them together
into a single B array we now need to
Hash this to generate the storage key so
I'll wrap that whole thing in a catch a
function and then one final step here
because catch 256 returns a bytes 32 and
we need this to return uh bytes memory
we just have to wrap this in one more
encode and that should be all that we
need to derive the storage location for
the L1 storage key so now we can close
these and then use this function to
overwrite the storage key that gets
passed into this validation
um so this will be proof.
DST L2 State
root proof prams do storage key is equal
to derive L1 storage key where we pass
in uh the two input parameters of
request and
proof okay sweet so at this point we now
have a verified value in the uh rollup
contract for the destination chain on L1
um we've confirmed that it is in the
correct location so we can trust that
it's the proper state representation and
then we can uh move on from there so the
next step here is to verifiably link the
destination chain state route to the
destination chain state representation
um if the destination chain is directly
posting their state route this is
unnecessary um we just need to make sure
that we have a verified State rout here
um so in this example because we're not
directly posting that it's a hash
of uh block Tim stamp and state route we
need to recreate what this output Ro
rout should be so
um we can rederive that with a bytes 32
uh for a local variable byes
derived
L2 um output rout is equal
to Kack
basically just recreating this line over
here in the rollup contract so this is
going to be an ai.
encod
packed and inside of the ABI docoda we
want to pass in the block Tim stamp and
a state route but at this point we don't
have a state route to use so that uh
would be the perfect now is the perfect
time to add that as the next field in
our RP 7755 proof struct um we would
expect the fulfiller in this case to
supply what the destination chain State
Route is and then we can use that to
rederive um the the state representation
that was verified using the first
storage proof and if they're equivalent
then we can trust the past in L2 State
Route so this will be a byes 32
root and we need to pass these arguments
in in the same order that they're passed
in over here so we'd start with the L2
block Tim stamp so this will be proof.
L2 oops L2 block
timestamp and then we'd want to pass in
the state root so proof.
root okay so now at this point we have a
rederived uh output route for the
destination chain in the case that this
doesn't equal the value we just verified
we'll create another custom error for
that uh to revert in that case so we can
call that an
error uh in valid L2 State
root copy
that and then we need to compare this to
the storage value that we verified in
this step so that'll be
um if derived L2 output rout does not
equal proof.
DST L2 State root proof
prams do storage
value then we revert with that custom
error and this is yelling at me because
the storage value is a a byes string and
this is a byes 32 so uh because we'd be
expecting them to be equivalent we can
wrap this in a byes 32
for the type safe uh yeah properties of
solidity and one other thing I'm
noticing here this is kind of just like
a personal preference for me but uh the
State validator Library up here because
we're using it on a specific account for
solidi purposes we can actually bind
that library to the account to just
improve the legibility of this this line
make it a little bit more succinct so
I'm going to do that but that's totally
just a personal preference so we would
add a line at the top of the Prov
contract that says using state validator
address and then what that allows us to
do is to copy this request.
L2 Oracle
and remove it from the function call and
then paste it here instead of state
validator and then this is doing the
same thing but it's just a little bit
shorter okay so at this point we have a
verified um destination chain store or
state route
now we can use that to basically redo
step three but now the account we care
about is the inbox contract on the
destination chain so what that's going
to look like is uh a bu is valid L2
state is equal to um and then to jog
your memory again on the structure of a
request we actually have the inbox
contract being defined by the user when
they submit the request so this address
is going to be the address that we're um
verifying State against so this will be
inbox contract dot verify
what's it called again oh validate
storage and in here we need to pass in a
state root and another instance of the
proof
programs so the state root here is
passed in from the proof struct and at
this point we verified that this can be
trusted so we'll um use that value so
this will be
proof.
L2 State root and then we need to
um add another instance of those proof
prams this time for the inbox contract
on the destination chain so we can
duplicate this line and then instead of
calling it DST L2 State root proof
programs we can call it DST L2 account
programs and then copy that field name
down here for the the second storage
proof we can pass that in as the second
argument so this looks like proof dot
that destination account proof progams
field and then for the case again where
is valid L2 State comes back false we
need a custom error to to throw as a
reversion in that case so we can Define
that up here error invalid L2
that and this will be so if not is valid
L to
State revert with that custom
error
cool and then so if you remember from
the first storage proof we had an issue
trusting the storage key that gets
passed in from the fulfiller um you can
assume that we have the same issue in
the second storage proof and we do
luckily it's a little bit EAS easier to
solve on this side of things because um
like I said at the beginning of the
walkth through here the out the outbox
contract red derives where that storage
key location should be already and that
gets passed in so we can just reassign
the storage key value with this passed
in inbox contract storage
key uh we'll do that above step five so
this will be proof.
DST L2 account proof
prams this time.
storage key is equal to
inbox contract storage stor
key and what that's going to do is
ensure that we're uh verifying against
the correct storage location where the
execution receipt should exist on the
inbox contract on the destination
chain so at this point we have a fully
verifiable proof um the last step is we
just have to confirm that finality delay
seconds is not still in
progress we have uh the receipt being
passed in here so we can use that for
check and for when it is still in
progress we can add a custom error at
the top this will be our last error so
this will be uh
finality delay seconds in
progress copy
that and then down here at the bottom of
function if fulfillment info.
timestamp Plus
finality delay seconds is
greater than if you'll remember for uh
the proof we defined the L2 block time
stamp up here this is exactly what we
need to use um for this time stamp based
protection so we can do proof.
L2 block
timestamp if that if the time stamp at
which it was submitted plus the uh
configured finality delay seconds is
greater than the time that we're using
for this proof
then we can't accept this proof because
final finality delay seconds is still in
progress so that's what this line is
doing so we'd
revert with that new custom error
finality delay seconds and progress and
then cool that's um all of our
steps but there is one final piece of uh
data connection that we're forgetting
here and that is stemming because of um
well we've confirmed a specific storage
location in the inbox contract on the
destination chain and then we confirmed
a p in receipt uh satisfies that
finality delay seconds requirement but
we did not confirm that that receipt
that we're using for this final check is
the same value as the one that we just
verified so uh we need to make sure that
the storage value for the second storage
proof is equal to the
encoded execution receipt that we're
using for this time stamp um check in
the last step and so that represents the
final piece that we still have to set up
to um secure this thing we can set up
the encoding of the Fulfillment info
struct as a separate private um helper
function so this will be let
see this will
be what do we want to call
that
encode fulfillment info
okay so for encoding fulfillment info we
need to pass in the uh struct that we're
using for the validation up
here and um inside of this it's a simple
encode pack so um return ai.
packed whoops with
fillment
info.
filler and then
fulfillment
timestamp passed
in this is because of the struct packing
rules and um solidity storage we have to
custom encode this struct here um if I
show you the definition of the struct in
the inbox contract again we see that it
has two Fields time stamp and filler the
time stamp is a 96 and the filler is an
address so this can get packed into a
single U 256 slot but the way that it
gets packed or the ordering that it gets
packed is in the order of the uh defined
fields and it uh packs them into the
lowest value bits first so the time
stamp actually ends up on the right side
of the storage slot and then the fillers
on the left so in order to recreate that
um alignment we have to uh use an ABI
codea here instead of uh where we pass
in like the the fields in reverse order
instead of just doing ai.
code and
passing in the entire struct we would
have it in reverse order in that
case so using this function now we can
override the storage value for this
final storage proof so this will be
DST L2 account proof programs.
storage value is equal
to encode fulfillment info we pass in
info excellent
so that should be our first pass at a
full implementation for validating one
of these nested storage proofs um we can
now see if this is compiling so if we CD
into the contracts directory can run a
forge well I like to format it properly
first and then we can do a forge
build to check if it's
compiling it
is um so now to check this I have a test
file in here with mock data from
um from a working system it's commented
out just to prevent compiler issues with
the initial like structure of the
project so we can uncomment
this and run a Forge test to make sure
that we did did Implement that
properly it'll recompile recompile this
test file and then okay cool it's
passing so this is using a previously
generated proof um that adheres to the
structure that we just set up in that RP
being proven against a specific storage
route or a specific state route that is
being assigned here in this commit
Beacon root function in the beacon or
contract um so because this is passing
it's a it's a good sign that our
implementation is working
properly so that wraps up the onchain
implementation piece um at this point we
should be good to take a step into the
offchain world um and look at the
integration for this nft minting um
site so I'll close the contracts
directory for now although we'll be back
here shortly to reference um different
function signatures inside of the
services directory uh we care about this
demo directory so if we take a look in
here a brief walk through it's literally
just like a backend like server script
to run it's going to just tell you what
it's doing um if you yeah it'll it'll
display your current nft balance for the
um for the nft contract that's going to
get deployed we're calling it deployed
on a mark arbitrum chain and then the
user is going to be minting it from
moach base and so it'll be displaying
your nft balance on moach arbitrum your
current eth balance on mock base what
the price is of the nft um which I think
I have hardcoded as one eth in the
deployment script this is using local
Anvil nodes so using um easy numbers is
pretty easy uh and then lastly it'll
prompt you for like once you hit enter
it'll trigger minting the T and then we
can watch the fulfiller in action
generating its proof after the fact um
which gets uh verified against that
proof or contract we just set up so
there's not too much for us to change
here this is just I just wanted to give
you a rundown of uh what exactly it is
that's happening what we care about is
inside of the SRC directory there's a
client file called clients.
service um
this is all in typescript if anyone's
familiar there's a function called RP
that is completely empty so this is what
the uh developer needs here we have to
set this up to be an RP 7755 request um
to be able to integrate with the cross
chain call and um close the loop for
this minting process so we can start
here by setting up what this request is
going to look like um to do that it
would help to have the Str file up here
as a
reference um so I'll open that up
because actually before we dive into
that as a refresher in the outbox
contract the function that we care about
as the entry point is this request cross
chain call which accepts one input
argument and it's a cross chain request
so really what we need to build here is
a cross-chain request with all the
correct Fields um so that's what I I
want to show you
guys so to start with this
implementation we can get a um an
outline of what this request is going to
look like as well as the the lowle call
that we need it to do to facilitate so
we can start with uh const calls it's
going to be a it's a batch but it's it's
just one call but it still needs to be
set up as an array because it's uh uh
meant to be able to support a batch of
calls and then we'll have a const
request which will be an empty object we
can start by just getting the field
names in here um I'm just going to
assign them all as empty values to start
just to motor through this and then we
can go through each one individually to
make sure that we're setting it up
properly and um explain it all as we go
so we need to add Prov contracts and
again I'm just copying everything to try
to prevent some silly typo
mistake um so just bear with me for a
second pass in the inbox
contract L2
Oracle L2 Oracle storage
key reward asset
reward amount we initialize a zero
finality delay second initialize a zero
we'll come back through this in a
second nons is
zero xur zero and then the final two
pre-check related fields pre-check
contract and pre-check
data and then for the individual call
that we want to set up here uh this just
takes in three parameters there's two
data and value so we can take
two empty
string
data and then
value okay so we have our structure
outlined here now we need to make sure
we set up each of these fields um
properly and it helps to have an
understanding of exactly what each field
is which we now all should um in order
to help with this I have inside of this
common directory there's a constants
file that has a couple of um chain
configs in here one for Mock arbitrum
and one for mock base so this is going
to be very um helpful for uh where we
can pull the addresses from assuming
everyone deploys the contracts using the
deployment scripts that are provided uh
these addresses are I mean they're
they're deterministic so they're if
they're deployed in the right order then
these addresses should all be correct um
which is why they're pre-populated in
this in this file uh even though the
contracts are not currently deployed on
our local
network so okay um let's start filling
these out for calls the destination
address here uh again what exactly is it
that we're trying to do uh we want to
Mint an nft so the two address is going
to be the nft address which we have up
here as mock arbitrum nft address so at
the top of this client service file we
can import that so this will be
import uh mock arbitrum nft address from
do do common
constants and then we can copy
that into our two
field data is going to be the encoded
call data for the mint function I'm
going to leave that for the last step
we'll come back to that in a second
value um as you see here this function
is being called with an address this is
going to be the user address receiving
the nft and then the mint price which is
the mint price of the nft denominated in
way so we can just pass in this mint
price as the value directly
um yeah so this will be mint
price and then now as we start to fill
out the request the requester is pretty
self-explanatory like I said the address
of the of the requester is being passed
in so we can use
that calls is going to be this calls
array prover contract is what we just
implemented this will be the ad the
contract address on the source chain
which in this context is is mock base um
of the prover contract that has been
implemented specifically to validate
requests or validate State about the
mock about the destination chain which
in this context is mock arbitrum so if
we look over here um there's only one
defined in each but this is set up in a
way that we could Define multiple Pro
contracts for each chain um but this is
pretty straightforward so we'll start
with
um well first we have to import the
chain configs here so if we go back up
to the top of the file we can import
that from the same file that we just
imported the nft address
and then down here in our mint function
we can destructure the mock arbitrum and
mock base configs from uh the outer
object that's containing the the chain
configs so this would look like const
Curly braces with Mock arbitrum and mock
base is equal to chain
configs and then now we can access all
of these config Fields directly on Mock
arbitr and mock base so for the approver
contract because this is the base side
of of the equation here this will be
Mach
base doover
contracts
prover the destination chain ID is going
to be mock arbitrum chain ID so we can
go Mach arbitrum dochain
ID inbox contract is going to be the
mock arbitrum so this will be mock
arbitrum do contracts.
inbox L2 Oracle is the rollup contract
on L1 for mock arbitrum here so this
will be moach arbitrum dol2
Oracle same thing with the storage key
or the L2 Oracle storage key this is for
the L2 Oracle contract for Mark arbitrum
so we'll grab that from the same place
be moach arbitrum L2 Oracle storage key
and then for reward asset for this
example we're just going to use native
currency because we're um sending native
currency for the mint function but it
doesn't necessarily have to be one to
one like that um we could be passing in
some erc20 and then expect the
fulfillers to do the necessary
conversions offchain to make sure that
the erc20 is enough value to account for
the native currency that's being passed
in here but it's a little bit cleaner
for the demo here to just keep it one to
one like that um so uh that's what we're
going to do
the ERC that I mentioned earlier that
had a spe specific uh asset that
represents native currency um is
hardcoded here so that's what this like
oxe address is um and this is another
exported constant from this constants
file so we can copy that and add it to
the import
statement and then pass that in for
reward
address reward amount again to to remind
you is is meant to cover all of the
value from the calls plus whatever the
the destination chain gas cost is plus a
tip for the fulfiller um the exact
mechanism to calculate what that Surplus
should be can be pretty complicated um
but for the sake of today's demo doing
it in a simplified context if we add an
extra 2% to the request that should be
uh more than enough for it to be
profitable for the fulfiller in our
local network so we'll do it that way so
this will be uh reward amount is going
to be the mint price which is already in
way to remind
you we'll add a 2% buffer so we can do
that with big in in in typescript by
multiplying it by something like 102n
for big int and then dividing it by
it all right so then for finality delay
seconds in a live Network this will
likely be something on the order of days
to a week to to ensure uh protection
against reorgs on the destination chain
because this is a self-contained system
that is going to run locally on your
machine we have the flexibility and the
freedom to make this really short and
because I want this to be a responsive
demo and for us to see everything
happening uh in real time we'll make it
just 10 seconds um so what this is going
to result in is like a 10 to 15c delay
after the request is submitted before
we'll see the fulfiller actually
generate the proof and claim their
reward not doesn't matter cuz that's
going to get over written in the outbox
contract it's just like a canonically
incrementing nons for every request xer
doesn't really matter too much for this
demo um we can if you see over here in
the constants file we have a onewe
constant we can just add one week to the
current block time stamp um we just need
like whatever this value it is is it has
to be greater than um the finality delay
seconds in the future from like now um
plus some extra cancellation buffer
period perod which is hardcoded as a
constant in the outbox contract storage
as a full day so um for the demo just to
get a valid value in here one week
should be more than
enough so this will be date.
now so in
JavaScript if you're not familiar has a
global date object that if you do date.
now will return the Unix Tim stamp but
in milliseconds and in solidity it's in
seconds so we have to divide that by a
th but solidity doesn't like decimals so
then we have to floor that to the
nearest
integer and then from here we can add uh
the onee
constant so we'll add that as another
import from this constants
file and then use it down here for the
xir timestamp We'll add one
week okay and then the last two fields
are this um pre-check contract and
pre-check data
which like I said earlier is an optional
like fulfillment uh condition that the
requester wants to be true uh because
it's optional we're not going to be
using it today but
um yeah so in order to not use it we
have to pass in the zero address and
there's a a helpful constant from uh the
web3 library I'm using VH um that is
just called the zero address so we can
import that at the top and then use that
as the pre-check contract address in
and then last but not least pre-check
data in order for it to pass the
offchain validation that vhm does we
just have to add an ox but this can be
anything it just has to be some kind of
arbitrary bite string because we're not
using this step it doesn't really
matter okay so that just about covers
all of the requests the only thing we
haven't done yet is encoded the call
data for um the the mint function on the
nft contract
so to uh reference the nft contract let
me pull that
up it's just a simple mint function that
takes one input argument um which is the
two address that should be receiving the
nft uh there's another helpful function
from vhm called encode function
data that we can use for encoding the
call data here
um we can Define this as another local
variable above the calls constant so
this will be const
encoded call data is equal to en code
function data and this takes in actually
before we Define that we'll just add
this in as the value for data encoded
call
data um and then now for encode function
data this accepts one input parameter
which is an object with a couple of
fields that are necessary here the first
one being uh the ABI for this nft
contract which is actually already being
imported uh as nft ABI for some of the
other help helper functions that are
defined in this class so uh we can just
use that so this will be ABI colon nft
ABI I don't know why I closed that
contract we still need
it next up we need to define the
function name that we're encoding data
for so that's just simply mint so if we
copy that this field name is function
name
with mint passed in and then because
mint accepts one input parameter we now
have to specify that with a field name
called args so this will be args which
is an array of the input parameters and
in this context it's just the two
address which is passed in here as
address and that should be it for
encoding call
data all right so at this point we have
a uh fully set up rip 7755
request um now we need to set up the
function call to submit the request so
what does that look like to give you a
little bit more context on how this
class is set up we have uh something
called a wallet client in like as a
local variable here and if you're
unfamiliar with vhm as a web3 library it
uses things called public clients and
wallet clients the public client is for
like reading state from the chain and
wallet client is for writing state to
the chain uh this wallet client is
already defined in the Constructor so we
can just use it as is for um the target
chain that we are submitting the request
to which is mock base
here so this is going to be an
asynchronous call so we'll start it with
weight this.
wallet
client and the function name that we
care about here is WR
contract so under the hood
this this creates your um your your your
transaction and signs it and and sends
it to the
network this will return a transaction
hash if it's successful so we can store
that as
hash and then we need to set up the
configuration for like what contract
we're writing to what function we're
writing to what parameters are needed um
so that can be a single
um object in here
where we
Define for reference I'm going to pull
up the constants file
again we need to define the address that
we're sending the transaction to so
address this is going to be coming from
mock base because we're submitting the
request to mock
base uh the the contract we care about
is the outbox contract for the standard
so this will be mock base do
contracts.
outbox
next we need to specify the ABI for the
outbox so this can be we're going to
have to import this at the top so this
will
be
import outbox ABI from do slabi
outbox we all already have that
populated in this um
directory so we can Define that as the
ABI
here we then need to Define the function
name that we're requesting or sending
the transaction to um so if we pull up
the RP 7755 outbox contract over here
the entry point as I said earlier for
the U standard is this request
cross-chain call function so we can copy
that into function
name we then need to define the input
args so um as you see here it's just one
argument uh which is the cross chain
request
this is going to
be um the request that we just defined
here and then last but not least we need
to Define um any value that should be
submitted with this with this
transaction so that's going to be a
field called
value and in this context it's not
actually going to be mint price because
if you remember we added a 2% buffer to
the mint price as the reward amount for
this um cross chain call so the value
here should be request.
reward amount to
account for that
buffer and that should be it for setting
up the the contract send um the last
piece here is using a public client from
vhm we can um wait for a transaction
receipt to make sure that the request is
confirmed or the transactions confirmed
so we can do that with another await
call um in the constants file for the
chain configurations one of the fields
for mock base is a public client so we
can use that directly so this will be a
wait moach
baseu client dot um the function name
that we're going to use here is called
wait for transaction
receip and that takes in just one input
object which is uh the transaction
hash and in JavaScript if the field name
and the the value name that you're
setting it as are the same name you can
omit the colon and the the value so like
this is the same thing as this um so
I'll leave it like this for clarity and
if we get through this wait for
transaction receipt call then the
transaction should be successful so then
we'll log something
console.log um transaction
success okay so that should be our full
request um it's pretty straightforward I
just wanted to kind of give you a walk
through on all the different field names
and how they should be assigned and um
what the values mean and like how
they're fitting together um this should
be enough in place to run the system end
to end so if we take a
look in the root of the directory uh
this the root read me here there's a
list of commands for spinning up all of
these all the infra here to deploy the
contracts on top of and all of the
services that are needed to get
everything to work together so um we can
start by running these commands the
first thing we need to do is spin up our
local chains so if we open new terminals
that are each at the root of the project
we can open three in split screen side
by side and this is going to be meant to
represent the the mack L1 and then the
two Mack L2 chains so we can start that
with um there's a make file defining all
these commands if you want to see what
they're actually doing under the hood we
can run make start mock L1 in the first
terminal so this is like our mock L1
chain we can then run make start mock
base this will be our mock base chain in
the middle and then lastly we can do
make start mock arbitrum to run our mock
arbitrum chain in the terminal on the
right here so now with these three
chains running we have um we have our
our local chains running so we can
deploy our contracts on top of them
there's another make file command set up
for deploying the contracts in the
correct order that is required by the
offchain services here so we can open a
new terminal um the three blockchains
are still running in the background here
um I just have a new terminal running on
top of them we can run make setup
contracts and that's going to compile
and deploy all of the contracts to the
local network so that'll just take a
second while that's going we can copy
the make start um Sinker command so what
this is to do is start the offchain
service for sharing State
representations bidirectionally between
the mackl one and the mack
l2s uh and this one's pretty chatty so
we can now open a new terminal for the
final two terminals that are needed here
there's a ton of terminals I know um we
need to start the offchain fulfiller to
listen to in response to
requests uh so that's make start
fulfiller so now we have the fulfiller
listening we can do a split screen here
to now run the demo so to to run the
demo app and mint the nft we would just
run make demo so if we type that
in not too pretty but logs to the
console uh what it what it's what it's
doing here current state so we have
welcome to the demo U mint your nft the
Devcon nft on mock arbitrum we currently
have zero in um in the wallet address
that's being used for the demo here the
price is 1 eth and the current base
balance is almost 10,000 eth cu this is
uh one of the default um accounts on the
local Anvil nodes so now if we press
enter this is going to send that mint
request to the local network and we can
see if everything worked successfully
and it did so the transaction went
through we actually if we run this again
we already have the current nft on the
destination chain because the fulfiller
if you saw over here picked up on the
request almost right away and submitted
it because it validated that the um
incentive was sufficient and then now in
a second we should see something else
happen um because the finality delay of
fulfiller just did is it picked up on
the fact that it waited long enough and
it's now allowed to claim the reward for
that request and it generated this
massive storage proof here and submitted
that storage proof to the outbox
contract on the mack base chain and
everything was successful so this was
validated against the prover contract
that we just implemented
um and so if you take a look in the
fulfiller directory here um after that
ran it logged the proof into a Json file
so you can see exactly what the proof
was that it used to um verify that the
call was submitted so that's what this
file is and then inside of the SRC
directory there's a database directory
that is storing uh db.
Json which this
is the representation of the request
that it picked up on um that we just
submitted and then it has a rewards file
that it's tracking how many how much eat
that it's claimed in rewards so we have
a locally running like fully working
system uh end to
endend woo um yeah and I'm realizing
right now that the reward tracking is
not accounting for gas cost on the
destination chain but um nonetheless you
get the you get the
idea so that just about does it um if
you take a look here yeah like I said uh
if we run the demo again we now see that
the current nft balance is one because
the the nft was actually minted on the
destination chain as uh defined by the
encoded call data that we set up for the
Target calls um and then so if we run it
again now it would be just incrementing
from there so that does it for the demo
thank you everyone for coming and I'll
be hanging around for a little bit if
anyone has questions or if you want to
chat um the standard a little bit more
like I said we have an open source repo
for proof of concept here so if anyone
feels compelled to contribute we fully
invite you to uh contribute so thank
you e
it's
o up
e e
for I
oh I
oh d
Beau
a a
true
a e
t
m oh
h a
kind of I mean it's fine but since
okay yeah very good afternoon to all of
you present here so yeah we have reached
the final day of Devcon we have had like
pre-confirmation three full scale events
and the only question that I've been
getting is how do you make all of this
like Fast transaction confirmations yeah
yeah we get it but how do you make this
so yeah now on the last day uh welcome
to the workshop on designing an end to
end system for based
reconfirmations a quick introduction of
the speakers uh Ahmed go ahead yeah um
so my name is Ahmed butar I work as an
ethereum core developer normally I'm
also the product manager of Surge and
the technical lead for our
pre-confirmation
solution and I'm Anu I am working as a
blockchain engineer at nethermind and I
joined this industry like 5 years ago
mostly focused on defi but for the past
uh my efforts have been mostly
concentrated on based
reconfirmations so today this session is
a no code session so I won't be like
writing a line of code and then asking
you to copy it and repeat it like 100
times over I know most of you will leave
in like half an hour if I do that so
instead this is a session on design
thinking where we'll build the whole
concept from ground up and share exact
what exactly we did during our research
over the past 6 months
but if you are interested in looking at
the code then I have linked it below
it's Tao precom AVS repository which you
can find on the nether mine GitHub
page so since we want to build it all up
from ground up we have to start with the
foundational knowledge which is rollups
because the based in in based
reconfirmations comes from based
rollups just by show off hands how many
of you do understand what a rollup is
okay pretty much everyone that's great
well rollup is a scaling
solution and why do we need a scaling
solution we need a scaling solution
because the L1 is really slow the
throughput of L1 is not much and why
exactly is that the case well in a
blockchain blocks are basically a
consensus on state transition that's the
first section of the ethereum white
paper you have state a you put a bunch
of transactions and apply it to State a
which is like a Delta and you get a
state
B but now imagine millions of nodes
doing this every single Epoch now that's
going to make this network really slow
and that's a major
problem so what's the rollup way of
doing it well if processing State
transitions is the biggest issue on the
L1 what if we process these State
transitions off chain or apply these
deltas offchain and that's exactly what
a rollup does we have like you can have
a one single rollup node or an L2 node
since it's becomes a layer two that
applies applies this Delta of chain
processes the state transition and the
L1 is just an observer on the L1 you
have a rollup inbox contract and you
simply push this state transition and
the Delta maybe as a form of a blob or
in the call data in the image it's a
blob and the L1 is just an
observer and in the most basic form this
is what a rollup is
but is this enough well no because if
it's just one note pushing the
transition and the Delta how do we know
whether it's actually correct or not and
this is where the flavors of the rollups
come in optimistic and ZK in the case of
an optimistic rollup well you push the
state transition and the Delta and then
you just wait you just wait for someone
to prove you incorrect if you're correct
it's it's all good but someone can just
come by and say oh hey it's a proof
here's a proof this transition that you
posted is not possible with the Delta
that you posted and then you kind of get
slashed if you have some stake in
depends on uh what kind of process the
rollup wants to
do and arbitrum is an example of an
optimistic rollup I guess most of you
must have used arbitrum and then we have
ZK rollups in the case of ZK rollups
instead of waiting on for someone to
prove you incorrect the moment you push
the transition and the Delta you have to
prove Pro that this is
correct so it's called a validity proof
you're basically proving the validity of
transition but the point here is that
whatever time or computational effort it
takes to verify this validity proof must
be less than what it takes for the L1
itself to process all the data only then
it actually makes sense right so these
are the two variants for proving whether
a transition is correct or
not once again by sh fans how many of
you have heard of centralized
sequencing okay it's the most cursed
concept right now and just to give a
quick primer when you're making a
transaction on arbitrum you're not
directly sending the transaction to a
public mempool like when you're doing
when you are transacting on ethereum L1
instead it's going to an arbitrum
sequencer and it's a private server what
the sequencer does is it has complete
control over arranging or ordering the
transactions and they usually promise
that they will arrange the transaction
in a certain way we don't know whether
they're actually doing it or not but in
the case of arbitrium the promise is
that it's a first come first serve if
your transaction comes before that other
person we'll put your transaction first
in in the block but once again it's a
promise we don't know whether that's
actually happening or
not so let's get based and talk about
based rollups and pre-confirmation
well the base part is actually not a
different variant of a rollup so it it
doesn't stand beside optimistic or ZK
rollup instead based is a form of
sequencing just like we have centralized
sequencing we have base
sequencing and in the case of Base
sequencing the L1 proposer is the
sequencer you don't have a centralized
server sequencing the transactions
instead it's the L1
proposer so let's say we have Tao Tao is
a based rollup and in the case of Tao
the L1 proposal literally runs a tao
software alongside the usual consensus
and execution clients and whenever their
block comes in they literally just put
pull the blocks pull the L2 transactions
from public Tao M Pool they order it in
their L1 block and put it on the network
so yeah you basically are inheriting the
L1 security as well as the L1 liveness
because the L1 itself is your
sequencer so just a quick overview of
how Tao actually is arranged well you
have the rollups inbox contract that I
have been talking about and although Tao
doesn't really call it rollup inbox uh
this is the colloquial term Tao has like
a bunch of contracts that uh work
together and they just call it Tao L1
contract so that's the L1 component now
if you're running an ethereum validator
you usually run an execution client and
a consensus client right so in a similar
way if you want to run or be a part of
an L2 Network the proposer has to run an
L2 execution client or an L2 and an L2
consensus client so in this case tyo get
is the execution CLI which is a
modification of the standard go
ethereum and this is where you have the
mempool you have the actual L2 chain all
the blocks are formalized and you also
have the evm on the L2 Network and then
we have the Tao client which has some
subcomponents and this forms the
consensus client and it deals with
proving the blocks and proposing the
blocks whenever
required now today the most important
thing for us are block proposals because
that's where the whole concept of
pre-confirmation will be built
upon so how exactly block proposals work
in Tao or in a based rollup so well when
you're making a transaction using any
kind of standard wallet it goes to the
mempool or the public meol which is
offered offered by
Tao and every few seconds or depending
upon what algorithm the proposer is
using transactions are from the
mempool and this transaction batch forms
the actual Delta and when you're calling
the rollup inbox contract you're
basically calling a function which is
proposed block and you're just passing
this Delta
along now you might be wondering well
that's the Delta fine where's the
transition so in Tao it's a two-step
process the Delta is gone and now we
have the Tao PR which comes in later on
and just says okay remember that Delta
that was pushed uh a few seconds ago or
a few minutes ago you see this is the
transition that that Delta causes and
since Tao is a ZK rollup it pushes uh a
concise proof along with it like okay
this is the transition and this is the
proof that the Delta caused this
transition now the most important aspect
Tao
driver so once these l blocks are put on
L1 there is an block proposed event that
is released which shows that hey okay
this L2 block was put in the L1 contract
and whenever that block proposed event
is released Tao driver listens to it and
advances the head in get advancing the
head basically means you're formalizing
and putting an L2 block within uh the L2
Network and this is when the wallets end
up getting the transaction receipt or
confirmation so you see the catcher is
is that Tao driver only receives the
block proposed event every 12 seconds
that means when you're making a
transaction on Tao you get a transaction
receipt after 12 seconds which is huge
that's not ideal for a rollup or a
scaling
solution and that's very evident from
the DU analytics graph of Tao's block
times it's average between 12 to 24
seconds which makes sense it's
inheriting L1 block time that's not
ideal at all
so we need pre-confirmation and pre-
confirmations is not something new we
have already had it on arbitrum for a
long while and several other
rollups again show off hands how many of
you have transacted on
arbitrum and when you transact on
arbitrium you basically get a
transaction receipt like in a very small
period of time like half a second 1
second sometimes 2
seconds but the point here is that
arbitrum only posts blocks every 2
minutes on L1 so how are you getting
this transaction receipt immediately
it's because that's a pre-confirmation
they're giving you a promise that hey
see this is the receipt and we will be
putting this on the L1 eventually in Tao
you have to wait for it to put be put on
L1 but well this gives better ux for
arbitrum and bad ux to
Tao now what if we want to put
pre-confirmation on Tao it's really
tricky because in the case of arbitrum
we have one server literally one server
in one corner of the world just running
except ordering transactions providing
pre- confirmations easy in the case of
based rollups the sequencer is changing
every single slot the proposer changes
every single slot so well the sequencer
changes every single slot and then these
days we don't have the proposer building
the blocks the blocks are actually built
via a PBS pipeline like me boost by
flashs where Builders build the blocks
for you or for you as the proposer and
then you just propose the block which
which whichever Builder gives you the
highest bid you just take their block
and propose it you don't even have any
control over what's in the block so how
exactly will you put in base prec
confirmations with three layers of
complexity well we have done it and
let's start with the design
principles maybe a quick round of
questions if anyone has any questions no
okay take it
all right great thank
um okay so the first thing we wanted to
do was we wanted to not introduce
centralization again and the way we
wanted the um the idea here is that if
we wanted to do to introduce
centralization we wouldn't have built it
as a Bas rollup in the first place then
how are we going to solve this complex
problem
so let me explain how gateways work
first so gateways are basically
centralized servers that expose an RPC
for the user to be able to provide them
the precom they the the user sends the
transaction to the RPC and then it
selects which uh which uh transactions
to Su precom and then it it provides it
to uh it proposes that block to
L1 of course the confirmation receipt
that goes to the user is given like in a
matter of milliseconds between 100 and
course the ux is very cool but the
compromise is very
high now also like there is a uh uh
another concept here in prec
confirmation that is important which is
not all validator has signed up to
become pre-
confers and because of this you
sometimes have some validators who have
uh decided to register as a pre- confir
and some others that haven't registered
so the Gateway can provide
pre-confirmation for users and it should
it could it not necessarily will push a
block uh a propose a block for the L2 on
this slot but it could potentially push
it here and the way to do this will be
explained in a later stage when we talk
about um for inclusion
lists all right the other thing that we
wanted to focus on which was important
for us is that we wanted to use the the
existing transaction structure the
existing wallets we don't want to invent
a new um a
new a new like complexity to the to the
already existing situation when you are
sending transactions through wallets
um so some suggestions in the precc
confing space were like oh we should
potentially put an inclusion precom fee
premium so like what are you going to
pay the promer to to to so he can
provide you with this fast service or
and the base fee per gas for that as
well or for example an execution precom
yeah it's it's basically very similar uh
to to each other like they're all like
the same so what we decided is no we're
going to choose something that is basic
so we're going to choose the same exact
EIP 1559 fields which is the priority
fee so the priority fee pays for the
pre-confirmation the proposing and the
proving of that transaction and the user
does not have to worry about all of
these complex things other
okay it's not moving
okay all right so I'll start now
explaining what we
designed
so in Tao like explained we have the in
Tao we have the uh Tao client and we
also have Tao
G in Tao also we have before these
before we come to these we have the
contract
that receives that block
proposals
and so so what we did is we added a
something we call a pre-c confing
node and that sets
between uh the proposer and the
contracts and we added some contracts
one contract is the pre-confirmation
service contract that basically receives
the blocks that are coming from the
proner
and also um we added a restake a reor
staking contract that will basically uh
allow the proposers to
register uh as a
pre-con and by this these proposers
whichever they are any validator can
basically just run this set of software
as a side car to uh whatever they're
running for the validator so alongside
L1 you're just running these three uh
basically uh these three um Docker
Docker Docker images Docker containers
and then you are able to precom
transactions when your slot is
up so what H how how does this exactly
work so we have a loop that happens
every 3 second when when when when you
are chosen as the pre Comer for the
upcoming slot what happens is that you
as a pre-c confing node will Fitch the
transactions every 3 seconds from The
Tao proposer which will basically fit
them from
Tao the user will have sent this
transaction to the mol so there is no
centralizing aspect here you don't have
to connect to a specific aend point to
send the
transaction and every 3 second the
precon fer will sign this trans uh this
batch of transactions that it has
received from The Tao proposer and then
broadcast it to other pre-c confers
through
P2P oops
okay um okay permissionless okay so here
we we we we we look at okay so how do we
choose which of the registered prec
confers are going to be used or have the
right to propose these
blocks and this is when we use the look
ahead that is provided by the consensus
layer to know which exactly uh is the
proposer that has been registered in the
upcoming 6 uh 64 uh or like in the in
this Epoch and in the epoch after so in
consensus layer and chain you can query
the CL client for the existing uh Epoch
the current Epoch which which which uh
which proposer which validators have the
right to propose and for the upcoming
Epoch um so it provides you with a list
epoch that you want and so basically the
what we did is that we made the pre
precom node fish this list from the CL
client and push it to the
service and this way we know for example
that since this proposer is not
registered this proposer is not
registered we know that this proposal is
registered so then we choose this
proposal to uh be the one who is pre-
confing those
blocks this thing doesn't always work
let's just
okay um so then there is like with with
any system you have to have incentive to
act
correctly some systems depend on uh um
on only rewarding uh good behavior some
systems depend on uh punishing bad
behavior most systems or a lot of
systems depend on doing both so in this
case the precon forgets the
fees and the proposing
fees in return
he needs to precom and provide good
information uh and honor that prec
confirmations that he gave to the
users the way we check that is that in
the case the
pre-confirmation the way it's done is
that so let's say I precom a batch of
transaction and then I didn't end up
pushing this batch of transactions on
chain but I have already broadcasted
that I have pre-comp this batch of
transaction with my signature so what
would happen is another pre comfort that
was listening on P2P would then pick
this signature with the with the with
the batch of transactions and push that
to the pre-confirmation service contract
the pre-confirmation service contract
would check if this is a valid signature
for the pre PR comfort of this slot and
if it is then it will go and ask the
reaking or staking contract to slash the
signer and in this case um yeah the
there is also the slashing for the
incorrect uh look ahead because you fish
the look ahead from the CL but how does
the El know that this uh look ahead is
correct there is you can use um 4788
uh EIP uh which uh basically provides
you with the CL Beacon rout um and using
that you can push a proof If the look
ahead is incorrect and the promer who
sent an incorrect look ahead would be
slashed okay so uh before I move on if
if you guys have any questions it's it's
good to to have them now so y please go
ahead I have question first is based I'm
not yeah so the thing about 4788 is that
it provides you with the beacon route of
the parent block and not the current
block and because of this when the look
ahead is pushed I cannot in that moment
verify its correctness but after one
single block I can with the proof using
that it is not so this is why we opted
for this in the case that it was
possible to verify we would have
potentially opted for um pushing the
proof with the look ahead the problem
with that normally entail that you would
pay more because the proof needs to be
verified on
chain in every single submission whereas
if you do it in a fraud proof manner
only when someone is acting maliciously
that you need to do this so the cost
drops dramatically and there is
precautions to this so whoever is
submitting the look ahead will get
rewarded submitting the proof the fraud
proof for the look ahead will get
rewarded for this uh by uh the slashing
of the other pre
Comfort other questions yeah yeah you
back
to okay uh let me try to make this work
somehow
okay work please Okay no
Okay yeah over here
sure well not SL was one a
SL I was wondering um I mean here this
one is not opted in and this one is so
for example if iations from
someone okay so this is probably not
mentioned in this
presentation which is uh a problem but
hey sorry um so basically what based
rollups depend end on giving the user
the ability to always push
transactions on the L1 with permission
perm permissionless Le okay and that
means that there is no one who could
prevent the user from pushing a
transaction that could invalidate future
transactions that have been precom that
will be pushed later that have been
pre-comp um and this leads to execution
precom not being able to be provided and
the only solution that we have to that
is delayed inbox so pre comers are able
to push directly to the Taos smart
contract to propose blocks whereas
normal users who don't want to use the
pre-c confing system that is built and
want to push directly to avoid
potentially censorship uh uh by the pre-
comer even though this is a
decentralized solution it could
potentially have some type of censorship
so if they push their transaction to
this delayed inbox what happens is that
we wait for the pre-confirmation to land
and then we include those uh
transactions that have been pushed by
the user so in this instance just to be
clear uh any transactions that come in
slot uh will will go to the queue and
will not be proposed no it will not be
denied it will go to the que yeah
delayed yes it will be delayed till
after the the pre confer has uh pushed
his pre-confirmation and then it will be
included what if my pre confirmation is
dependent on1 ST which is like really
nice component
of
um yeah no
ume
L1 yes so if we engage a composability
in here then it could yes any state any
L1 State change could potentially affect
uh this uh L2 transaction that depends
on it and this is not a problem that the
solution is trying to solve
unfortunately so just like Ane yeah I
don't think I don't think like um as of
now there is potentially there's some
people working on this but I'm not aware
of any solution to this particular
problem this is a very good question
thank you
sir any other questions yeah go ahead
does this requ that at least
one yeah so I think this might be talked
about and in a later stage so I'm not
going to touch on it more but there is a
way for choosing a random pre- Comer in
the case that there isn't a pre Comfort
available for the next 64 uh block
slots any other
questions yeah go ahead um could you
touch on more about the so I'm doing the
pre Gateway is like a a subset of the pp
layer that's exclusive for pre and
that's how to interact mhm um this
immediately sounds like a Loosely coupl
system to me off the do you feel like
there's consensus required here to agree
on preon state like what happens if the
is to pull back to another like could
you unpack the
Gateway the
Gateway okay so the Gateway basically
buys the right from the proposers that
have registered at P confers to propose
at a certain
slot do need agree on like the for
example tip the US
provid um I don't think so no like they
can they can have varying tips between
one one one one one gateway to another
the problem is that with gateways is
that the gate the gateways will have to
compete in the beginning we might have a
couple of gateways out there the problem
with that is that it it normally con
people normally end up converging into a
couple of gateways that then would have
a monopoly so like two or one Gateway
that would then be dominating because
the idea here is that if a Gateway
cannot
secure uh uh verif uh validators or
proposers that are willing to sell it to
sell the Gateway their right to propose
these uh Tao transactions the Gateway
cannot uh operate would there ever be an
instance where pre pre compilations buil
on other
pre yeah so consens um you do and that's
why we have the P2P I'll explain that in
slide so when we said here sorry this
this thing is not that okay yeah so when
when we said that the precom node every
a batch of transaction and signs it and
then it broadcasts the sign prec
confirmation
Comfort blocks on P2P this is important
because anyone who's
listening can do a bunch of things first
they can advance the head of the uh of
the Tao so people can keep up with these
precon prec confirmation moving to a
safe head there sorry is it moving just
to a safe head it's not a safe head no
it's it's not even a safe head at this
point because it's basically a soft head
very soft head
as long as long as it hasn't been
proposed on L1 it's not fully safe I
mean there is financial precautions to
to the precon if he doesn't obey or
honor these prec confirmations but they
can always software can always fail or
um they they could potentially have
other incentives so it's a very soft
head but at least you get consistent
block times which is a better user
experience than what you get right now
um I mean ano said that trans actions
normally take 12 seconds and on Tao
sometimes they take 20 seconds so there
is some kind of extra delay it's very
long
time um any other questions before
moving on sorry I just wanted to
understand the consensus at the payto
pay L that you were describing
um so what what do you mean the
consensus so my original question was if
you have um pre- confirmations being
built upon by sorry new pre conf being
built upon the state of previous pre
confirmations mhm how does that that
like consensus is needed there for
between two different proposes that the
pre- confer that comes so let's say that
okay let's um let's say that all of
these are pre- comers and this one is a
pre- comer and has been pushing um it
pushed basically four blocks it precom
first one second one third one fourth
one and then it basically just went and
pushed it to L1
this one would be listening to these
batches on the P2P and would receive
them and it would just wait for a
confirmation that they have landed on L1
and then it would start building on top
that would the middle one be accepting
pre-confirmation before it's been posted
to L1 no no because since it's
um depends on uh the the state of what
happens in that chain here so it can't
do
that or it will collect I mean it can
but it will collect a bunch of
potentially a bunch of um transactions
that has been already included for
example so it would potentially lose
that space uh on the L1 side and yeah
and also if it um it and if it does not
if it sees if it for example precs a
bunch of transactions that uh then
already has landed the execution precom
is not honored that doesn't mean that it
will be slashed it won't be slashed in
the system that because the inclusion
pre-com is still there but it will lose
that uh that and if it does not include
them it will be slashed so in both cases
it's kind of losing something of course
non-inclusion makes it lose more so it
would include them even though they're
already processed and will be invalid if
they're included again but it won't at
least at least it won't be
slashed yeah so this is this is the
consensus um I mean this is a problem
with also like varying types of preon
because you can always U that like if if
so in in the system right now we're
trying to build with pre- confirmations
is that trying to avoid a singular
solution to dominate so there is
multiple Solutions so there is the
Gateway there is what we're building and
there is multiple ones so if each one
kind of like needs to build on that one
other the other one it needs to wait for
um the L1 the state of L1 to be updated
to start building on top of it
additionally to that um if someone if a
user pushes a transaction directly to L1
without um without pushing it through a
pre-c confer then that also changes the
state so it doesn't make any sense at
all to start building pre- confirmations
before knowing the exact state in the on
the L1 thank you
okay let's hope this marker starts
okay uh yeah so we talked about slashing
now so as we said the pre- confer needs
to include and propose these batches of
transactions on the
L1 but if this validator is Silling his
right to build the block to uh through
PB s to a builder it cannot accomplish
that because it has no control over the
content of that
block and the solution we found to that
is that we would modify the epbs
pipeline um to accomplish this exact uh
uh goal so the the the precom node would
go and tell basically the the Mev boost
that there is a constraint on the
Builder and that the builder needs to
include a bunch of L2 blocks which are
basically a couple of L1 transactions or
it could be one L1 transaction and their
blobs and it could in it should include
them and that's why the uh and and then
the PBS relayer would return with okay
yeah I can honor that and and they build
a block including these transactions at
the end and we propose that L1 block
this is the way that um and currently
we're using um bolt Smith boost because
they have that constraint API already
implemented so we we didn't want to
implement reimplement the wheel but of
course there is also commit boost which
can have that bolt my Boost module built
on it and you can have it for more
details on those please search them on
Google commit boost and bolt myth boost
both of them are they have open source
GitHub repres atories that you can um
look at and
yeah pre-conference selection I think an
will take over here thank you sir thank
you you want the mic mic just this one
yeah okay so now you have a good idea of
what the overall design looks
like and let's talk about pre-con fer
selection because we did speak about how
we want the L1 proposer to be the only
one who can precom and then propose the
L2 blocks in a particular slot now this
is actually a very hard problem even
though it doesn't look like because at
ethereum we love patching things up and
in the process of patching things up we
develop new
problems so when eth moved from P to POS
what happened was we introduced a new
layer the consensus layer besides the
existing execution so earlier it was
merged into like one single thing and
now we have it's separate we have a
consensus layer which manages the POS
part and we have the execution layer
where which is what we developers
usually handle when we are de deploying
smart contracts or interacting with
ethereum using a wallet the problem is
the consensus layer is where the
proposer identity
lives and that has a BLS signature
scheme but the execution layer where all
the inbox contracts are where all the
transactions are made that has an ecdsa
sign signature scheme and that's a big
problem how do we make a connection
between both of these there's no way to
make a
connection so what we need is we need a
BLS to ecdsa mapping so let's say I'm an
entity I have an ecdsa address and I run
a thousand validators with thousand
different BLS public
keys I need a way that I can prove that
I own those thousand validators I can
show it to the registry contract so we
have the pre-confirmation service
contract contracts actually have three
subcontracts the pre-confirmation
registry which we'll be dealing with in
this slide and two other contracts that
we'll be taking up later
on so this entity needs to prove that
hey I own these validators and I
actually have the right to propose an L2
Block in a particular slot and how
exactly do you prove ownership of a key
through signatures right so we have this
signature format here which you can see
it basically has the standard thing like
having a an ID and then validator op is
basically either zero or one if it's
zero you're removing a validator from
your list one you're adding and then
there is an exper and the actual pre-
confer so in here the precon fer in the
signature uh message is the ecdsa
address that I'm claiming that is
claiming the ownership of a BLS
address so the ecdsa address just pushes
a signature and the contract just
verifies that yeah it's the signature is
correct and this BLS public key actually
belongs to this ecdsa key and inserts it
into a simple
map now the execution layer has no
native way
of verifying BLS signatures right now
but very soon in the next upgrade the
pectra upgrade a new pre-compile is
being added via EIP 2537 that's where
all the discussion uh has happened and
this pre-compile or a set of promiles
three pre- compiles actually will help
us verify BLS
signatures now this are really expensive
because for verifying one signature we
need to spend like 300K units of gas
that's really
expensive so in our next alter in our
next PC we are actually proposing an
alternative where in the case of BLS
there's a great feature and that's
aggregation so if you have thousand
validators what you can do is you can
have thousand signatures off chain then
add all of these signatures up it's
basically elliptic curve addition you
add these signatures up and then on the
contract you just have to verify one
signature so essentially you can add uh
like you can put thousands of validators
in your registry via just one signature
and just a bit more than 300 gigas which
is amazing and this is what we will
potentially be putting in the next
version but yeah right now it's one to
one single address single signature
every single time
so how is this used to construct the
look ahead because the BLS look ahead is
absolutely useless on the conent that's
on the consensus layer we need an ecdsa
look ahead on the execution layer so
every every single time we know that
only this ecdsa is supposed to propose
no other ecdsa can propose an L2
block so in this case it's kind of
simple the precom node has the logic the
precom node can take a look at the
consensus lay because the pre-com node
has the view of both the execution layer
and the consensus layer so the precom
node pulls all the proposal from the
consensus layer for the next Epoch then
it fetches the associated ecds key from
the pre-confirmation registry because we
have the BLS to ecdsa mapping there and
it just matches it okay this this BLS
for the for the next slot is belongs to
this ecdsa This one belongs to this and
it creates the entire look ahead
now in our design we have assigned the
duty to push the look ahead of pushing
the look ahead to the first pre- confer
of every Epoch so the first prec confer
of current Epoch will be pushing the the
look ahead for the next Epoch and they
are basically bounded by this Duty they
must do it if they well it it kind of
there's no option of not doing it
because the contract expects you to
provide
that and this is what a simple look
ahead like like one of the nodes in the
look ahead array or mapping looks like
I'll get to what the look ahead what
data structure we actually use but in
here the time stamp the second field and
the fourth field makes sense the time
stamp is the time stamp of the slot and
the prec confer is whoever is supposed
to be pre- confing in that slot or
proposing an L2
block we have another field fall back
and previous time time now what are
these well the previous Tim stamp is
just a link to the
last uh look ahead nodes timestamp what
this allow us to do
is um arrange the look ahead as a link
list within the contract or sort of a
link list within the so every look ahead
structure is an item in a map and the
previous time stamp just points to one
of the other timestamps what this allows
us to do is have advanced proposals
because not every proposer will be
opting in and also not every proposer
will be registering and exposing an
ecdsa address some are just not
interested in pre-c confing right so in
this case we cannot just have an entire
Epoch be empty if there are no pre-con
fers or if there are very few pre-con
fers we need to do something in the
empty
slots and what we do is we allow the
next chosen prec confer to preon in
advanced and because of this link we can
do that with a simple check a a simple
if condition that's that's why in here
you can see that P2 pre- confer 2 can
pre-com in the second and third slot
already and P3 can precom in three slots
in advanced that is made possible
because of this linkless
design finally if we have an Epoch where
there are no pre-c confers at all and
that's very much possible if no one none
of the proposers in that uh Epoch has
opted in we don't have anyone as a prec
confer then we have to select someone
randomly and that's a very simple
selection like we need a source of
Randomness and with apply like simp
simple modulus to select one of the
indices of who is exactly going to be
the proner from the registry and the
source of Randomness comes from the
beacon root contract so we uh as far as
as far as I remember we basically end up
choosing the beacon rot of the first
block in the last Epoch because this
gives us a pre a deterministic idea of
who's going to be the random prec confer
in the next T so we use that as a source
of Randomness and we just use that to
pick out a prec
confer and this fallback preer has an
advantage and that is it can pre-con in
every single slot of this Epoch because
no one else is there to
precom yeah
uh in six
months well but we won't be stopping for
six stopping the system for six months
right yeah so I can uh get in here I
understand the question um so you're
asking is since the pre Comfort does not
have the right to pre uh to propose a
block in the next Epoch for example and
we chose it at random um how will it be
able to honor these prec
confirmations and the answer to this
question is that it might not be able to
honor the pre-confirmation
but uh it will not be slashed if it does
not honor them in this case because it's
a random picked pre- confer and also we
thought about this like okay maybe it
shouldn't be providing pre-confirmation
but this would be a very bad ux so we'
provide the pre-confirmation we would
send them in the P2P on on on U on the M
Pool and potentially someone will pick
them up and include them if the if the
if the if the fee is right um and this
was like the mechanism that we wanted to
do in the so um what Tao is doing also
is that they're they're they're they're
using this fullback mechanism to say
okay if there is a no a proner
registered in the next Epoch then we are
going to propose just to keep the the
the liveness of the of the chain um and
of course this proposal will go to the
mle and someone will pick it up but if
someone intentionally is censoring uh
these uh transactions and there is no
mechanism to force the builders to
include them then they will potentially
not be embedded uh in time
yeah thank you
am and one thing to not is that
throughout this POC we have never
touched The Tao contracts although
eventually we might to add that delayed
inbox but in here we have tried to not
mess around with the Tao contract and
what our task manager does is it simply
routes the blocks that are being
proposed over to Tao contract so because
of this the prover architecture doesn't
have to change that's the best part
nothing in the prover has to change and
the proposer also needs very minor
modifications because the original
contract original contracts of Tao have
barely been changed
go ahead for the next
step thank you thank
you okay so now we're going to go back
to the pre-confirmation loop that we
discussed that every 3 seconds we go and
um in a bit more
details I hope this clicker
works okay I'll just stand here
um all right
so first we start with
the normal event Loop for Tao so what
Tao does is that once every L1 slot it
pulls the pending transactions from the
men poool Tao proposer goes and forms
the block and then pushes it through the
blob to the rollup inbox contract
through the proposed block
function very simple straightforward
what we have with the pre confing
solution is the following so we have the
precom node every 3 second requesting
from The Tao proposal a batch of
transaction Tao proposer goes and
fitches those batch of transactions from
Tao and forms a batch gives that batch
to the precom node
and the pre off node then goes and then
um uh pushes
this transaction to the P2P like we said
the batch of transactions to the P2P and
of course this also only happens after
it made sure that it is the precc
comfort for this specific uh for the up
for this slot and or an upcoming slot
that is very
near so this is the the new uh
loop okay all right so what do we sign
when we provide the the prec
confirmations through P2P what's the
signature so the the structure that we
use is we use the block ID because we we
need to commit to a specific block
height or that uh pre confer could
potentially sandwich transaction if it
wanted to if we don't commit to a
specific block height that it needs to
to uh to propose this uh batch app also
the chain ID in case we are we have like
multiple uh chains and transaction list
hash which is basically just a hash of
the rlp encoded transaction list and I
see there are some hands for questions
yeah go ahead you you have the mic it's
fine just raise your three seconds yeah
so 3 seconds was like a just a
conservative um random number that we
chose at this point because we weren't
sure how fast the the system would be
the latencies all of that um what we're
going to be working on later as you we
will see in one of the slides is like
getting that number lower and seeing how
it's going to behave and how will it
work we will talk about that in in in
later
slides
okay okay so this works here
okay yeah so the the the
pre-confirmation structure we saw it and
then there is the pre-confirmation
object that is sent in P2P because the
prec confirmation structure is the one
that can be pushed as a proof for uh uh
fraud proof but here we need to uh when
we are pushing the precom batch on P2P
we need more details that one is not
enough so we have the block he High and
the pending transaction list the whole
list and um and the pending transaction
bytes I'm not entirely sure what that is
for for and the proof uh uh of the
precom
message and this is what ends up being
sent exactly in the P2P and the reason
we need the batch of transactions
because we need all the other uh prec
confers or all of the other participants
in the network to be able to advance the
head with this batch of
transaction and we also um need them to
be aware of this so when they're role of
pre- comping comes along they know that
okay these transactions have been
already pre-med and potentially will be
proposed in the next one in in the in
the previous L1 block before we start
preing
ourselves
yeah so when um when a precom node
receives the batch of transaction from
the P2P once it's has been recomed
we currently the way it's it it works uh
in Tao before the precom is that we get
an event which is called block proposed
from the L1 and that goes the Tao driver
is basically subscribed to this specific
event and advances the head uh uh once
it receives this event which means that
the user will get a transaction receipt
every 12 to 24
seconds and this is the main point that
prec confirmation our precon solution is
trying to
alleviate with this design so now the
pre-c confing node can once it receives
the uh pre-com message with the pending
transaction list it can provide it to
Tao driver and Tao driver can basically
Advance the head of Tao in around 3
seconds given that we choose a 3se
second uh confirmation Loop um time
all right
so the the nonpr so there is the pre-c
confing node so this is the previous
slide was about the pre-c confing node
so once it pre-com the transaction list
it does this and there is also the non
preconfig node receiving this message
through P2P and then sending it to Tao
priv driver to advance the head so the
whole network advances together and not
a single uh one of the nodes in the
network
yep so we already kind of discussed this
so um we have two ways that the pre-c
confer sends his transactions or that
the L1 transactions that will basically
push the uh L2 uh transaction batches so
first we said okay let's say that we
have a preconference slot number five
and this prec Comfort is on duty for
slot number 1 two 3 four and five that
means that they need to precom a lot of
batches on in these slots and then they
can force include them in slot number
five and that's not a problem that's
easy to do by uh using the PVS software
like we
explained um the problem arises if there
are sparse pre- Comforts there isn't a
lot of pre Comforts and that would mean
that potentially one prec Comfort could
be in slot number
don't know five up until 42 and this
would mean that he needs to push a lot
of transactions in in his slot if we
follow this model so instead we said
okay maybe we should just push all the
pre-com transactions right away to the m
poool so we get batch a batch B and we
just push them directly to the men poool
and at the same time we put them in a
queue in a cache and the idea of this
cache is that once an L1 block comes and
it has those uh batch transaction that
has been pushed here in it then we can
remove this batch from the
cache if if that doesn't happen then the
batch of trans L2 transaction stays in
the cache and then once it is yeah and
so basically if it's if it's if it's
included we clear that batch from the
from the
cache okay so on the proposal
slot we take the ones that hasn't been
included uh that we pushed to the m pole
and hasn't been included yet and we make
sure that we push them through the
constraints API of Bolt Smith boost to
be forc included by the Builder and then
once we receive the L1 block we have the
guarantee from the relayer that these
transactions uh uh L1 transactions that
contain the L2 transaction batches are
included then in the uh L1 proposed L1
block and she will talk about slashing
and yeah
sorry got
yeah
okay so now comes the pre-confirmation
service manager contract which we
haven't spoken about yet and this is a
very interesting contract because what
we have tried to achieve with this POC
is a really flexible interfacing because
we have a number of reaking solutions
right now out there in the in the market
we have I we have kak we we might also
have our own staking contract later on
if a community decides on one which uh
is actually going on a discussion is
going on on having a unified
registry and that calls for having some
kind of a middleware contract so that
later on the code logic doesn't have to
be changed and the staking is just
abstracted away to a different set of
contracts and that's what we achieve
with the service manager is essentially
like a middleway that ensures that only
those proposers who have a wired stake
are allowed to precom or propose in in
the upcoming blocks in the upcoming
slots so what kind of slashings do we
have or when exactly do we slash well
one one time do we that we do slash is
when the look ahead being posted is
incorrect or the look ahead posted is
incorrect a basic version of this is
that when you have uh like let's say for
a validator with BLS key BLS public key
B5
sorry in the BLS mapping you have E4 as
the associated individual who owns the
B5 key but the proposer who pushed the
look ahead placed E2 as the associated
ecdsa key which is factually
incorrect now this might look like an
easy way to just compare hey okay both
of these are not really equal so why not
we slash the the person who posted a
look ahead but it's kind of tricky to
prove this inequality because we have B5
and E4 from the pre-confirmation
registry but in the task manager we
don't have access to who exactly was the
BLS the the validator and its Associated
BLS key for the current slot or any slot
that is incorrect we don't have that
information in like s in a simple
way and what we need to do is we
basically need to have uh this kind of a
match that okay B5 from the
pre-confirmation registry and B5 in the
current slot both of them have different
ecdsa keys and then B on the basis of
that we slash the pre the poster of the
look
ahead so well there is a way to do that
and I kind of have to make a correction
on my
previous uh statement that there is no
connection between the consensus layer
and execution layer well there is but
it's kind of a complicated connection
and that's through the beacon block
route which I think Emma touched upon
briefly so you see just like the
consensus layer has blocks sorry the
execution layer has blocks that we deal
with the consensus layer also has Beacon
blocks because it's the beacon
chain and each beacon block has a state
route and if you
unravel like the entire state tree then
you'll realize that in Beacon State we
have the validators field which contains
all the validators or the
proposers uh and that includes their
unique index as well as their BLS
key so what E7 4788 proposes is that we
get this eventual Merkel route like if
we meriz this entire Beacon State and
then eventually the beacon block we
eventually get a 132 by long Merkel
route and we make this available within
the execution
layer so the thing here is that there's
a problem and that's we only have access
to historical Roots we don't have access
to the current slots proposal because
well the consensus layer is yet to
create the block so we can't have the we
can't really know who the proposer
is so we have to slash or prove that a
look ahead is incorrect optimistically
and the way we do it is we wait until
the incorrect slot has passed and we
have the route and and once we have the
rout we can basically make a static call
to this contract which is the beacon
Roots contract and get that Beacon route
and then just need to send two
proes so first the proposer or sorry the
Challenger posts the BLS key of whoever
was supposed to be the validator of that
slot as well as their validator
index and along with this it sends two
proofs first is the proof that in this
case if you see we have a proposal index
in the beacon block but in the beacon
State well we basically end up having
BLS keys of the validators at respective
indices so via a meral proof we have to
make this connection that hey this
proposer index actually belongs to this
particular BLS key or BLS public key and
that's the step
two and then in the next step the
validator or once again not the
validator the Challenger needs to prove
that this is the proposer index that is
present in the beacon block as you can
see here the second field so very simply
with two simple Merkle proofs you are
able to get whoever was the BLS the BLS
key of whoever was the validator in the
current slot or the pre the slot that is
being
challenged and well once you get that
you can just go ahead and
make check if this inequality is
actually satisfied if it is then well
the look ahead slot is incorrect and you
can slash whoever posted it
along with that we have slashing of bad
prec confirmations which I think was
touched upon by Ahmed but in this case
if we want to expand it we have
execution pre- comps that could be bad
and we could also have bad inclusion
proms in the case of execution precom
well the proposer did push the eventual
block that he pre-confirmation
or maybe inserted a new transaction that
was not actually pre-confirmation
what ends up having what we end up
having is that the transaction list hash
is mismatched between the proposed block
and the pre-confirmation
proms that's a bit more simpler we end
up getting different proposal for the
same block ID because it might have
happened that well he pre-confirmation
these are the two kinds of slashings uh
I think that was quite a mouthful so any
questions no on the inclusion PR can it
happen that I do a prir for a I don't
know my turn 5 away soive
before and then the preer propos would
really is that true yeah so in this case
we actually have uh discovered a few
issues so another variant a more simple
variant of your issue would be I
precom and I don't include it but then
for a long period no one actually
includes any block so what happens is we
a long time passes and the dispute
period gets over so even though that
there is no pre-confirmation there is a
pre-confirmation but there is no
Associated block like the block ID has
never really progressed on chain and and
that's an issue but you can't really uh
prove the incorrect of this so we have a
way of doing that and uh that is so we
might have to go back to so let's say
this is like the slots okay so whenever
uh a pre-confirmation is being made we
also include a look ahead pointer which
basically points to Which slot in the
look ahead am I pre coming for so in
this way what we have to do is we have
to make a connection between the uh
pre-confirmation and the proposed block
why are the look ahead I think now that
answers your question because if we have
that look ahead pointer that basically
states which look ahead slot have we
made the pre-confirmation for and if it
lands on at a different time on uh on
L1 we can make the
inequality okay but but is it possible
that I pre-confirmation
would be pre confirmers for for that
slot before so that I wouldn't be able
to even include this in the as part of a
pre- confirmations I I don't know if
that makes sense I mean not really
because you are prec because the
proposer is once again the I mean this
is Advanced proposals I mean you just
put it in you just release it in the
public M Pool and it might happen that
the proposal does not include it but
then your slot will be coming in so if
you go back to this slide that
Ahmed uh presented in this case when
your slot comes in you clear all those
pending transactions that have never
been included because the proposer
didn't want to include but your slot has
now arrived so you pick those
transactions and you force included
whilea the inclusion list through the uh
PBS pipeline yeah the the other answer
to this question is that the previous
pre
Comer um cannot uh like that that the
previous slot and if if if you're
talking about if if this slot is for
pre-c confer 2 to pre-com at the the
pre-com one cannot then go and push
transactions there every slot has an
assigned pre-c confer and only a
specific pre- comfer can uh push
transactions or batches in those slots
so the contract will just ignore any
batches that arrive from precom fors
that are not assigned to these specific
slots okay perfect
any more
questions
no I think we can touch upon the future
work now
yeah um all right so first we start with
soft blocks So currently what we do when
we Advan thee is that we push a whole
full block to Tao and in this way what
ends up happening is that it goes and
lands in the canonical chain and this is
normal and this is why those
transactions are then removed from the
mol so when you propose the next block
they don't get included twice so that's
one thing um the problem with this
approach
is um is that when you we are proposing
these blocks at the end on L1 we need to
propose multiple blocks so for example
if I prec confirm in every L1 slot
around four uh batches then that means
that I have to make four proposers four
proposals on L1 and this is costy
proposals and verification of these
blocks is costy for a block proposal it
cost around 200 um 200 um 200,000 gas
Anu right yeah give or take and um
around 400 for verifying the ZK proof
for a single block give or take as well
uh could be a bit more than 400 more
closer to 500 so every block that we end
up proposing is is is adding a lot of
cost for proposal and verification so
what did we end up with is a solution
where when you
precom um you're going to add the batch
to Tao push it and then when you push
another batch what it ends up happening
is that it gets added to the block
instead of being so it gets pended in
the block so what happens is that a new
block is formed with the previous
transactions that are in the block and
um the new transaction batch and the
previous block gets reor out and then we
include the new
block and this keeps happening until the
precom node sends a to end of
or uh and then this block becomes a
standard block and gets pushed to L one
as a whole single proposal and this
gives us the C saving that we're looking
for but it's still not finalized
something that we're going to hopefully
work on the next couple of
months another thing like uh our friend
here asked about before is the slot time
uh for the L2 So currently we have a
constant three block second block time
and what we're looking for to
accomplishing is 1 second block time and
it's not that this is not possible
currently it just hasn't been tried yet
and we're not sure what limitations
we're going to hit with the P2P
Etc yeah and then in the last one I
think you will talk about it
yeah so when I was talking about the
pre-confirmation service manager
contract I said we are trying to make it
like a middleware so that as and when we
want to change the reaking service or
the staking service we can just swap it
out and use a new one
and in regards to that the community is
planning to launch a universal
pre-confirmation registry so chances are
there will be many more based rollups
down the line not just Tao and when you
have so many based rollups it could be
the case that one proposer wants to
propose or precom for multiple based
rollups but it doesn't really want to
register continuously because that will
cost him a lot of gas and also it won't
be that credibly neutral because might
be the case that every rollup starts up
its own staking service and and that's
not reasonable for the proposer and
that's a waste of eth not a good use of
collateral so in this case there will be
a universal pre-confirmation registry
where any proposer who wants to become a
prec confirm can go in register the BLS
mapping instead of being in the protocol
owned registry it will be here in the
Universal pre-confirmation registry
along with that so the slashing
condition optin this is a very important
aspect so
the uh rollup protocol like whether
whoever makes another based rollup wants
to have might want to have their own set
of conditions based on which they want
to slash so maybe they don't want to
slash inclusion proms they want to just
slash execution pre counts so they can
Define their own slashing conditions and
then only have those proposers who have
opted into these slashing conditions be
prec confers for their uh rollup so yeah
this is still an ongoing discussion in
the community and eventually there will
be we will be specking it all out and
releasing it but yeah that's it's going
to be a
while well that's it thank you so
much okay there's a question here h how
do you see this integrating into
existing KY systems or rather the path
to scale and adoption on the side of
users and institutions I'm not sure
that's a question for the session yeah
yeah all right so any
questions final how how how do I
evaluate the security of a PR say
i1 care if I send Million by
now if they say is right so what you're
asking about is the fair exchange
problem and this is something that our
research team has been looking into for
quite some time now um as of now we
don't have a solution for the fair
exchange problem um and I think most of
the existing or proposed Solutions
depend on a reputation system as of now
where um if the pre confer or the
Gateway providing the pre-confirmation
um uh is acting maliciously they would
this would affect the reputation in a
bad way and they would potentially be uh
cut out of pre-c confing for the
specific protocol they're working on and
this would potentially lead them for
losses so they the reputation based
system uh being proposed for now but we
are working on a non- reputation based
system where there is
um some oversight over how the pre-c
comers are acting and if they are
actually proning in the correct time
providing pre-confirmation in a timely
manner without like um delaying the
precon informations by the you from
coming from the users or um um like
reordering transactions uh with this
delay to to to just generate more meev
or or profit for themselves
there's another question here what kind
of slashing conditions do you see is it
a penalty or more
tougher so I think right now our
slashing condition is very
straightforward we just slash the entire
stake which is not ideal and it's
definitely not going to be this
eventually I think there was one there
is one proposal by the research team and
that's we have let's say slash tickets
so for every pre-confirmation that you
provide and every validator that you
register you have a a fixed amount of
stake so for pre confirmations let's say
you are staking one eth for every
pre-confirmation that you provide and
once the pre-confirmation is settled you
can basically reuse those tickets but if
you mess up that pre-confirmation only
that one e amount will be slashed and
not your entire stake so this is open
for discussion and once again I think
this is a part this will be a part of
the community Le discussion of how
seriously we want to slash a a a a
malicious prec
confirm uh sorry how do you think uh
distributed validator technology fits
into your prec confirmation design do
you think it could make it much more
secure or have have you guys looked into
that H so in DVT I'm not entirely sure
about the block proposal and how it
works exactly so uh I I know that for
attestation uh multiple uh uh like three
out of four nodes they need to sign
basically to get a proper signat a BLS
signature and um I think it's kind of
the same for the proposal but I'm not
sure how they choose which one of the
nodes is the one who's responsible for
forming the block so honestly no uh we
have not looked into how def DVT would
interact with with this protocol at this
moment uh because also DVT does not form
significant um like um share in the
market of proposers as of now so it it
it would it might not make sense for us
to look into it in a serious um in a
serious manner but potentially if it
becomes more popular then yeah this
would make sense
you have anyb
for subscribe to this kind of stuff are
you measuring life or I mean this is not
yet on Main net because firstly we don't
even have the pre-c compiles yet we need
to have the prra grade so it's it's
running on testnet on Helder testnet uh
have you heard of Helder test it's a
devnet which was released during each CC
so Tao already has uh not the final
version but one of the intermediate
versions running on providing pre-
confirmations but once again that's a
devet so it's only the validators that
Tao is running but yeah this this was
tested using 300 validators and it
worked great yeah okay thank
you if you can speak to the mic because
I didn't hear half of what you said yeah
how just how do you decide how much you
pay for the preconference to propose the
rollup blocks because there might be
multiple base rollups and for the slot
and they might be compete for this pre
same
precom so for the payment we
have we have lifted up for the market
and because we decided that the priority
fee will be used then basically the
pre-conference will just not prec
confirm transactions that are not
profitable um so any transactions that
are do not have a high priority fee that
is paying the proner enough will just
not be included because the precon fer
has the incentive to include as many
transactions as it can in the block to
um potentially extract as much value as
as possible from The Blob that it's
pushing because the blob has has quite a
lot of space so the more data I can fit
in a blob which is basically now free
one way to to get a blob as of now um
the the the more I can make money so we
lift the pricing to the market to decide
um there are some research that is going
on in the space by Conor um and Lynn
from nethermind and there's another guy
I think called fin Finn yeah I don't
know their full name so I apologize for
that about the economics of pre-
confirmations and the pricing for peoms
ETC and this work um there is a lot of
talks that Connor Finn and Lynn has been
talking about pre-confirmation um I
advise you to go check the recordings
for these Talks by these people they're
BL they're they they touch exactly on
what you asked about thank
you how you
think
so do you
think it improves it uh is that a reason
concern um personally um like me or not
me um the the protocol works with local
built blocks and also works with forced
inclusion through PBS pipeline
the only problem here that I see is that
if prayers and Builders decided that
they're not going to adopt the
constraint API that we talked about
because it basically reduces their
income because pre-confirmation are not
profitable enough compared to what they
can include other than these
transactions um then we would have a
problem but as of now and as we uh as we
heard from our partners is that uh
there's a lot of talk and the relays and
Builders are agreeing to add the
constraint API um to their pipe to the
epbs pipeline so they would be
potentially uh including
to add to this will I think we also have
plans for L2 me extraction so when that
is added to this I think the dynamic
changes a bit Yeah so basically since we
have like currently 3C and potentially 1
second uh uh block time for the L2 in
this one second you can the the pre-
confer still at at will can reorder
these transaction but we would not
expect every prec Comer which is
basically just an L1 validator to have
thetic the sophistication needed uh in
the software and in the hardware to be
able to support such ordering in one
second and I think what's going to
happen is that there will be an a PBS
pipeline for L2 blocks if this uh
protocol gets adoption that will that
tries to extract M from these L2 blocks
in this 1 second
slot sorry last question uh what are the
latency figures that you guys have
regarding like the block transmission
from the precom we don't we don't have
that yet because as of now we have only
Dev Nets and Dev Nets are basically just
um curtosis uh set up uh instances that
are running on local machines I mean we
have Helder but Helder deployed a hybrid
solution between Gateway precom and our
solution so our smart contracts but
Gateway software basically and um as of
now that that's what no that's that's
deployed in Hilder yeah okay yeah so
that's what deployed in Hilder right now
so it's not the same and we don't have
that distribution of of side cars
running so we can calculate this this
latency we can do some simulations
potentially but yeah reality always is
is different than
simulations do we have more
think all right that's thank you
everyone for having for for for
attending
oh m
now
