[Music]
for
good morning everybody welcome back to
day three of deathcon I hope everyone
has been having some fun in the side
event
e
e e
you like uh you uh let him go down a
state and
you
pap
back
oh
now hi everyone please get your seats we
are starting in 10 minutes so for those
of you that's still out there you can
make your way inside we have 10 minutes
and we'll be starting on time at 10
a.m.
thanks
all right everybody we are starting in
at 10:00 a.m.
please make your way into
the auditorium and get seated because
you don't want to miss
this for
[Applause]
hi everyone so another five minutes till
we get started with the first speaking
session of Devcon day three I'm sure
everyone is excited so please get seated
for those that are outside you can come
in as well get seated get comfortable
it's going to be a fantastic session
o
w
good morning
everybody Welcome to day tree of Defcon
here so my name is Ben I'm your MC for
this morning and today on this stage
we're going to be covering several
different topics so we're going to talk
a bit about the real world we're going
to talk a bit about layer twos we're
also going to talk a bit about crypto
economics so the energy has been good so
far I'm sure everybody has been having
fun at the side events at Devcon I know
I've been having fun and yeah I would
like to introduce the speaker for today
his name is pum he is a local Thai and
one fun fact about him is that he
organized the First music coding event
at Thailand's old this Museum so without
further Ado let's give it up for
pum hello uh my name is pum and I'm
software engineer at metabase and I work
on open source analytics but in my free
time I'm actually the co-founder of an
open source initiative in Thailand
called Career Garden where we basically
work on open source projects and cre
create events to explore things like
synthetic biology and topics like Phil
philosophy but we try to explore those
mainly with coding so while working on
these projects in crus Garden I got
asked two questions mainly first is
basically how do we get typ people or
specifically type Builders to be
creative and second thing is how do you
bring Builders to your spaces for
example if you have uh basically an
etherum space or web 3 space how do you
get people hooked or interested so we
have been hosting these events in
Thailand for about eight years now so
since I was in Middle School actually
and I'm going to talk about two of these
events that like kind of gives me this
idea on how to engage with Builders so
first is on hacking taii beats so this
is a project I work with Thailand's
oldest Museum so I was working with this
guy Kun Hanoi and he might look very
traditional to you like a Thai musician
but don't let that fool you he's
actually an AI researcher at Tik Tok and
at Google so he was working on a program
that would be able to synthesize music
out of AI so I was thinking what if we
would take tie instruments for example
the Bai and granad and we would be able
to use computer and coding to basically
synthesize sounds out of nothing so
that's where the idea comes in what if
you can use Alor or algorithmic audio
synthesis to basically create an event
where musicians can come together but
instead of instruments they do coding
and instead of western music they do Tha
music so in this events we actually did
a big projection mapping onto the
worldall of Thailand's odest Museum and
people were using things like AI
synthesis tools and algorithmic coding
tools where they can basically build
sounds out of nothing and I think this
is one of the most like important
lessons we know like over the years
which is it's very important not to only
have a strong domain or a strong theme
or a strong tool but to combine that for
example a lot of hacker house they only
focus on the technology for example they
focus on ethereum but they didn't really
let people know like what they can build
with it in contrast a lot of hacker
house they focus on themes so for
example Finance but they don't really
see it like what other interesting tools
you can interact with that so with the
Jack toos it kind of helps a lot so
Samar perer kind of puts it best when he
says like people really learn best when
you build things that you're interested
in he was talking about children but
this really applies to anyone so that
kind of brings me to my second project
hacking Thai cities so everyone knows
like Bangkok is a great City but there's
one catch well you know there's like the
air we have right here is probably not
the best and maybe the traffic is is not
the light test and the mayor of Bangkok
didn't actually like just stop and did
nothing he actually hosted a hackathon
uh actually was done about 3 years in a
row now and I kind of like that idea but
the problem is in a lot of these
hackathons the idea just stop and really
go nowhere so I was thinking what
happened if we used the power of Open
Source like I know like the space like
ethereum really got this far because
it's open source so why not the whole
city not make an open source city so we
started with the idea of basically
letting people come together but they
don't have to formally from a team but
rather an open source project where
anyone can join anytime if you're
interested in someone well just open a
PR and we started by basically bringing
the domain experts in Bangkok people who
have the data of the whole city like
what are the problems in the city what
are the areas that have flooded and the
distribution of the those people as well
as people who have accessibility
problems like people who are in a wheel
share for example and I think the
greatest thing about open source it lets
everyone contribute so it follows the
principle of low floor high ceiling and
White Walls low floor means you can
contribute like anytime like if you know
how to do translations you can do it but
there's also very high ceiling so if
you're an AI researcher you can
Kickstart a new project and it has white
wall so no matter if you're a scientist
if you're a researcher well there's a
place for you to contribute and this
brings like very interesting projects in
the hackathon we did so for example
there were a lot of motorcycles that
were parking near basically the
sidewalks and you cannot basically get
over that and it was really annoying so
someone developed a software that was
computer vision to check that and
automatically report that and get a
bounty so in Bangkok we have that bounty
system where you can make money
by just catching the people who are on
the sidewalks uh the motorcycles and you
can automate that with computer vision
or automating the tree detection of
every tree in Bangkok so we did that and
the last project I want to share with
you is hacking tight dance in 1923 there
was this photo which is the first ever
photo taken of the ti Dan and the
interesting things is is 100 years later
but nothing has changed we're still
teaching dance to same way in school and
to be honest a lot of kids like my age
they don't really get interested in
dance anymore it's un like K-pop where
you able to hack so we were thinking can
we use AI to basically change that so we
think of the project where you can
generate new dance out of all dance
moves like for example the 59 principal
dances so we work so we were turning
this into art performance called cyber
subin which lets human dancers kind of
dance with AI so we bu a software that
would try to learn the characteristics
of tight dance the way we did this is we
started uh basically a group of Builders
but also a group of tha choreographers
and we were going through the old
documents of how people would decompose
the dance that makes us learn that there
are six principles in a tie dance for
example the energy in your body and the
circle and curve that surrounds you and
from the knowledge we gain from the
choreograph
we were able to build a software that
about allows us to basically generate
new dance out of old ones by tweaking
the parameters so we think of things as
basically a set of Animation
Transformations where you would have the
original dance for example the dance of
uh tanom which looks like this and then
you generally run that through a series
of programs that would generate like
very new dance that you can command and
we turn this into interface where
dancers can use to basically generate
dances and we put this all together in a
dance performance so we just showed this
up in Bali uh I think that was Indonesia
and also in Taipei taiwwan so this dance
performance we got a lot of people like
upstage to kind of join in the fun and
play around with ti
dance so generally I think this brings
me like all the three projects to a
final conclusion which just if your
culture or your domain is very hackable
for example if you make Finance like
very hackable or you make Tai cure like
there are some elements where people can
go in and can use their tools or use
their Technologies to hack then I make
it makes it really fun so compare let's
say a thai student who were learning the
Thai dance in school and they were
really bored because there's nothing new
to make versus like kids who know how to
use Ai and they're able to construct new
dances and have fun with it yeah so so I
would like to say thank you to my team
in cyber subin for the dance production
and thank you to you too for listening
this is it thank
you thank you
P that was an
insightful um experience I think has
anyone been searching for the Frog
cryptos here in in Defcon as well so
okay I don't see any questions right
here however I know that you are curious
to ask something as well so we can open
the floor for anyone with any
questions going
once going
twice sah okay yeah I think that's it
thank you so much P appreciate your time
thank you we will be starting at 10:30
for the next session so please stay
tuned hang around it'll be right it'll
be back shortly thank
you e
he
[Laughter]
C
h
in
n
hi everybody I hope everyone's ready for
the next session so just a reminder
before we get started there will be a QR
code on the side of this screen what you
have to do is just scan it and send in
your curious questions we would love for
you to have the Q&amp;A so without further
Ado I will be introducing Lou Who be
talking a bit about the Franklin
fallacy take it away big round of
applause
please hello
everyone um okay I'm going to take you
back 241 years to
France and the first untethered manned
hot air balloon flight took place um
this was a big deal uh it was the first
time man was taking to the sky
untethered um most people think of the
right Brothers as the first time humans
took to the skies but actually it
happened over a hundred years earlier um
and there were lots of crowd people in
the crowd to witness this event and one
of those people was Benjamin Franklin um
the American polymath uh inventor and
Diplomat and there's a famous story um
after this event
um Franklin was asked a question about
this Innovation and that question
was what use is it what's the point
um and his response is quite famous and
it went something along the lines
of what use is a newborn baby right and
this was kind of quite a profound
response um in terms of the way we
interpret new technologies um and
uh the point he was making was that we
don't look at a newborn baby and
judge it based on the things it can't do
right we understand that babies grow and
evolve and learn um and so do
Technologies
and you just wouldn't point at a baby
and say it can't walk it can't talk and
so it has no hope and you know it's it's
a write off right that that that would
be IR
rational but we do this uh with people
do this with new technologies a lot and
with hot air balloons they evolved um
just like babies grown evolve um and I
call this the Franklin fallacy it needs
a name and I'm calling it The Franklin
fallacy and it's something you notice uh
will rear its head whenever a new
technology comes along right um and this
is a really useful
framework
um I mean most people at this conference
aren't going to be fall for this fallacy
but like it's a good framework to
explain to people why they should uh put
their doubts to one side and maybe not
be so cynical um and I'm going to run
you through like the history of this
fallacy
um you saw it happen when the airplane
emerged bicycles light bulbs
um shortly after the wri brothers did
their first public demonstration um
um the the Manchester Guardian now just
the guardian you'll be familiar um said
shortly after we are not belittling the
exploit of Mr Wright it is a great
Triumph of mechanical Ingenuity a
magnificent feat of
acrobatics but we cannot understand to
what practical use a flying machine that
is heavier than air is to be put the
English government like the French and
the German shows its wisdom in
neglecting airplanes and con
concentrating its attention on the
Improvement of the
Airship so ironically just as the hot
air
balloon suffered from the Franklin valac
so did man flight and what people said
was well you've just made a worse
Airship it can't take off and land
vertically it can't carry many people um
it has to constantly keep moving in the
air um there were lots of reasons why
you would think the airships were the
future um
headlines like this appeared using that
same logic airlanes only a fad um and
airships were like uh socially accepted
um more developed uh it was easy to make
a convincing argument uh that airplanes
were only a fad because it was hard to
kind of predict how it would grow and
evolve um you know you couldn't really
predict jet engines and stuff like that
um the bicycle suffered from a similar
thing uh early bicycles were called bone
shakers um because they didn't have uh
inflatable tires which cushioned acted
as a suspension um so early bicycles
were quite uncomfortable to ride and
depending on the surface so again you
take an innovation you see its early
flaws and you can you can quickly
dismiss it um but but
it's a mistake because it's hard to
predict how things will improve over
time um light
bulbs they early light bulbs didn't last
very long they they they were a cool
science experiment but they didn't last
long enough to be practical or make
sense um but Edison looked at that and
thought what if there was another way
and he and his team tested over a
thousand different materials
um until they
came upon bamboo which he used to create
a longlasting light bulb and suddenly
this thing had legs but if Edison had
just looked at like the
limitations the early limitations it
would have been easy to dismiss the
light
bulbs um and my favorite example is home
PCS
so uh in
the 1970s
early 1980s lots of hype around personal
computers everyone's going to have one
um there was there was a lot of hype and
people painting a picture of the future
um that's now become true but then it
was all speculative um and there were
limitations these things were expensive
they had you know limited use cases
and again the Franklin fallacy came
along um these quotes my favorite the
home computer may be going the way of
video games which were a dying fad uh
for most personal tasks such as
balancing a checkbook Consulting Airline
schedules writing a modest number of
letters paperworks just as well as a
computer and cost less very very amusing
in retrospect even more amusing when you
realize it was actually Steve wnc who
said these quotes um so this was
a year earlier
it wasn't selling as well as people
expected um and was did an interview
where he basically said they're just a
bit too they're just too expensive and
not useful enough in the home um
and he basically said that they've been
oversold and this isn't really going to
pan
out and interestingly the same year
Steve Jobs basically echoed what Steve
wak was saying uh he admitted in an
interview with
Playboy that the home PC was more of a
conceptual Market than a real
Market but the thing the difference
between Steve wnc and Steve Jobs is
Steve Jobs wasn't suffering from the
Franklin fallacy he he saw the
short-term limitations but he was a
long-term
Optimist and he did this interview with
Playboy which is super fascinating and
it really like summed up the challenge
of of countering the Franklin fallacy
and he said the hard part we're up
against now is that people ask you about
specifics and you can't tell them um 100
years ago if somebody asked Alexander
grah Bell what are you going to be able
to do with the telephone he wouldn't
have been able to tell them um
and the interviewer kind of said well
you just asking people to have blind
faith in this vision of the future uh
like you just want people to put down
like thousands of dollars and just hope
everything pounds out and and jobs
replied with this he said I can only
begin to speculate we see that a lot a
lot in our industry you don't know
exactly what's going to result but you
know it's something very big and very
good um and this kind of sums up the
problem with arguing against the
Franklin policy you can't be that
specific like the limitations people are
bringing up
that's a fact that's
reality and
then you're asking people to kind of
have a faith but history shows that like
when there's a lot of smart people
working in a new technology you can be
damn sure that a lot is going to change
a lot is going to improve and you
shouldn't judge a new technology based
on these early limitations in the same
way that you shouldn't judge what a baby
is going to become in the future um and
this is all very relevant to this
conference because we've we've seen this
happen with
cryptocurrency
um Bitcoin energy usage has was a big
thing the world economic Forum projected
it was going to consume more power than
the world does in
limitations um and then stuff like
ethereum came along which removed them
um
and E theorum itself its energy use was
really quite High um for a long time
when
nft art collecting blew up there was uh
a lot of criticism around the amount of
energy in carbon emissions uh a lot of
people protesting uh selling art in that
way as a result and of course we saw
uh we saw the shift to proof of proof of
stake um um which reduced the energy use
by
this conference the opening speeches the
improvements of ethereum over the last
few years have been incredible and to
judge ethereum two years ago based on
its limitations would have been would
have been a big
mistake now of course everyone here
knows this that's why you're in this
space uh if you if you were suffering
from this fallacy you would wouldn't be
here um but the reason I'm doing this
talk is because I think it's a really
useful framework uh to explain to people
how to think about new technologies and
why their reservations and doubts might
not be not be so rational
and they should think beyond the current
reality um yeah I'm a little bit little
bit under time here but that that's it
um I run a project called pessimists
archive we explore the history of tech
phobia and moral Panic um we have a
Twitter account we have a newsletter you
can scan the QR code for that now um uh
but we catalog a lot of examples of the
Franklin fallacy and other things um
yeah thank you very
much thank you very much Louie so I
really like the animations that was used
in the slides yes beautiful all right so
we have two questions here I urge
everybody to continuously send your
questions over but let's talk about the
first one so in your opinion what point
is the technology ready to be judged
without the fear of the tech being too
early wait wait wait what's at what
point is a technology ready to be
judged I
mean what is a technology I don't really
know in your
opinion we could take the second one
first maybe we can have some time to
think about it well no I think like um
you know if a limitation persists for
many many years and it's starting to
look like that's kind of hard to solve
then okay like that's fair enough but in
the early early days it's like let's
let's just hold out right let's not
assume this is going to persist um but
obviously there are some things which
aren't you can't overcome um but but uh
it's it's best not to act in too much
haste uh around that i' say understood
okay and the second one would then be
what are some of the times where the
Franklin fallacy turned out to be right
counter argument to that uh I
mean maybe met of us yeah I mean
what I guess te telegraphy had its
limits you know um and then the
telephone came along so you know I think
it was fair to doubt that like it's it's
funny that in the Playboy interview
Steve Jobs talks about this he talks
about people predicting the telegraph
there' be a telegraph on every desk but
he said that you know learning
to learning to use Mor code was just not
practical for most people and the
telephone came along and it made it more
accessible to people so like I
guess I guess
that's one like telegraphy kind of hit a
wall there okay um and you know I I
guess you could say you know
uh ethereum was created because Bitcoin
had some hard limitations yeah um but I
guess like the the broader technology is
blockchain technology and that's what
people were judging based on the
limitations of Bitcoin um
so yeah there there are hard limits but
um but you shouldn't be too hasty in
deciding what those hard limits are I
think well fantastic Insight from Louie
thank you very much for anyone who have
oh there's one more question actually
that just came in oh has it worked for
you to convince people of blockchain
potential by explaining the Franklin
uh I mean I I'm not sure but I hope it I
hope it does I hope I hope it helps um
you know I I kind of concocted this
concept about a month ago so I haven't
had all that much time to deploy it um
but but it's it's really worth using
history to point this stuff out and
point to headlines about people
dismissing the airplane dismissing the
light bulbs because these are all things
we accept holy and we understand their
value um so I'm hoping I will be able to
use it so could probably be a fun story
at Christmas absolutely all right thank
you very much um Louie so our next
session will be at
wants to use the restroom it's outside
on the right and yeah feel free to
stretch I'll see you later thank Youk
ch
m
around
e for
m e
all right so we are under way for the
next session already can I get a quick
check here how many people are currently
using or have used reaking protocols
anybody in the crow
okay that's amazing so we're in for a
treat because next we have tun who's a
renowned expert in this field and he's
going to be talking about Security on
reaking protocols can we get a quick
Round of Applause thank you very
much hey hey everyone um so I think uh
you know in the in the kind of current
ERA there's been a lot of new protocols
that are being built on top of ethereum
um some of them are rollups as many of
you know and some of them are sort of
these kind of new kind of amphibious
things that are are sort of known as
avss or networks or services so natural
question you might say is you know
what's the difference between these you
know when do I need to pay for a rollup
security when do I need to pay for
something that's less and how do I
quantify that so um there's sort of
three things we'll talk about we'll talk
about reaking sort of being a a a
matching Market uh we'll talk about how
to think about threat models for
determining Economic Security and then
finally we'll talk about how do you
quantify that and so most of this talk
they're a bunch of papers that have sort
of the formal results but this is sort
of going to give a high level
description so uh a natural question is
is what is a matching market so matching
Market uh kind of the most common one
people think of is uh in this example
sort of matching uh partners and so each
person has a preference and based on
their preferences you can kind of
construct this graph and then try to
find a valid uh matching and so it's
sort of a a natural thing where you want
to match two different types of goods
one side that's the supply side and one
side that's demand side uh of course I
guess in the the dating one maybe
they're both symmetric hopefully
uh but you know what is a matching
market so matching markets are are sort
of things that are studied in economics
but also used in practice a lot so uh
probably the most famous type of
matching Market is the kidney exchange
so this is for people who need kidney
transplants uh you know maybe maybe I I
had some type of accident I need a kid
kidney transplant but I can't just take
any kidney there's some constraints on
it it has to be a certain size it has to
be the right blood type it has to to
have have a bunch of different things uh
and so there are people who are donors
who are willing to donate kidneys and
then people who need kidneys and there's
sort of
you'd be surprised but there are
algorithms for kind of matching them but
the main thing to think about is there's
a supply of inhomogeneous goods I.E
people whose kidneys have some
properties uh you know blood type size
Etc um the key thing is that there there
there's some similarity between them
they're all kidneys but they have some
special properties and then there's sort
of demand which is people who kind of
want to to to to receive
those so you know in you hear a lot
about auctions in fact someone yesterday
told me they were surprised I went an
hour without saying the word auction
which I felt embarrassed about but uh so
you might say you know how do how do how
do matching markets compare to auctions
so matching markets are sort of more
focused on stability uh under to
perturbations of uh different kind of
mechanisms versus auctions are focused
on things like maximizing revenue or
maximizing welfare um so for instance a
matching may prefer to to to sell all
Goods to all people participating even
if it's doesn't maximize the amount of
money that's transferred and in crypto
we have a bunch right we have meev
auctions for the auction side and we
have intents and also reaking for
matching
markets so natural place to to kind of
formalize matching markets is is using
graph Theory using sort of bipartite
graphs where the idea is you have one
side that is the set of suppliers the
different types of supply and the other
side is the types of demand
um but in most classical matching
markets um you this graph is sort of
static IE the set of people who want
kidneys or need kidneys as fixed and
there's usually a central planner now
decentralized matching markets don't
have each either of these features um
because people can join and leave
whenever they want they can change their
demand whenever they want and this is
why uh you know we we need to start a
little bit by thinking about restak in
terms of being a decentralized matching
market so uh decentralized matching
Market you can have the supply side and
demand side join and leave at will and
so a natural question is you know why
are these harder to to to analyze how
are they harder to analyze uh first off
if people can can join and leave you can
get matched and unmatched um which means
that you have to consider kind of worst
case Dropout from different
participants um the second thing is
without having a central planner uh
without having kind of like the National
Kidney registry you rely on how you pay
incentives
token incentives Etc to get people to to
figure out the
matching and finally you sort of need a
explicit adversarial model so um you
need to kind of model all the different
types of taxs so just to to to to kind
of explain how reaking looks like a
matching Market um you know restak is
really focused on people who are running
ethereum validators who are offering to
run extra services so you can kind of
think of them as the supply side and the
demand inside our services like these
abss so you know a natural question that
I think is a meme in a lot of ways uh is
is economic security uh as you can see
from from this there's many varying
definitions um but we'll take a tiny
detour to talk about Economic Security
and then after that and sort of how to
compare Economic Security between
rollups and reaking and then kind of
talk about the the kind of risks in
reaking so a natural question is is what
does it really mean to have Economic
Security so you know the classical
definition in proof of stake is oh one
third of the total amount of stake is
enough to corrupt a network well that's
true that's true for a double spend but
suppose I want to do an oracle
manipulation attack it might be much
cheaper so uh defining Economic Security
in absolute sense sorry about the font
color there um is actually quite
difficult um partially because you have
things like
me
uh you have to think about the attack
space Sorry all right well I guess we
got a little ahead of ourselves um but
basically there's there's sort of a
bunch of different things you have to
consider so so there's a lot of
different attacks there sort of me
there's attacks that come from uh
competitive pressures uh between
networks um for competing for the same
fees um but generally we try to think of
the the cost of of an attack as sort of
something bounded by a sort of linear
function of the the the numer I maybe
stable coin maybe Bitcoin whatever your
your choice of numerators value of the
stake so in this uh figure we have the
amount of asset staked we have the price
of the asset we have a notion of the
expected time it takes to execute an
attack uh this is sort of a measure of
opportunity cost and then we have a sort
of fixed constant up front that's sort
of what fraction of the network you need
to execute the
attack so natural question is what does
economic security look like for
reaking so in reaking oh o hopefully
this is not uh there are two competing
pressures um the first pressure is if
people see higher yields from reaking
they purchase some fraction of Stak so
they increase the uh amount staked by a
multiplicative Factor
Delta on the other hand uh the slash
Stak so if if you know you get slash for
a kind of Penal in the AVS the slash S
reduces uh your overall network
security so here is something that looks
a little more uh mischievous but let's
go through the terms so so CR is the the
sort of cost uh kind of attack cost for
reaking so first we have a risk measure
so this is sort of a measure of how much
stake what fraction of stake do you
expect to be
slashed the second is we have a notion
of a price impact function so all of
these people who are who were not
staking in the network but they see the
excess yields from reaking they actually
go and buy stake so they increase the
numer value and this sort of abstracts
us to to this function G that's sort of
a price impact
function
uh and uh basically the idea here is if
we look at this this cost says there's
two competing forces one is the risk
measure so how much gets slashed and the
other stuff is about how you increase
the value of the the stake
so natural question ask is when is
reaking
safe um so reaking can be kind of
thought of as safe when you have this
invariant where like the cost of attack
in the reaking network is greater than
the cost of attack uh without the
network uh if we write out the previous
equations we get this condition which
says Hey the risk this risk term the
amount that has to be slashed the
maximum percentage that can be slashed
is bounded in terms of this sort of
price impact like how much more people
are buying new stake to
participate so there's sort of this
dependence on on on how how elastic
borrowers are to the incentives I.E the
new
fees so we'll make a tiny detour and
make a comparison to
rollups um so rollups have a number of
sort of natural economic trade-offs
within
ethereum um a lot of the execution
Revenue now goes to the rollup a lot of
the Mev Revenue goes to the sequencer
um again sorry about the font I didn't
didn't expect this um the uh da Revenue
which is you know uh blob space can be
dwarfed by execution
Revenue so a natural question is when do
rollups if I have a a set an L1 with n
rollups when does the does that Network
break even with the monolithic
L1 so a paper that I have coming out
soon kind of shows for en rollups in
under a bunch of kind of generic
assumtions you actually need N squared
more Revenue so you can kind of think of
this as a sort of inverse Metal's law so
Metal's law is sort of a kind of heris
network law that says I have n
participants in network the total value
they they get is sort of uh Omega of N
squared uh this sort of says that's true
for the rollup users but the L1 is sort
of paying the the price and that's sort
of what this result
shows now you might say well how much re
how how does the revenue from avss
compensate for reaking risk
and um it turns out that if you have s s
sorry just say SS's you only need this
kind of factor that's decaying in the
number of services so what this says is
reaking actually can provide a lot of
value to the L1 and sort of increase it
its monetary premium in a way that's
very different from
rollups so the main thing in this entire
line of logic is that the risk this r
factor is sufficiently small right you
need to not have flashing that Cascades
in order for the the value for the
reaking network to be higher than the
underlying so natural question is how do
you model that risk in in the the
previous example it sort of relied on
this notion of are the incentives high
enough for people to buy more stake and
and and deposit um and so a natural
thing to do is to to now think about how
how to model this formally and again
this talk has none of the proofs but the
you can find them on archive I should
have put a c QR code my bad
so what does this look like abstractly
mathematically um so the the basic
construct is what's called a restak
graph reaking graph like the matching
Market graphs is a bipartite graph in
this bipartite graph one of the
bipartitions is the set of node
operators that's a set V each of the
node operators uh it's a a Vertex label
that is stake which is how much stake
each of them have there's a set of
services s this the avss there's a set
of profit from attacking so this is sort
of if I attack the network what's the
maximum profit I could get there's a set
of corruption thresholds so this is you
know in in bft protocols 1/3 is sort of
this 1/3 of bft stake needs to be
aggregated to do a double spend or in
the longest chain this is the 1/ half
that's sort of how you can think of
these and one key difference between
this reaking and proof of stake is you
can have the same node operator operate
multiple services with the same stake so
that is represented by this middle thing
so this uh operator labeled V
intersection you can think of as taking
its five ethereum of stake and operating
both Services S1 and
S2 so you might say hey is this thing
real like do these graphs exist this is
the live IG L reaking graph from I think
May to August and you can see uh
basically on the left are the node
operators uh who are ethereum validators
who are also running these services on
the right are the different Services um
there's actually far more services now I
think it's about double the number so
this graph is a lot more dense than what
you see
here so when we talk about risk we need
to also talk about what it means to be
an attack what does an attack against
reaking graph look like so the idea is u
a need to be profitable so that means
the maximum profit for attacking a set a
of services has to be greater than the
maximum slashing penalty for a group of
validators who are colluding to attack
uh so this kind of says even if I get
loose my stake from doing the bad action
The Profit that I get is higher so this
is what it means for a profitable attack
the second thing is a feasible attack a
feasible attack says that for every
service that's being attacked the amount
of stake that the cartel that's
attacking the group of validators who
are attacking that service have is
greater than the threshold times the
total stake of that service so it says
for instance if there's two services in
our previous example one that has Alpha
is 1/3 one that has Alpha is 1/2 the
attacking cartel has to have at least
one3 stake in uh set one and one half St
in set
two uh so you can write this in symbols
uh using this this way this comes from
sort of the igen white paper appendix B
uh and then it was sort of cleaned up
more by th and rough Gard which sort of
lays out the initial version of
this so unlike proof of stake the
interesting thing here is is to how to
think about tax here so here every
service is actually over collateralized
so service one there's a profit of four
uh and stake of six that could be lost
um so uh it's not worth attacking and
service two uh the same thing however if
all the validators collude it's actually
profitable to attack both Services
simultaneously and so this sort of says
that unlike proof of stake where you're
isolated proof of stake is sort of a
graph with one service when you have
multiple services and you share you can
have these kind of profitable attacks
from from the shared
stake so what does this look like what
is sort of the bad case of this look
like so what we're going to talk about
is something known as a cascading attack
so a cascading attack is some validator
somehow drops out maybe they're dosed
maybe they lost their stake maybe they
committed a infraction that got
themselves slashed and they get knocked
out now by them being knocked out they
open up an attack against the service
that they were validating so in this
case you can see the middle node
operator attacks the service and then
once the middle operator attacks a
service they open up an attack on the
other service and now you can see that
the entire stake has been burnt so this
is the worst case this is R equals one
in the previous example and you can
think of this as a proof of stake analog
of like a lending liquidation Cascade or
Perpetual liquidation
Cascade so how do we Define these uh so
we take sets of services and operators
where each of them is a feasible attack
after uh the previous attacks are
executed and we Define this quantity RI
which is the maximum percentage of stake
that can be lost due to initial loss of
side that's how you write it formally
but don't worry about that so you might
say hey this tells us how much money we
have to spend to secure an AVS if we're
willing to if we only want we we we
choose a sigh such that our sigh is less
than some threshold so maybe I want that
to be less than 5% maybe I want that to
be less than 10% so this gives you a
concrete way of computing how much
security you need unfortunately there's
a a bad news which is uh this this
result which says there's an infinite
family of restak graphs which you burn
the whole stake that have the Cascades
like what we
saw uh in the effort sense of time I
won't talk about it but this is sort of
what they look like um where the the
dots are validators in the boxes or
Services uh but there's a slightly less
bad news which is uh a theorem from this
paper that says uh RI is actually
bounded if the system is really over
collateralized and we won't talk exactly
about what the definition is but this is
sort of you can interpret this as the
proof of stake analogy of a
decentralized stable coin needs to be
sufficiently over collateralized to
avoid cascading deegs the problem is
this overcollateralization condition is
so strong that each service needs stake
potentially proportional to the sum of
all the
profits so as an example imagine I have
the network with two Services where one
of the profits is one eth and one is a
million eth well the one eth service
needs to attract million in one e to be
secur to cascading attacks under this
overcloud realization definition that's
not good right like if if if I'm a
service whose Pro Max profit is one eth
there's no way I can attract that much
I'm not going to generate that much
revenue so you might say okay is this
like bad does this mean abss are kind of
hard or we never going to be able to
control this risk so that we can get
this kind of safe cost of attack that we
started talking
about uh and the key here is to consider
the incentives so what we do is we now
consider incentives that are paid so
think of this as like block rewards that
are paid by each service to the
validators and then we also allow the
validators to adjust their stake um in
response to the rewards so they can
change which Services they're
validating uh and what you can show is
this this sort of lets you halt some of
these cascading attacks and the key
things to know about this are we we kind
of include some notion of a cost of
attack if an adversary is attacking a
bunch of services simultaneously it
costs them more than if they were just
attacking one um and so having this cost
actually uh we sort of is more realistic
than the the rough card model the second
thing is we assume the node operators
are smart they are looking at the
rewards and they're selfish and they're
like how do I optimize my
payout and if you get this you know our
result is basically you can bound this
risk this RSI um in in a way that DEC in
the number of services um and so uh
there's also a way to approximate
this so the interpretation is if
adversaries who are attacking face costs
if node operators are smarter and if
avss and services can pay sufficiently
high rewards the risk is small so that
actually means you can you can actually
have these things be safely added to
your network and they generate
Revenue so how do you reduce this in
practice uh so IG proposed a new
mechanism which is called unique stake
again sorry about my font uh where each
service is allowed to say some fraction
of any stake that is delegated to to my
service only I can slash someone else
can't slash
it uh which sort of caps the overlap
like how much a single validator can
share their stake across multiple
Services um and if you use this you can
sort of get very nice verifiable proofs
that the risk is small and you can think
of these as sort of verifiable capital
requirements and with that I'm ready for
questions I
think wow thanks for the very
informative session ter if I could
invite you to stand in the middle sound
to answer the questions so we have one
question so far please feel free to
continue submitting more but the first
question what's the tldr what's the main
takeaway that you want people to know
main takeaway is reaking networks
generally if you can bound the risk that
they create like from this stuff we were
analyzing they're actually very good
Revenue generators for l1's they
generate sort of premium for the L1
token it's a little bit it actually is
somewhat counterintuitive but the result
is that they actually generate more
value with a small smaller number of
services that generate fees than rollups
you actually need way more rollups to
generate you need way more fees from
rollups to compensate the L1 um whereas
in in in reaking it's it's it's actually
lower and so the the point is this is
only true if this risk is bounded that
sufficiently small and so you know most
of this result is how do you show that
risk is small under what conditions is
that risk small and that's that's kind
of what we're showing which is basically
that validators are need to be active
management uh and uh the adversar is
face
costs all right so you see a couple more
questions coming in um let's go to the
first one so should we advocate or
enshrine reaking protocols then yeah so
this is a great question I uh you know I
I I'm not sure about the the the
political Liberty on this but I actually
think reaking protocols because they
generate so much revenue potentially for
the L1 it actually does make sense in a
lot of ways for them to be Ed um of
course you know you also have to keep in
mind all of these extra risks you have
um and so I think it would take a lot
longer for the L one to really be able
to justify it um but yeah okay so we see
a couple more that's coming up I'll read
the the one so what do you think about
asset migration from one reaking
protocol to another yeah great question
um so I think like in a world where
there's no restrictions no unbonding
time where you can immediately move your
stake you have a lot of problems where
you can open up attacks um but generally
if you look at symbiotic igen layer GTO
all all of the the reaking networks are
actually giving have have sort of
unbonding times and and and sort of
friction for you moving between them uh
and that friction is actually quite
important uh to for their security in a
lot of ways um and I think this is one
of the reasons it might not make sense
to enshrine right now uh it's probably
better to see how these different
reaking networks work in practice how
much revenue they generate and then over
time figure out how to internalize them
but I think reaking is a little bit
different than me in the sense that it's
not really parasitic to users unless you
have these cascading slashing events uh
and so as long as you limit those it's
just more money for the L1 sers okay um
yeah great answer so wait that's a
couple more I and we still have time as
well so let's talk about can you go over
the one e and one M example again for
sure so yeah imagine have two Services
um one you know let's let's take two
avss let's say one is aan Da and let's
say the other one is uh an oracle
and let's suppose that you know I da
doesn't have that much in fees right now
and the the the max profit you get from
getting the validators to collude to
attack it is one eth on the other hand
suppose the Oracle is tied to a
perpetuals exchange so if I could
manipulate the Oracle I can cause a
price to to to move a lot and then I can
earn a lot of profit and imagine you
could earn 1 million E from that now if
these were two separate proof of stake
networks like the da network was it own
POS Network and the uh uh Oracle network
with its own POS Network then the cost
of attack is or the amount of stake you
need should somehow be proportional to
the profit so for the Oracle I would
need a million eth for the uh uh uh da
layer I would only need one e but if
they're used in reaking and they have a
lot of overlapping validators the one e
service the one that has one e of a
attack profit has to pay has to attract
an amount of stake that's equal to 1
million and 1 E so the sum of their
profits if they have a lot of shared
validators and this is because if the
shared validators get slashed it kills
both of them at the same time it doesn't
just kill one of them and so so this is
sort of one of the reasons in the worst
case you have this additive
Behavior okay I think we have um shot
while Mo um uh I like to thank tun for
the questions please give him a round of
applause for the insights that he shared
we'll be back at 11: for the next
session about mvvs so please hang tight
stay tuned and I'll see you in a
bit good thanks sir
is
no
all right and we are back for the next
session so if everyone has good insights
you know good learning so far I
encourage everyone to please feel free
to share it on social media with the #
Defcon
introduce our next speakers and they'll
be talking about ethereum block building
options introducing Danny as well as
Burak from flash Bots take it
away all right hi everyone I'm borak
today we're going to present our work
with Danning to you and our co-author
Thomas is unfortunately not here today
um as you might see from the slide and
if you were here for tun's presentation
the title is heavily infu influenced
from the uh famous book who gets what
and why and we're actually going to look
into that but in the concept of ethereum
uh blocks and if you were around in the
past couple of days a couple more folks
from uh flashboards actually had uh
quite nice presentations and uh
specifically Phil and Kristoff and one
concept they were talking about was the
centralization in how ethereum blocks
are being built today and in fact we're
going to start from right
there so how are the blocks getting
built today and we know that as an
ethereum validator when it's your turn
to propose a block you can either build
it locally meaning that you will use
your own execution load execution node
and uh pick the transactions which go
into your block and this has the benefit
that you pick the transactions that go
into your block but also the same thing
is kind of also occurs because you have
to pick the transactions which will like
maximize your uh earnings from that
block and if you are not like a
sophisticated um validator who is like
aware of uh block or bundle merging
techniques or block building techniques
well this could lead that like some
validators could make really good money
while you are left behind and to avoid
this kind of an hit en in Block rewards
we proposed or implemented me boost
which is a PBS implementation that's
been active since the merge and the idea
is that now the validators could
actually just delegate their uh block
proposing rights or auction them off uh
to a set of external entities called
Builders and the builders can will
simply bid for the right to earn uh uh
this proposing rights and in this um
tradeoff now the bill the proposers
simply gets easy access to rewards which
is good for the protocol because now
ideally we have like homogeneous access
to immed rewards from the uh validator
side good for consensus security but the
problem is that now the validator has no
say in what goes into their block and
from an individual validators
perspective this might not be like such
a bad thing but we see that now this
could be bad for our
protocol and we see that around 10% of
the validators only actually produce
their blocks locally while 90% opt in
for Meb
boost and what we see today is that as
you might have seen
already only two Builders are actually
building like 95% of Ed boost blocks
right now in our study it was like three
Builders but right now it's it's a Dooly
and why is this bad well if these two
Builders simply don't want your
transactions in their block or if they
have an economic reason to exclude you
they are free to do so and what this
simply means is that the following slide
is not available so we need to avoid
this and there are a lot of pro um
gadgets or uh protocols uh that's been
under uh development for this right now
and in this paper we simply wanted to
understand okay how did these guys
become so powerful in the first
place and there are two aspects that we
uh tackle this problem problem one of
them is how do you earn market share how
do you like get to uh win more auctions
and the other one is how do you actually
increase your profits or how do you
become profitable while doing this
because we see that there are some
Builders who are like not building that
many blocks but are extremely profitable
whereas some Builders who have
relatively higher market shares but uh
they are not actually that profitable
and we want to understand how like this
can
happen and and what we see uh here in
this slide is that if we classify the
transactions based on their objectives
like what they achieve uh or we call
them um order flow labels we see that
telegram bot transactions and me
transactions so like your um Arbitrage
uh sexx Arbitrage sandwich and so on
they cumulatively contribute 51% of all
value to ethereum blocks while only
consuming 10% uh block space or 10% of
the gas very as um less valuable
transactions like I don't know like your
simple e transfers or your retail swaps
they uh consume around 60% of whole gas
while contributing much less value and
like one takeaway we have here is that
the more valuable transactions are
usually exclusively submitted so they
skip the public manool and the blocks
are usually filled with less valuable
public transactions and on the right
hand side you see a uh order flow
composition of the top 10 builders that
is like what percentage of value comes
from which order flow label and uh like
one of the results again we achieve is
that the valuable order flows are also
like uh available in higher percentage
in these more successful
Builders and one thing we actually uh
find is that the diversity of the order
flow is positively correlated with the
market share so those Builders who have
more diverse order flow can simply be
more competitive or be competitive more
frequently than those who are dependent
on a single order flow type for example
like if you are a Searcher Builder which
you only get the order flow of your
Searcher then you are dependent on that
opportunity to arise so that you can win
the auction whereas a builder like
Beaver build um or Titan who is like
getting diverse orderflow can simply uh
be competitive more frequently the other
thing of course is yes you can Vin the
auction one way or other maybe you can
subsidize but how do you actually make
profits and to keep profits in the me
boost auction structure right now you
need to have exclusive order flow which
gives you the Competitive Edge to win
the auction but on top of that keep some
profits so or in other words you don't
have to express your full value to win
the auction and we see that if you have
an exclusive orderflow provider which
means you have a Prov provider that is
only providing meaningful order flow to
you and no one else and you can think
like canonical examples like SCP and
beer build or Vint mute and rsync then
you can actually be more profitable and
again there is a positive correlation
there with having an exclusive provider
and the percentage of uh profitable
blocks that you can produce as a
builder and in fact we find many other
features which are correlated in the
same direction with being profitable and
having a a high market share especially
among the top 10 Builders and this kind
of indicates uh chicken and neck problem
that is like if you want to be
profitable then you need exclusive order
flow which like gives you this
Competitive Edge which differentiates
you from others but that kind of an
order flow only goes into those Builders
who already have high market shares
because those order flow providers they
want inclusion guarantees and hence like
as a new entrance to the Market you
simply have no chance and this is why
like we see such a a convergence in the
number of Builders who are like simply
uh winning the auction today and Denning
will uh tell more about like reasons of
that but this is like a one of the key
takeaways and we also uh go further into
some Builder strategies so like one of
them is you can think it as like how
they pack blocks and um what percentage
of value they drive from uh their block
regions and this is specifically uh
interesting for the top of the block
region because those competitive
transactions which are uh okay to pay
high fees they want priority and By
Priority this could be like acing first
on a state that was stale so like the
last block for example or like doing a
sex Dex Arbitrage which means that
someone shouldn't touch the same state
before them and that for this they're
okay to pay high money but of
course uh as a builder you need this
order flow to come to you so that like
you can place them in the top positions
and get the money from them and we see
that the builders who have high market
shares are also the ones again who are
making the most money from top of the
block and you can also see some
interesting behavior in the end of the
block region um and we can discuss that
later on more but uh simply you can
think it like some Builders allow some
Searchers to do searching after they
construct the block so on the state
that's already transitioned before the
simply like we move on to the next
slot another interesting strategy here
is the latency and bidding behavior that
is of course this auction happens in a
to get relay your transactions to the uh
intermediary relay so that they can make
them available to the proposers and of
course latency matters in this uh in
this
structure because even if you have like
a really high value bit which like you
just uh maybe created in the last like
cannot relate this uh information to the
network then simply it's worthless and
we see that this uh structure simply
incentivizes latency and collocation
with the uh relays and like one
strategic behavior is um cancellations
that these uh Builders use which is
simply like lowering their bid in a
strategic way which is maybe because
they see that like a signal like an
external signal is not in their favor
anymore like if they're doing a sexx
Arbitrage now they want to lower their
value that's available in the auction
and now Denning is going to continue
with uh so how do we end it up like with
such a centralized Market structure yes
so with all these learnings of all the
behaviors and strategies the builders
are doing to win the market share and to
make more money the to the critical
question how do we end up with a such
centralized Market structure today um if
we revisit this data if we compare how
the transparency label or basically
meaning if the transactions are going
through public or private mle we can see
this also interesting 8020 rule here on
the right side you could see pretty much
uh only 20% of transactions are going
through as exclusive signal meaning
they're going through private men pool
while they are providing more than 60%
of value to the final payouts to the
proposer meaning the me value of the
block um pretty much as Brooke already
hinted The Exclusive Auto flow is
providing much higher value than the
public uh mempool transactions with all
these learnings what what's the outcome
uh we Al we we can see that like from
the right side of the chart uh from the
bottom to the top we ranked the block
Builders from the biggest market share
to the lower one we can see pretty much
the bigger the Builder is with the
market year the higher private order
flow percentage is everyone learned that
okay we need to make sure get to acquire
more transactions orderflow privately
and not have other people's to access it
so we can basically be able to keep more
value to ourselves rather than competing
in the bidding to the proposers we can
also see pretty much that on the left
side most of the most meev valuable
transactions are pretty much all private
today what does that mean if we look at
at a time zone Horizon you can pretty
much see that this Behavior or learning
has been pushing all the transactions on
ethereum towards private menle more and
more over time during a two years time
frame if we look back from the beginning
of
only see 3 to 5% of private mle
transactions meaning every day when the
transaction land on ethereum only 5% are
going through private mle but this
number has going up to 10% and then 15%
in end of last year and then actually
bumped up to 35% right now so today
there are pretty much how to say
onethird of the transactions on etherum
are never seen by all those public mle
nodes so why did it happen if we what
happened to the jump in 2024 Q2 if we
exam on all those top block Builders uh
block and basically break it down by the
orderflow content you could see that uh
besides the orderflow that belongs to
them themselves exclusively for example
the thing we identified as the beaver
build who is also a sexex uh trading
firm that has the SCP flow our Sync has
their winter mu flow we could see some
critical order flow for example like the
orange onean bananagun has been uh going
up in Titan block um very interestingly
it correlates with this like dotted line
on the right side which represents the
profit of the Builder that has shoot it
up crazy in the beginning of this year
um which correlates with the growth of
the banana gun flow um so the answer to
the question why did the private order
flow went up over time is that we have
seen this movement of block Builders
trying to compete and almost like
competing in orderflow acquisition War
um which happened quietly everyone is
trying to get deal to the basically most
valuable telegram Bots or potentially
researchers who is the winner uh we can
see that Tian has got the bananagun flow
here Beaver build had an increase in the
Jared from Subway the famous searcher uh
who is doing sandwiching attack on
ethereum um the result is that basically
we have a more centralized Market
structure one interesting to highlight
is that there's another thing that
happened which is in Q2 metamask the
wallet they starting to monetize their
transaction order flow to block Builders
which then drove the crazy 35% up um so
to revisit how did we end up here today
you could see that was the orderflow
acquisition thing that we mentioned in
the beginning of this year um you there
is a huge change or like a padan shift
of how the block Builders started from
pretty much three builders in the past
half uh half years become now only Titan
and beaver um our sync pretty much gave
up after they lost the biggest deal and
decide to not to like try to keep their
market share up uh because to do so they
will have to give out more profits from
their searching flow and also
subsidizing potentially um so this is
our takeaway me boost have successfully
enabled uniform access to Meb rewards
for ethereum validators however the
current market structure is not ideal
and it undermines ethereum censorship
resistance and neutrality properties um
and we know that everyone in the market
want a more decentralized Mar uh Market
structure including the top Builders um
by talking to the top Builders um the
top Builders are also sick of this
basically uh orderflow acquisition
competing uh game and because there's a
lot of inefficiency in current design
for for example if the top block
Builders are trying to acquire order
flow uh exclusively to each other um
meanwhile these order flows are actually
not really conflicting in terms of the
state accessing of the blog space they
are basically competing say for example
the centralized exchange that uh and uh
exchange how to say uh searching flow
competing against the telegram Bots flow
which can totally exist in one block but
today because they belongs to different
block Builders they will have to compete
to land in the next block and so to pay
more to the proposer which also caused
proposer Monopoly um another thing is
that it's really hard for any new
Builder to come to the market without uh
adding a lot of subsidy to Kickstart and
markets in the inclusion rate uh charts
which have evolved into a pretty toxic
zero sound game where everyone is trying
to subsidizing more which also then
causing the top Builder to subsidize
more and which is very unsustainable for
the whole game um so what if we are able
to find a way to decentralize the market
set and redistribute value to all the
people in the game um so our team flash
BS we believe that um decentralizing the
block Builder set is one solution
towards uh solving this centralization
uh of the market structure uh we we
believe it has to be achieved step by
step one is we have to basically design
a set of the multi-operator set where
multiple Builders can run um and you can
trust them to be run by any of the
neutral entity and another thing is that
we can we can have this C how to say
neutral platform to allow any block
Builder to come to the block building
algorithm and just to bring their order
flow keep them private potentially in a
tee um and we can be able to uh fairly
redistribute value for the aut flow they
provide uh one thing we have implemented
so far is a gas refound rule um so the
the idea is basically like uh whoever
you have a a set of order that you want
to build and land in the next block you
have a measurement of the realized value
which is the onchain payment um how much
these transaction are paying including
gas fee and tip to to the Builder um you
also have a block value Delta or we call
it marginal contribution value for the
block so meaning for the block when we
simulate uh to build a valuable block
without this order flow how much is the
value uh compared to how much the value
will increase including order flow the
Delta would be your marginal
contribution to the block and uh then we
can basically calculate how much refund
we can potentially refund back to the
autoflow providers um based on how much
profit the Builder can take uh we have
already um collected of around 60 e
refunds for the autoflow providers that
are sending to flash BS Builders uh we
have processed uh three EAS of them and
we're hoping to see more and more
adoption for this um thank you that's
our talk and if you're interested in all
those details of the data feel free to
check out the paper uh which is uh
included in the AFT conference this year
thank you thank you
everyone
hello thank you everyone and thanks for
the speakers I I do agree a monopoly is
never good right um if I could invite
you all just to stand here uh to answer
some of the questions that's posed by
the audience so the first one and most
upvoted what do you think about epbs
yeah um so if you have attended uh
Kristoff's talk yesterday simply uh his
theorem shows that or suggest that the
centralized structure of the market
would not change under epbs or any APS
designs um and hence that's why we are
at flashboards trying
to put the building logic inside a te
where like the outside uh interference
is not POS possible and thus achieve
some kind of a decentralization in the
process because again epbs yes could has
benefits in terms of
like providing an enshrined um market
for the same purpose as meev boost
without relay intermediaries but it
won't be a solution for
centralization okay thanks uh on to the
next one which is how do you get the
metrics for order flows for example the
telegram board yeah so so I I guess we
should have defined the metrics Mev what
does that mean in our context um it Bas
it simply means how much value are paid
out to proposers so we're calculating
how much basically uh each transactions
are paying in gas priority fee the base
fee is burned so doesn't really count
and there is a function called coinbase
transfer in M boost um the software
which pretty much looks like a value
transfer Ines so them all together would
be the value or the payouts from the
transactions um then there's a layer of
uh bidding involved so when the block
Builders are collecting all the
transactions this is how much value
they're receiving which is the true
value of the block and then um we are
looking at how much build are bidding to
the proposers so the value of the
telegram Bots is simply basically
looking at their uh payouts on chain and
labeling based on their
routers okay thanks thanks for the
insightful one uh okay on to the next
one is the code publicly available for
labeling autof flows
um we have all the uh um queries that we
have uh used on Dune available and
actually referenced in the paper but
then some um some of the internal logic
is I think not yet publicly available
but we can definitely share if you reach
out to us okay um next one did
introduction of block markets have any
effect on Builder Market um yeah one
thing we observed and also we note in
the paper is um it's not directly on the
Builder market in terms of like who wins
Etc but we see that after the
introduction of uh blobs um the the gas
uh space or the block space consumed by
these um rollup transactions simply like
which uses call data and so on actually
lost significance so you can see I guess
a positive impact in that sense okay
next pretty interesting one isn't he
just trust me bro
it's definitely not TR trust me bro
there is like remote adastation and many
other thing you can verify like if the
code running in Te is actually what you
what they're saying uh we actually have
a teammate uh dear he had his talk about
um this more specifically so I would
suggest you guys to check it out um I
would say if te wouldn't help with
Central uh censorship resistance and
there might needs to be other solutions
to patch to that but and also just to
add on to that I mean aren we trust
think anything so everyone so far we
trust the relays I don't know we trust
the builders who we send our order flows
to uh maybe this time we can try
trusting like cryptography a bit more
and give a shot to tees okay I think we
have time for one final one so can gas
refunds increase spam as it would get it
was mean the spammers can get the most
of the gas back it's an interesting
question um here's your take too but I
think um I don't think it will in
increase spam um or maybe you meant a
different meaning of the spam but like
if you're paying that much money um like
the refund is kept at how much you're
paying uh as of today so I don't think I
don't know if what are you getting out
of spamming U our us I mean I mean um so
to get a refund you simply have to end
up Landing in our block and uh have a
have a contribution and of course
depending on your unique contribution
you get refunded so
uh like you can spam but it will be just
like bad for us in terms of like dealing
with that but it won't like affect
anything your refund as a matter of fact
spamming might actually hurt your refund
because we then we'll see similar order
flow that is uh competing with your
other flow and which makes the marginal
contribution of your flow less all right
thank you so much for the q&amp;as there's a
lot of questions thank you very much we
will be back at 12:00 p.m.
so feel free
to get a toilet break stretch your legs
see you later
for for
hello hello we are back with the next
one yes if you don't mind could you take
the discussion a bit to the side so it's
not disruptive all right I'm really
excited for the next talk I'm going to
introduce Sean who just a little fun
fact he's been training for Marathon
while he's here but more importantly for
today he's going to be talking about
bootstrapping a block Builder so let's
give it up for Sean and take it
away hello
okay so bootstrapping a block
Builder well over the past few months
we've been looking into how do you
actually join the block Builder Market I
think the last talk did a good job
setting up how difficult it actually is
um so we're attempting to the impossible
I guess on some
level this is a picture of relay scan
which many of you may may have already
seen I think it illustrates the problem
with the current centralization of the
market pretty well you can see on the
right hand side here there's two
builders that are really dominating the
market producing about 95% of
blocks um and that's obviously a huge
centralization Vector for ethereum um
the block builder at the end of the day
acts as uh an Arbiter of inclusion to
the chain the proposer Outsourcing its
ability to pick which transactions to
include and the inverse of this power is
that a block Builder gets to decide
which transactions to exclude so it has
power over censorship of the chain as
well so let's look at the Builder
profitability tab
here as you can see it looks like 600
eth per week is being made by each of
these block Builders you might think you
know this is pretty good business to get
into
um but this isn't entirely illustrative
like it's not entirely comprehensive
this number is derived from the balance
changes on a builder's address after uh
it builds a block it doesn't include any
information that's offchain so like we
saw in the last talk uh there's a lot of
competition for actually getting the
transactions that you can then extract
me from and then include in a block on
chain so payments for these types of
things are probably being made offchain
um and the purpose of that is one just
privacy for the transaction flow
provider and two back running or front
running protection um so the or at least
like exclusion of front running rights
something like that um so it's these
numbers are actually a lot more opaque
than this we don't know exactly how far
off this is it could be something like a
factor of 10 um we don't really know all
right so where's the competition because
in spite of this you would still
probably expect there to be more builder
competition you can see two years ago
Rel scan looked a lot different there's
like nine different block builders that
each had more than 6% of blocks being
built and no block Builder had more than
built over the years more than 40 block
Builders have ceased operations um so
why have they been failing
I think you could chalk it up to
competition on some level um just there
simply being out out competed on a in a
zero some
market so let's hone in onto like what
is the role of the Builder to try to
figure out like why are they failing why
are they shutting
down um here I want to make a
distinction between a Searcher and a
builder where the Searchers the very
specialized party that's actually
extracting the Mev um the Builder more
of an aggregator of the uh searcher's
output and then the party that's
participating in the bids to actually
get blocks on chain um so that's the
part the interaction with the relay
there um some Builders choose to
collapse these Center two blocks the
search and Builder um it could be more
efficient to run both of these processes
in process there's no like communication
overhead there um the downside though
would be if you have that type of setup
you may not be able to get other
Searchers to work with you and the
Builder since it's an aggregator it has
a high incentive to um get bundles from
as many Searchers as possible in order
to get the most competitive
block um and over here if we look at the
order orderflow provider this is another
party that like may or may not be
distinct from the Searcher a Searcher
May have with it its own unique order
flow um if it's doing sex Arbitrage the
Searcher itself might be an orderflow
provider um but at the end of the day
the the flow of money here it sort of
moves away from the Builder on both
ends the
Searcher is paying for the rights for
transactions on some level the tra the
Builder can be like a proxy for this it
could be like a broker for this um and
the money being paid here is going to an
orderflow provider something like a
wallet something like an
RPC um and on the other
end the any excess bid that a search is
sending to a builder has to be
aggregated and used in order to be
competitive in the block building
auction so in the limit the money is
moving away from the Builder on both
ends so the margins are compressed as
there's more competition between
Builders um so you can start to see how
it could become a very tough Mark to
participate
in so
specifically what is the Builder doing
why should it exist in this
interaction one thing is it's it is the
expert in actually getting a block on
chain so it has a broad like a breath of
knowledge as far as what transactions
are
available um it has the ability to um
make certain guarant es for certain
transactions that they can get in in a
timely matter this might be important
for sexx Arbitrage for
example a builder can also provide
privacy
guarantees so it can provide privacy to
an orderflow provider which would be
good for not front running potentially
it can be provide privacy to Searchers
as well so that their meth strategies
aren't
leaked and it can also provide other
sets of guarantees so for a Mev Searcher
it might be a specific position within a
block which enables some strategy uh can
guarantee atomicity of bundles of
transactions so they like execute and
sequence on train on chain and then also
giving a guarantee that if there's
contentious State like your transaction
will execute like it won't revert um so
these are all valuable things that a
builder can provide
um if we go back to this
diagram we if we start to think
about the Privacy component here of a
builder we need to look at the private
transaction flow so orderflow provider
to Builder and eventually the Searcher
the Searcher needs to have access to
these transactions in order to um
extract me from them so it needs to see
the private transactions but we don't
want
leakage um so how do we add add privacy
guarantees or some some conditions of
privacy to this well one way to do it is
if there's public order flow auctions
you can add obfuscation to
transactions so this is what flash Bots
Mev share does Mev blocker does um they
allow like a more permissionless auction
for order flow but uh there's some
degree of obis for transactions so
Searchers can on some level extract Mev
but not like perfectly perhaps another
another major way to do this is via like
offchain agreements probably legal
contracts so that would that would be
like the orderflow provider and the
Builder and the orderflow provider and
the Searcher enter into legal agreements
to say like these transactions have to
be private these are the conditions if
not and the need for these types of
legal contracts is a big centralizing
Force um because this requires like
administrative overhead for the Builder
it requires some degree of reputation in
the space you have to be a public figure
on some level and a lot of actors in
this ecosystem prefer anonymity
especially Searchers um so that's
another big Buri to
entry okay and so this is actually the
paper that was in the last talk um and I
think it does a good job illustrating
how critical the order flow is to this
whole um the success of the Builder
and some of the key takeways included
the diversity of order flow is very key
it correlates to the success of the
Builder and I think hand inand with that
is the exclusivity of of a specific
Builder's order flow and it makes
intuitive sense because if two Builders
have access to the same set of
transaction you're probably just
competing on computation on latency but
if one Builder has the most important
transaction in the set all of a sudden
he just has perhaps an in insurmountable
Advantage so this is the key thing to
focus on I think as far as bootstrapping
a
builder and how do you do
it well you could just try to win these
orderflow auctions they are very
competitive if you're you have a
separation between a sear and builder
then you need to work with a Searcher as
a builder to get like a specialist to
like work with you to win this it would
be better if they worked just with you
um that might be easier said than
done another interesting approach this
is sort of what Titan has done over the
past year is to focus on like feature
richness so making features in your
Builder that are conducive to a
searcher's searching and that might
attract them to use your Builder and
they might bring with them maybe order
flow that they possess um so a specific
feature would be if you send the Titan
Builder a transaction that runs out of
gas they'll just front the the payment
for the gas for you so long as the
Builder's balance increases at the end
of the
transaction um and then subsidization
you could view this also like a feature
on some level like it's a feature very
directly in that the Searcher ends up
having to to tip less because you're
just paying for the searcher's
inclusion but also if a Searcher is
running some sort of strategy where they
need maybe like a 10% chance that their
block ends up on chain you might have to
subsidize in order for them to have that
probability and then yeah major
component is just business development
so this is like actually making the
relationships with orderflow providers
with Searchers um the things that go
into this include like building an
ecosystem represent or
reputation and making legal agreements
contracts being a public
presence all right and can we get rid of
these off chain contracts because these
are like really highly
centralizing I think it's reasonable to
think of tees as a potential replacement
for a legal contract because
because if what you really want is just
to keep the execution of the
transactions private or the execution of
the Builder over private
transactions um tees can let you do that
and they can let you do it with a pretty
minimal performance
impact they're not bulletproof though
and because of this like if it's really
like high value
transactions it might still require a
legal agreement in conjunction with the
te so this this isn't necessarily a
catch-all solution something that would
hopefully be more of a catch all is like
a pure cryptography
solution um something like threshold
encryption or fully homomorphic ENC
encryption but both of these add a lot
more of a performance overhead
especially presently but maybe in the
future that can be reduced to where the
performance tradeoff versus the
trustless isn't quite as great
right um so let's look at specifically
the Builder software cuz actually
working with this is a barrier to entry
in itself there are some open source
options that are good the uer Mev RS um
what you can do is you can extend these
you can start with these to like help
you hit the ground
running um at some point you might need
like more optimization maybe
optimization you don't want to share
because you're trying to like bootstrap
your Builder you want every Edge you can
get especially if you're trying to
overcome these other network effects
like order flow um so that might lead
you to trying to start a builder from
the ground up that would also help you
build some expertise in in your
Builder all then infrastructure this is
another barrier to
entry a lot of the game for a builder is
is minimizing
latency uh you want to minimize latency
because if you're able to include a
transaction that's produced
later then that broadens your set of
transactions for potential inclusion in
your block like maybe the most valuable
transaction in a slot comes like just
before the end um and you can include it
no one else can that would be an
advantage you want to minimize latency
from transaction origination to your
bill
and you also want to minimize it from
your Builder to the
relay the way to minimize
transaction uh origin
latency there's a few ways but you could
use like an optimized me pool there's
some thirdparty services that do this
you could build your own sort of
infrastructure for this where you have
Sentry nodes around the network and
maybe they're directly connected to each
other and just like sending transactions
back and forth you could also
potentially collocate at an orderflow
provider that would be like how to
minimize it
maximally um but on the other end you
probably want to collocate with a
relay um because that's an easy way to
minimize the latency from the Builder to
the relay obviously um and relays might
be geographically distributed to serve
different proposers around the world um
like with lower latency so you might
also want to collocate your Builder with
a single relay but at each instance of a
relay so generally this leads to you
probably want a very flexible uh devops
infrastructure setup you probably want
to use something like kubernetes because
um at some point you might want to
horizontally scale as well so if you
want like multiple clusters around the
world horizontally scaled it gets pretty
complex and the cost runs out pretty
quick because you're dealing with full
nodes for a lot of this and full nodes
are expensive to
run all right and then projecting the
role of the Builder into the future this
is another challenge in trying to start
a builder is it's not really just a a
stagnant Target you're aiming at it's a
moving Target so you'll probably want to
incorporate what do things like Bas
sequencing pre-confirmation epbs like
how do the impact um how your your
Builder will develop in the future like
maybe if you can get ahead on one of
these things that would give you a bit
of an edge to try to enter the market um
it's interesting pre-confirmation are
actually similar to the guarantees you
would get now from a builder as far as
like oh like I want to be I want this
traction like not to
revert but they happened earlier in the
slot and they can happen uh with the
risk of the Builder losing in collateral
otherwise so there's kind of like some
overlap with a pre-confirmation and like
a builder's current
role and yeah so right now we're
building blocks on heski it's a lot
easier there lower competition
thankfully um our intent is to try to
make a builder that's competitive and
from there work on trying to push the
boundary of how to decentralize it how
to make it more transparent how to make
it more permissionless
um this feels like a more natural
approach to us as oppos to starting with
a theoretical solution and trying to
make it performant um probably because
we're a team of
Engineers um yeah that's it thank
you thanks Sean I hope that inspires a
few people here to try something out if
I could just have you in the middle
we're going to take some of these
questions but please feel free to keep
submitting them first one what prevents
a build relayer or proposal from
themselves front running a searches
bundle Builder relayer proposer all
right so the Builder wouldn't front run
the searcher's bundle because they would
have some sort of agreement and this is
where like either the aisc comes in or
maybe a legal agreement or just trust um
that like the Searcher will continue to
send the Builder
bundles unless you know they build a
front run them but from the
relays perspective the relay is like a
trusted intermediary where they they'll
see the bundles and they serve the
purpose of actually blinding the payload
and cashing it before sending it to the
proposer and the idea there is that the
proposer is going to be like the most
distributed Anonymous actor here so they
have they would have the easiest uh way
to I guess just steal the Mev and you
know
just wait for the next proposal in like
six months they don't really care but
the relay has to have some degree of
reputation because it's acting like
every slot so yeah all right so next
question does Builder benefit from being
closer to popular public RPC servers
such as latency benefit oh yeah I think
definitely it's tough to say like we
don't have like empirical evidence to
this yet but you want to minimize that
type of latency if possible if that's
where you're getting order flows from
but also latency to the proposer or to
the relay um and which of those
Dimensions is more valuable to optimize
for I'm not sure it might be better to
do it near your orderflow provider
because you don't know which relay is
going to have the block that wins the
auction for example okay next one do RPC
providers like Alchemy or infura sell a
transaction for order flow should we
take precaution against this um yeah
they might I don't have personal insight
into this but yeah they might should you
take personal action I mean you could
try to put pressure on these rpcs to say
like oh if you're selling this like I
should get a rebate like if my
transactions going to you I should get
some money back for that I think that's
like The Natural end state of the market
um it's just not quite there yet okay
what do you think of execution auctions
and how they might change the function
of the Builder uh I think execution
auctions are really
cool one thing it does is it kind
of generalizes the interaction between
the Builder and the proposer all of a
sudden the Builder doesn't have to like
go directly through the proposer to
broadcast a block it's like you buy the
block beforehand a builder would and
then you have the rights to like do your
best job building um so in some ways it
simplifies it it's sort of like it could
be viewed as making the building set
more permissionless but you obviously
have these other ber stes still so maybe
not
quite okay uh what if a proposer such as
a note provider is launching his block
Builder without a relay is it
bad a node provider with his own block
Builder without a relay I I think it
depends
if the proposer if this is like a big
set of proposers using a single Builder
that would be bad
if it's a single proposer with their own
builder that doesn't seem so bad that
seems the same as like you're using a
local block Builder but the best version
of that if every proposer had their own
highly optimized block Builder you'd
still have this really decentralized
block production uh Network so you'd
still have the same like censorship
property as we have to that okay uh next
one I'll allow you to choose which one
of the Tre as the last question
okay
yeah
um okay is the link between Searcher and
Builders public Onin for instance which
Builders which Builder a famous Searcher
like Jared from SE uses oh okay I think
they actually touched on that in the
last talk um and they were able to see
that recently Beaver build is getting
more flow from Jared so there is way to
track it on some level but we haven't
dug into this too much sounds like the
last team did okay thank you very much
Sean for your session please another 7
minutes and we have our next speaker so
please hang tight
thanks thank you
okay we're back so
so the next speaker her she's also from
flashboard but fun fact she's also MC
that did had the sessions as well um I'd
like to introduce Elaine who will be
speaking about empirical analysis of amm
loss versus rebalancing on Layer Two
Chains so please everyone give her a
round of applause thank you very much
hi everyone I know it's near lunchtime
you must well be a bit hungry thinking
about lunch um hopefully after this talk
you'll be more hungry not just hungry
for food but hungry for more information
on this topic so loss versus rebalancing
whenever I talk about loss people tend
to wish they didn't hear about this term
because nobody wants to talk about loss
but actually this kind of loss um you
could avoid and you could potentially
turn it into a profit so if you're a
liquidity provider you've never heard of
lvr loss versus rebalancing hopefully by
the end of this talk you'll get a better
idea uh you will probably know how to
reduce it so let's get started first why
do we care and what is
lvr some people say that this is bad
blood in the amm system and I tend to
agree but
first let me quote the original authors
who Define this idea in their paper in
incurred by amm LPS due to stale prices
that are picked off by better informed
arit Chargers well today at Devcon I say
this is my quote that LP live on an
isolated island and they don't know
what's going on outside so they rely on
the arbitres to bring them information
and they pay this unjustifiably high
cost which is what I call lvr so in this
scenario um the a the LPS are always
worse off because they're waiting for
the arbitrages to come in and snipe the
m and stale price make a profit so
whenever the sex price moves away from
the Dex price um you it's like leaving
cash on the table right so at the moment
this cash on the table is only picked up
by the arbitragers some of of it goes to
the block proposes but none of it goes
to the lp so that that doesn't seem
right and surely there's something we
could do about it but before we try to
tackle this problem we want to know
what's the magnitude of the problem
right how much ourr is out there so
these are some key questions we're
trying to address today first how much
lvr is out there not just on E theorem
but also on base arbitrum because there
are more users using l 2 we want to know
how much lvr is out there on all the
l2s and secondly we want to understand
if this theoretical value that's
proposed by this paper is anywhere close
to the empirical value because the
theoretical value is an easier
calculation it will give you a very easy
bull bullar number of the estimation
right so if it's close then that's good
news lastly we want to see what are the
factors that affect lvr um and this
includes looking at different hedging
frequencies looking at uh hedging on
centralized exchange like binance um or
Perpetual um platforms like dydx we also
want to look at blog time um and also
the design of the transaction ordering
for different chains these are all very
important questions we want to answer
and see if we can find ways to reduce
lvr I need to talk a little bit about
methodology here because I'll be
referring to empirical versus the
theoretical lvr and it's important to
understand what these terms mean so in
the original paper the lvr is defined as
a function of liquidity providers pnl
the rebalancing strategies pnl and also
the lp
fees so on the left hand side here we
have the hedged lp pnl so if you're are
a liquidity provider you hold West usdc
and you don't want to be exposed to the
risky assets let's say you don't want
the price volatility of East so you can
perform this so-called Delta hedging
strategy or rebalancing strategy by
selling exactly the same amount of risky
asset you hold in the liquidity pool in
a centralized exchange such as binance
so if you do that you're expected to be
risk neutral um you won't be exposed to
any risky assets so on the right hand
side the only expected return should be
your LP fees but in in reality this is
not the case right because we always
have some kind of residual left uh
because the sex price is not exactly the
same as the Dex price you always have
something um that can't balance this
equation and that residual is defined by
the um authors of this paper as the
lvr so in my analysis I reshuffle the
equation a little bit on the left hand
side this is what I call empirical lvr
you can calculate this using observable
on chain data and you can also perform a
rebalancing or Delta hedging strategy
using binance price you can calculate
everything on the left hand side on the
right hand side you have the theoretical
lvr here I'm just showing uh one of the
formula which is uh for constant product
pool it's a simple enough equation you
just PL plug in these parameters you can
calculate a theoretical alvr so the
point is that we want to understand if
the theoretical is anywhere close to the
empirical if it is then we can avoid all
the hassle on the left hand side we just
apply the simple formula on the right
hand side to give a b bullar number
measurement now enough of the
theoretical empirical let's take a look
at the analysis so first we want to know
how much lvr right we just want to know
not only ethereum but also base arbitrum
we want to compare the empirical versus
the thetical we want to compare
different hedging frequencies
here is a chart showing if um on
ethereum West usdc pool that if you're
an LP you provide liquidity from the
beginning of March and you hold it for S
months until the end of September what
is your accumulative expected lvr so
this is a loss number right even though
it's showing as positive we want this
number to be as low as possible because
it's a loss and the theory goes that if
you hedge more frequently your loss will
be lower and these different lines I'm
showing here actually aligns nicely with
this Theory because you see that one
minute hedge lvr is the lowest you're
only losing 800,000 usdc but if you're
lazy you hedge every day you're losing
almost 3 million for the whole seven
months holding period just remember that
this number is the maximum number
because I'm calculating it for for the
entire liquidity pool right so if you're
only a single LP this is only
um uh this is the maximum number you're
only getting a portion of that loss so
don't worry you won't be losing 3
million if you just provide a small
portion of the liquidity um you also see
some theoretical values here so that's
the two dotted lines that's more smooth
in the middle and uh these are the
theoretical formula I mentioned about
and why there are two lines I'll explain
the next
slide so in the original paper in
important assumption it assumes that
there is no trading cost to the
arbitragers assumes that the arbitragers
trade against the Dex pool they don't
pay any fees and that's obviously not
true it's not very realistic right
imagine you're in a very volatile Market
of course you have to pay some fee to
trade against the Dex pool um so they
realized that and they they produced
another paper in the next year
considering trading fee as a factor in
the lvr calculation so that's why here
you see two different lines the the line
with um trading fee in Tak into
consideration gives you a lower lvr
because a cost to the arbitrager is a
gain to the lp that's fees you're
collecting so you have a lower lvr here
and we want to compare the impact of
this fee feature and you can see it's
around 0.2% of the total pool
value now like let's take a look at base
base is similar to ethereum it's a
priority gas auction um it only has two
seconds block time but we expect it to
be very similar to ethereum so you see
here that we have the different hedging
frequency the one minute hedging
frequency again gives you the lowest lvr
only 13,000 usdc loss but if you hedge 4
Hour it increases to 66,000 although
it's not totally monotonic because you
don't see the daily number being the
highest here uh 4 hour is the highest
but we can say that you know pretty much
in general we still follow the rule that
the more frequently you hedge the less
lvr you get and again looking at the
difference between considering the swap
fee and without considering the swap fee
the difference is similar 0.3% of the
pool value now let's look at an outlier
and this is arbitrum why do I say it's
an outlier because first arbitrum is not
a PGA priority gas auction chain uh it's
a first come first serve chain which
means that if your transaction arrives
early it'll be executed earlier and also
it block time is very short it's only
something to be different and I used two
pools here the the first one on the left
is the same you uh usdc West pool from
Unis swap V2 but unfortunately the pool
is not very liquid it has very few swaps
so if you do the same analysis you see
different hedging frequencies it doesn't
really follow the rulle of you know the
more frequently your hedge the lower the
loss right you see the daily hedge
actually has the lowest loss uh doesn't
really follow the rule doesn't make much
sense so I thought okay then maybe I'll
look at a a pool with more volume more
swaps so I found this other pool Camelo
V2 which is also a constant product pool
and I perform the same analysis and here
you see that actually it comes back to
the theory that the more frequently you
hedge the less lvr you have so the one
minute you have the least lvr of only
impact of fees on the left hand side you
see the difference is about is about one
uh 0.1% of the pool on the right hand
side is about 0.3% of the pool so this
result is very similar to ethereum and
base now the next interesting question
is if I'm an LP I want to perform this
rebalancing strategy this Delta hedging
strategy where should I do it should I
do it on a centralized exchange like
binance or should I do it on a Perpetual
platform like dydx right I might want to
just stay in the ecosystem do it on on
dyds if uh there's not much difference
so here I'm showing you the rebalancing
strategy pnl if I hedge every minute
this is the chart on the left there's
almost no difference whether I do it on
binance or dydx but if I hedge daily it
seems that I have an edge on uh hedging
D on dydx right because my pnl is higher
on this chart and we found the same for
base and also arbitrum so next now let's
take a look at the empirical lvr and uh
we also um see that the lvr is lower on
dox remember I said the p&amp;l was higher
on dox as the lp so what does it mean
here it actually means the price
discrepancies between the Dex on
ethereum and dydx is actually small
smaller than the price discrepancies on
Dex and binance this means that the
arbit charer has less of an opportunity
trading Dex dydx so less opportunity for
them to make a profit more opportunity
for you to reduce your lvr so you are
better off uh doing this hedron dydx if
you are providing liquidity on
ethereum but base we don't see much
difference here even you look at the
daily chart it's quite similar um so you
can choose whichever you want for
arbitrum again this is very different uh
because we see the other way around
right this time you're actually better
off uh just uh doing the HED on binance
because the dis discrepancy between Dex
binance is smaller than between Dex dydx
so that's what you know you can choose
based on which chain you provide
liquidity the last question we have here
is to compare different chains across
and see what's the alv R in terms of the
percentage out of the total pool value
so the theory says that uh lvr is a
function of square root of block time so
if the theory follows the shorter the
block time the lower the lvr and you'd
expect arbitrum to have the lowest
lvr and let's see if that's the
case I have four charts here with
different hedging frequencies also
including all the chains and for
opportun I've included two pools one is
the uh pool with low Activity one is the
pool with a high activity but let's just
ignore arbitrum for a second because
it's the outlier let's focus on the blue
line which is ethereum and the red line
which is base so you can see for all the
hedging frequencies uh throughout all
the seven months holding period you
almost always have a lower lvr for base
and Bas only has a 2C blockchain time so
we could say that this follows this the
theory that the shorter the block time
the lower the lvr right but arbitrum
outcome seems inconclusive because
whichever hedging frequency you look at
whichever you know High activity pool
low activity pool you look at sometimes
it's higher than base in ethereum
sometimes it's lower so we can't make
any consistent conclusions here and this
might be because the chain is a first
com first serve chain is different right
it could also because the volumes I
looked at in these two pools on arbitrum
is actually quite low so the number of
swaps are very low here the US dollar uh
USD trading volume is also very low you
can see the two at the bottom they're
from the two poles from arbitrum much
lower than ethereum and
base now we know ethereum has the
highest lvr followed by base followed by
um orbitum but this is only the lvr from
one single pool I'm showing you right
West USD C and there are many many more
PS as we all know on each of these
chains so imagine if you can capture all
of these lvrs all of this is not a loss
it could be your profit it could be
profit that you can give it back to your
user so imagine the potential you can
gain a lot more users using your
protocol using your chain and the list
goes
on now coming to conclusions so we've
compared a lot of things we've compared
empirical versus the theoretical we know
the theoretical is kind of similar to
the empirical we can use it as
approximation to give us a bullar number
if we want a quick estimation we also
look at trading on a Perpetual like dydx
and trading on a centralized exchange
like binance and the results seem to be
very similar if you hedge very
frequently then we compare the trading
fee uh feature with trading fee you have
a lower lvr is a trading fee is a cost
to the arbitrager and it's a gain for
the LPS so you have a lower lvr we also
compare base with etherum and Bas is a
shorter block time it has lower lvr so
shorter block time lower lower
lvr and we also know that the more
frequently you hedge the less lvr you
have there are some inconclusive results
from arbitrum uh we don't know if it's
because of the first for a Ser of chain
nature or is it because the pools I
choose have too low of a volume too um
not that many number of swaps right so
these are
inconclusive lastly how can we reduce
lvr so as an LP you obviously want to
hedge more frequently you can reduce lvr
by not being lazy um you could also
provide liquidity on a pool that has
more activities so your price stay stale
for less time um and I want to mention
something that I I pointed out earlier
so the trading volume and the number of
swaps actually play a factor um in the
lvr because imagine if you only have a
swaps on your pool is only once per hour
so at the maximum your price update is
only going to be once per hour no matter
how quick your block time is right so
actually the the frequency of the pool
the activity of the pool makes a huge
difference that's why you need to choose
a pool with more activity so as a
protocol designer you want to be
thinking about how to internalize lvr
and redistri uh capture it at your
protocol level and redistribute it back
to your LPS and I think that's uh what
our next speaker will be talking about
they've done something um in this kind
of uh design and I think she will show
you some of the Practical analysis you
could also improve the real ESS of your
decks by bringing in some Oracle updates
or even by just uh charging a dynamic
fee lastly if you're a blockchain
architect you might want to think about
shorter block time uh you want to think
about different transaction ordering
designs that potentially will increase
the opportunity cost of the Arbitrage so
first come first serve chains or prior
to gas chains or any other kind of
different design that will help your
user to reduce lvr is worth looking
into and that's the end of my talk uh
I'd like to thank this list of people
and also the data providers alium and CC
data for making this analysis
possible question thanks thanks Elaine
you can tell you can tell how much M's
not working okay hi yeah thanks El you
can tell how much effort she put into
the presentation just by the charts so
let's take a look at some of the
questions so the first one what
percentage of LP rebalance your
portfolio with a comparable frequency as
arbitragers I would say the LPS are
definitely as not as professional as the
arbitragers so I would expect the
hedging frequency at the maximum you
could do I mean if you can build a bot
you can do it very frequently right but
if you can build a bot you probably an
arbitrager so I actually like to ask the
audience how many of you actually do
hedging if you provide liquidity I only
see one hand oh actually a lot more yes
yes so that's good to know but yeah it's
a lot of hassle I doubt users will
actually use uh like a highly frequently
hedged position which is why the
protocol designer needs to find ways to
you know help the user to tackle this
problem okay so the next one is how does
lvr look on V3 versus
V2 yeah so that's something I didn't
have time to look into well I had time
to look into but I didn't have time to
show you here um V3 actually has a lot
more lvr just because the trading volum
is much more and there are much more
activities there um so it's something
that's worth looking to for sure yeah
and the next one is does liquidity
liquidity concentration increase or
decrease
lvr I think a large part of it um is due
to the price discrepancies so liquidity
concentration in some sense if you have
LPS who have these thresholds where you
have the upper tick the lower tick if
suddenly the price moves and you
suddenly have a lot more or a lot less
concentrated virtual liquidities in the
V3 pool your uh pools price is going to
change right because the less liquidity
concentrated liquidity you have you know
the more price movement there is so it
dep depends on how fast the price moves
versus the centralized exchange I think
that makes um it make makes more sense
than purely looking at the concentrated
liquidity okay on to the next one is
there a trading fee for hedging
activities I would assume one minute
Hing would lead to a lot more trade cost
compared to
daily
um I would say the main fee will be
let's say if you Hedge on binance I
think the fee is around
lower based on you know which side of
the thing you are if you're a taker you
pay you pay a fee if you're a maker you
pay a different fee I remember the mid
price is like
you had on
DX okay how can you explain that the one
minute empirical lvr is smaller than the
theoretical lvr
well the theoretical value is actually
in the formula it's using uh volatility
based on the daily volatility so that's
why you could so in in the formula one
of the parameters is the price
volatility and in the in the paper they
use the daily volatility of the binance
price that's why you know you get a
higher number and one minute if you use
a one minute volatility in that equation
you probably get a similar number yeah
next question does execution prices and
size of hedging plus how Hedges are
executed is taken into
account uh so the execution price in
this paper is just the centralized
Exchange price right so you're assuming
you're hedging on binance so you look at
exactly what the price is on binance and
the hedging size is just whatever you
hold on the lp as the risky asset you
want to hedge so in my example it was
East so you hedge exactly let's say you
provide liquidity to East with I don't
know 6,000 usdc then you'll be just
shorting two on the centralized Exchange
price using binance
price okay so we are out of time for the
questions ready but please follow her
and X perhaps she can answer it there um
yeah we have one more session after this
so feel hang tight and yeah we'll catch
back later
the
o m
okay this will be the last session
before we go for lunch break but I want
everyone to keep the same energy and
welcome our next speaker Anna so she's
known for the ca that makes the moo
sound when you make a swap and today
she'll be talking about revolutionizing
liquidity and how they go about it so
please give a round of applause for Anna
hello um hi I'm Anna from cow wait one
second ah perfect now we have the right
slide and um today we're here to talk
about amm designs why they're currently
broken how we can fix them and what
other positive side effects it will have
if we fix
amm who here is currently depositing
liquidity on Unis swap
yeah you might um find out and I think
in the previous talk we actually had the
question who of you is hatching against
lvr and not so many people were raising
their hand so um we are talk about here
to talk about today to let you know why
you should rethink about how you want to
provide liquidity in the
future um so let's start why do we want
to change the system it seems to be
working
fine amm have been around for a few
years at this point they have a ton of
liquidity so they seem to be
okay however research has shown in the
last couple of years that actually
liquidity pools leak a lot of
value and this phenomenon we are calling
loss versus rebalancing or in short lvr
or
lever and it essentially describes this
adverse selection risk that you take by
potentially taking the wrong side of a
trade So In traditional Finance this
happens if you trade against an informed
Trader but on blockchain this problem is
accelerated it essentially happens on
every single
block and so you basically are
guaranteed to trade at an information
disadvantage so I don't call it adverse
selection risk I call it adverse
election
guarantee and to describe it with help
of an
example today most of the price finding
unfortunately is still taking place on
centralized
exchanges so um if you think if you see
that the East price is dropping from
$3,100 to
buy one ease for
$3,000 on Unis swap the pool will show
still show you the outdated price so you
can sell your one e for
$3,100 so the arbiture is making a $100
profit and then the liquidity providers
on Unis they say at a
loss you can measure this loss by
looking at how your liquidity position
is comparing is performing compared to a
rebalancing portfolio if we look at
concrete numbers research or basically
what we can see is that there's a lower
bound of at least
settled on Unis V2 post merge is coming
um from arbiture Traders so arbitrager
volume isn't equal your lvr loss but you
can be assured that arbitrageur will
only trade if they can make a
profit if you look at concrete numbers
research suggests that between 5 to 7%
of liquidity providers liquidity is lost
annually due to
ivr this equals in US dollar an
estimated amount lower bound of $500
million and this is on ethereum alone
and from every body who was raising
their hands that they are providing
liquidity to Unis swop part of this
money is coming from
you so in other words providing
liquidity on chain currently is not the
happiest thing for liquidity
providers so we need to look into how we
can solve this problem how can we solve
lvr and in order to understand how we
can solve it first need to also
understand how the current systems are
operating so if we look at the
traditional amm Market most of the amm
are using some type of constant function
amm the reason is that essentially on
blockchain current you have a lot of
different transactions in a single block
and then they get executed sequentially
so you are first second third or
wherever in the block one track gets
executed after the other
however you get different prices right
like the first Trader might get a
different price than the second trade so
now this turns out to be a bit
problematic because at the same time you
also want to then fulfill sat to satisfy
pass Independence which means that there
shouldn't be an incentive for you to
split up your trade if you trade $1,000
worth of a token there shouldn't be an
incentive for you to instead settle 10
trades of $100 each or maybe to have
like a very simple way of describing it
on the constant function your price is
determined
deterministically whereas the actual
price might be might be somewhere
outside so you basically have these two
constraints on traditional amm right
that you're processing trade
sequentially and that you have to
fulfill path
Independence now we were going back to
the drawing board and like see is there
like a different way of how we can
actually fulfill this or make this less
problematic so we looked into batching a
solution and if you collect all the
transactions of a block into single
batch and you execute them actually at a
uniform clearing price then the order of
the transactions doesn't matter anymore
because anyway all of the transactions
within this batch received the same
clearing price and then it also doesn't
matter anymore if users want to split
their trades into multiple because in
any case the batch is reaggregating all
those
traits so as I mentioned I'm from cow
and cow has been looking into batch
auction mechanisms for a long time so we
have a live mechanism for over 3 years
and so we decided okay let's try it out
let's build an amm on top of this
existing batching mechanism
so really brief overview of how it works
all transactions are collected in a
batch over a certain period of time and
then there's an auction where multiple
external parties who we call sers are
competing to finding the best possible
price for the orders that are in this
batch and they also have to comply to
some rules one is this uniform clearing
price essentially all Traders with the
same assets should get the same
execution price and then there's another
Criterium ebo that requires that also
the minimum price met is at least equal
or better to existing other onchain
prices having this
competition guarantees then that even if
somebody is trying like to take
advantage of the a low like of a price
discrepancy there's an there's an
auction there's this competition between
different parties who will all Drive the
price
up and then
lastly there's this consolidation of all
transactions in the batch you can net
them out against each other and only the
leftover amount is executed then against
amm and by having this additional noises
of like additional transactions you can
generate additional Surplus that is then
all distributed this captured lvr and
the additional Surplus that is captured
is distributed to the liquidity
providers so other words the AVR is
captured and redistributed in this way
the amm doesn't suffer from
it um just to show you briefly how the
price functions differ on the left you
have the constant function one of the
traditional amm that sort of like
deterministically defining where you
where your track gets executed and then
now with the new approach
by batching you can now think of a price
function where at the actual price point
sits outside so with every trade that
they execute you can move up this price
function this is why we are calling it a
function maximizing
amm and looking concretely into the
return of your investment on the
traditional amm it is sort of like a
rebalancing strategy just that you have
the loss that lvr incurs and then
on top as a bonus you get the fees that
the amm
collects on our new approach the
amm it also operates in a way like a
rebalancing strategy but you do not
incur the loss from loss versus
rebalancing and on top of that you get
additional
Surplus so in other words batching
combin with this new price function
removes ivr and can finally make
liquidity providers happy
this sounds great in
theory um how does it actually
perform so as I mentioned we did do an
implementation of T of cow protocol and
we call it cow
amm it's been live for a little over 3
months and it has around 20 million in
TVA at the moment it's deployed across
ethereum arbitrum and nosis
chain and has um essentially 29 pools
that have more than 10K in
tvl the most interesting data point up
front it currently outperforms Unis V2
pools in 50% of the cases you might
wonder why do we compare against Unis V2
the reason is that Unis swap V2 is
currently performing best for Passive
liquidity providers so we wanted to
compare km against whoever is performing
best um let's look into the methodology
we using we looked into growth of 10K so
essentially if you deposit $10,000 US
Dollars into a pool on C amm versus the
equivalent un2 pool at the same moment
in time how does this strategy
perform and the reason why we like this
methodology is because it can be
negative because at the end of the day
as a liquidity provider what you care
about is the total assets that you hold
in your balance in your wallet we also
look at API
comparisons um just because this is what
users like to see they're really used to
it um but in a way it's somewhat
misleading because it can be very
positive you can sometimes have moments
that shows oh amazing I have 100% 200%
APR but it doesn't tell you so much we
use it for essentially like short-term
price volatility
okay let's look concretely at the pools
the interesting part here is I already
said that km outperforms un2 pools in
part here is we also looked at tvl and
so Unis swap has larger tvl then C amm
across all the pools we
compared and the interesting component
here is that in those cases where Unis
swap tvi is only between three to nine
times higher than on C amm C amm already
outperforms Unis Swap and only on pools
where the tvl of Unis swap is between 30
to to 80 times higher cm is still
underperforming and this is kind of
expected because the more the like the
more TV you have the more like the more
over proportionally it also attracts
trading volume so it will also generate
more
fees so we should expect that as TV is
growing on C amm so should also increase
its
performance then we were actually
curious to see if there's currently
Surplus left on the tables because we
literally like C was just launched three
months ago and it also of course relies
on good solver support and unfortunately
so far only three solvers integrated C
natively so we looked into Tok compare
usdc West pool um and looked at
different performance periods I think
this one particularly shows for one week
or a little longer actually and um
looked into um how many trades could
have been settled against cow
amm but didn't and what is the Surplus
that was left on the
table and it turns out that
unfortunately 96% of the Surplus is
still not
captured um and then we've render
analysis across across different time
periods and also across different token
pools and turns out that this captured
even more surpluses left on a table so
we're currently working together with
sers that it do natively integrate km
because then also the performance will
significantly go
up um loss verus rebalancing ivr is
particularly problematic in times of
high volatility right like the more
there's a price discrepancy between a
centralized exchange compared to a DEX
the more value can be
extracted so we looked into those High
volatile times and there's actually a
bunch of examples I'm only going to show
two now that are both pretty recent so
the save token got listed on
upit and within a time span of 15
minutes it had a huge price increase to
over of over
and there was a bunch of rebalancing
transactions on
km a bunch of them were juicy one
particularly juicy one um generated over
Surplus if you compare this with how it
would have performed on Unis swap there
to remind you how does Unis fop capture
lvr not at all the only thing they have
to kind of circumvent the losses of lvr
is by taking a fee but the fee is fixed
and the fee is fixed to 0.3% at least on
the equivalent
pool and so if you compare the
profitability cowm essentially did 30
times better than Unis
swop um then to give one second example
just to show this is not a rare occasion
last week the cow token got listed on
binance also led to a really big price
jump and um there essentially even 15%
Surplus was captured in one single
transaction again price jumps like the
price movement obviously happened over
time interval of a few minutes not in
one single block so there's a bunch of
like individual rebalancing transaction
on cow amm and I just picked here one
particularly juicy one um and again if
you compare this to a 0.3% fee on Unis
swap then on this particular trade um
how outperformed Unis swap 50 by 50
times
so what's the lesson here that's
essentially if we remove a and we add
Surplus into the mix we can actually
really maximize the liquid the returns
for liquidity
providers now if we remove the problem
of lvr we can finally also think of C
amm as an investment strategy why is
this the case it's because in a way it
is performing like an index fund because
it automatically rebalances
the reason why Unis swap wouldn't work
as a good Index Fund strategy or
rebalancing strategy is again because
you have the loss due to lvr which is
now fixed and then it essentially even
outperforms an index fund because
instead of having to pay fees to to pool
managers that are doing the rebalancing
you it does it
automatically and then on top of that so
you don't have to pay fees and on top of
that you even gain additional fees from
Surplus we call this new product
dtfs or decentralized traded
funds and it has all the financial
upsides that I just
mentioned and it can also already
support multi tokens because you can
just create two different pools with
like a 50/50 or
those newly created IP tokens and put
them in a new to in a new pool and this
way you can already create your
multi-token asset pool we will also uh
build on top of balancer V3 so then
there's going to be a more native more
straightforward integration of multi
tokens but you can already do it
today and you have full control over
your assets naturally and can access
them
anytime and then there's this last
really really nice benefit also that
come comes from integrating on top of
cocol which is that you can actually
leverage your yield bearing tokens
because if you look at the unisa pools
they all against West right but a lot of
people want to hold rep stake East s
whatever any interest bearing
token and you can use them and put them
into an amm one because like you have
this really nice rebalancing strategy
but the highlight of Kor is that it's
underlying solver mechanism can e swap
in and out of this token so if somebody
is interested in buying W and not rep St
East they can still take advantage of
the liquidity that's in the pool that
you created so instead of keeping all
your idle assets all your idle yield
bearing tokens in just your wallet you
can now think about hey why don't I
deposit them in an amm and earn
additional yield on
top so rebalancing on km plus generating
ser plus and leveraging interest bearing
tokens is essentially a little bit like
providing liquidity on
LSD the summary is um by removing so ivr
today is the reason why liquidity
provision doesn't work well we can fix
this now with a function maximizing
amm and the current implementation of it
C amm is already outperforming univ 2 in
will increase as there's going to be
more solver support and as the TV will
grow and as of today dysfunction
maximizing amms can already unlock the
potential of passive investment
strategies so I'm inviting you to try it
out thank
you thank you Anna I am definitely
interested to try it out so let's take
some
questions first one if C amm volumes
come from left over of the batch meaning
that the noise Trader volumes don't hit
the amm aren't LP getting very little
trading fees due to low volumes and how
do you solve that I would say that at
the moment yes probably if you compare
the fees obviously that they receive
compared to Unis of volume it's lower
but the real benefit is so essentially
there's studies showing that the fees
that Unis fb3 is making are not making
up for the losses that lvr is creating
so just by comparing this cm is already
performing better right because K is
removing ivr by pushing the prices to
the real price where the price should be
and then even if the Surplus is slight
might be slightly lower than the fees
the Surplus is on top of this AVR
removal and on Unis swop it's only
trying to make up for the
avvr all right next question how much of
the C operation happens on
offchain well the basically at the I
mean we are working on a
decentralization white paper because the
goal is in the future to have everything
fully on chain but the matchmaking
currently is taking place offchain okay
right so the next one if it outperforms
uni V2 on 50% of the trades what
happened for the 50% remaining does it
perform the same or Worse um I think I
showed actually the performance on the
slide and it's currently performing
worse but it's like by 0 point something
perc it depends on the pool depends on
how much tvl it has and depends on how
much volume we be we are able to capture
on those pools so there's no this is the
fixed percentage across the pools but
yeah it is SL slightly underperforming
at the moment okay does c lping Works
similar to Unis swap
V3 no because Unis swap V3 is leveraging
concentrated liquidity and this is not
the audience we're targeting we are
targeting passive liquidity
providers um actually if you look in the
performance of univ V3 everybody who's
like trying to do passive like who's not
Super Active and is not an informed
Trader and like a specialist and knows
what they're doing actually suffering
even worse like their positioning return
is much worse than on univ 2 so our
Target group is the passive um liquidity
provider who wants to go who wants to
get a return on the investment and not
leak value and so you know it's
different definitely how can you come up
with lower bound on percentage of swaps
that are
Arbitrage um let me try to understand
the question are you come up with lower
bound of percentage of swaps that are H
do you mean the I I assume that what is
meant is essentially the the slide where
I showed this so this is not research
that we did
internally um but there's a bunch of
research papers that I think I quoted in
the source of the of the presentation so
if you're interested you can look into
it
okay okay so the next one would be in
the example you gave how amm performs
outperforms uni V2 in 50% okay that that
has been answered so we're going to the
second one can you call it an index fund
when a token holding strongly depends on
the price isn't Hing strictly
necessary um so as if you like basically
if you look at an ETF strategy what you
do is you invest into it right and then
you have like a company who's doing
rebalancing for you actually much less
frequently than it happens on an amm so
depend on the price so in other words
for this part like if if you're like an
informed Trader who's providing
concentrated liquidity on univ 3 then
probably you also do hatching if you're
a normal passive liquidity provider who
essentially just wants to earn some
interest on their hard earned tokens
without being a professional at what
they are doing then no you don't need it
because overall you're not losing money
but you're making money on top okay so
we have time for one last questions do
do c amm LPS outperform the hle
strategy yes we did look into it and um
in maybe so the problems we only have
data periods of three months but the
short answer is yes it outperforms it um
maybe if you look at like if a newly
created pool was just set up and it's a
couple of days or that maybe there might
be cases where it doesn't outperform it
but over time yes it
does okay thank you very much Anna thank
you you so we will be closing this stage
for the next hour to have lunch and I
urge everyone to go go out um you know
stretch of feet get some lunch get some
food and also explore so I'll see
everyone back here at 1:30 p.m.
ciao thank you so much forting you're
doing so good thank you I think I want
to try it out too yesterday I was I was
researching on on your page actually but
I didn't
p.m.
okay oh my b
okay all right so we're closing for the
next hour we'll see everyone back here
in 2:30 p.m.
I
oh e
to
B
see
now
your
right
hello
hello hi there everyone so back from
lunch break I hope everyone had a
feeling lunch get settled get comfy so
we're going to start the next session
for stage five it's going to be all the
way to 6:30 I want to introduce to you
Max so he is often mistaken as Mark
zuberg but I'll let you be the judge
when he comes on later on right so yeah
Max today is's going to be talking about
onboarding and um all the close so
without further Ado let's give it a chot
breig Round of Applause
please hello everyone thank you for
coming to our talk on how crypto goes
mainstream it's a topic that's very near
and dear to our heart
I work at privy and privy is an easy and
Powerful way for crypto products to
onboard their users and privy Powers
many of the most popular crypto apps
from Trading apps like hyper liquid and
pump.
fun to restaurant loyalty projects
like Blackbird to social apps like Zora
and friendtech and so from supporting
many of the most popular consumer teams
we've gotten a really good
into what makes a great consumer crypto
product and it's really exciting at this
Devcon to hear how many people are
talking about consumers and and apps and
you know one of the things I've seen a
lot on Twitter is people saying where
are the apps and how are we going to get
more users on chain and this is a
problem we think about a
ton and at
privy we
we um actually I'll tell you a little
bit about what we're going to talk about
first and then we'll dive into it so
we're going to talk about the changes in
our market like why as an industry we've
gone from you know not not giving much
airtime to Consumer to it being
something that everyone is is
referencing and talking about we're
going to talk about the crossroads we're
in and why we're starting to see a
really exciting acceleration in the
crypto Market we're going to talk about
what great looks like in consumer so
what some of the qualities of the most
popular consumer apps will look like
we're going to talk about where we go
from here how we're going to get every
consumer product on chain over
time at priview we we we talk a lot
about you know what what will it take
for a consumer product to break out and
new tech often needs to power
experiences that are orders of magnitude
better than the status quo and so to use
an internet analogy like if you were
building a new internet if you built
something that's better than dialup you
know that's not going to cut it because
now we have fiber and so with consumer
you know we need to build something
that's you know a better experience a
more compelling experience than
something like Uber or Facebook or Tik
Tok in order to get you know everyone to
start using it and to us there there are
three things that we get from building
on crypto rails that you know aren't
possible if you're building offchain the
first is you know this idea of ownership
the assets that you're accumulating in
your app are yours you you can get kind
of shut off from the app but you still
have the assets that you've earned and
you can take them with you which is
related to the second Point around
interoperability by building on a
blockchain you can take your assets
experiences with you from app to app so
you can mint an nft on Zora and then go
sell it on openc or any other nft
Marketplace and the third is around
payment so crypto offers a digital first
instant payment layer which is a really
exciting new capability that's not
possible
offchain historically
getting that combination of attributes
in a product required using something
like this metamask it accomplished you
know everything that crypto enables
really well but it requires you to to be
very familiar with crypto and if you
know you don't care about crypto or
you're not willing to go through the
Hoops to set up you know your crypto
life this might be too daunting to you
and it's you know been a big reason why
many crypto apps haven't you know been
able to cater to people who don't know
much about crypto and a lot of the first
popular crypto app experiences powered
by you know these external wallets they
looked like this um they were great for
discret
one-time user experiences come in do a
financial transaction get what you need
leave and then you know come back when
you need to do your next financial
transaction but they weren't they
weren't well set up for multi-session
user
Journeys and the Tex stack has come a
very long way to enable these richer
consumer experiences so you know a lot
of time a lot of the time we talk about
like what are the barriers to Consumer
products really breaking out at C you
know on on crypto rails and there's sort
of like a lot of the ux around making
crypto apps easy to use there's
scalability cheap you know fast reliable
blockchains and then there are kind of
elements around the transaction
experience and making that easier and
for the first time we have a tech stack
that kind of combining all of these
attributes allows us to build great
consumer
experiences and as a result we've seen
the market evolve quite a bit so we've
gone from you know here we're
highlighting you know what we see as
like kind of the most popular most
visible consumer products consumer
crypto products of the year um starting
with you know Financial one-time defi
use cases to much kind of broader defi
use cases to Bringing art and culture on
chain to game
um to social interactions and now having
a full social
layer and you know now we're starting to
see these more kind of Rich consumer
product
experiences but we're at a crossroad so
we have kind of everything we need to
build a great consumer experience um but
we're not at the point where every app
we're using is on crypto rails and so
the question we ask a lot at privy is
What will what will it take for that to
happen and we see two trends that are
both very exciting that are both
accelerating a ton right now that we
think
will unlock the next wave of crypto
products for consumers the first trend
is crypto native apps so products that
are built on crypto rails the crypto
infrastructure is very much core to you
know the product experience that are
going after a mainstream audience that
are trying to really hide abstract a lot
of the crypto mechanics away from users
but crypto is like fundamental to the
product from the outset so one of the
you know most visible examples of this
right now is poly Market which is a
product built on crypto rails but you
know has
attracted orders of magnitude more users
than the kind of core crypto native
population and you know openc
accomplished this Blackbird the
restaurant loyalty app is accomplishing
this pump.
fun is accomplishing this and
the number of crypto products you know
that are crypto native crypto from the
outset that are catering to a broader
audience is accelerating a lot and this
is one Trend that we think is going to
continue
accelerating and we break down kind of
like there are four four common
attributes a lot of a lot of these
experiences have the first is that
they're engaging like they're
experiences that people want to use and
come back to and participate in so
whether that is you know something like
Zora where you can consume content you
can like content as a Creator you get
rewarded for posting content to games
like friend pet to receipts which is a
fun competitive fitness app on chain you
know we're seeing you the basine of just
a fun experience that people want to
engage with again and again as the most
common attribute for crypto native
products that are breaking out into a
broader
audience the second and one that's very
kind of close to home for us at pry is
ux for everyone so even though it is a
crypto experience at its core it is
friendly and familiar to people who know
absolutely nothing about crypto so
whether it's you know what we have on
the left with pirate nation which is one
of the most popular crypto games which
allows users to sign in with Google
login or Discord and get a fully self-
custodial powerful wallet under the hood
that could do anything you need it to on
chain to anime um which is a fun
ecosystem of experiences centered around
anime where you know you could sign up
and start collecting onchain assets but
you have no idea that you know anything
you're interacting with is
crypto to B3 who implemented an
experience uh we call guest mode where
you can get a wallet without actually
creating an account uh which is an
experience that's familiar to people who
shop online for example and aren't going
to create an account in order to
purchase something you know a lot of a
lot of the ux elements of these apps are
accessible for people who don't know
anything about
crypto the next is uh real world tie-in
so a lot of the most popular apps we see
are manifesting in the real world in
different ways so whether that's you
know Blackbird who has many of the most
popular restaurants in New York there
are physical pucks at the restaurant
that you can tap your phone to to earn
rewards points that you could redeem to
either pay your bill or
um get a free drink at the restaurant to
you know seeing onchain Assets in W Mar
and Target as as the pudgy Penguins team
is accomplishing you know showing
onchain Assets in the real world is
another very common element for apps
that are breaking out and then the last
piece is around account funding and
getting people to transact on chain
without taking them through the the
multi-step journey of getting crypto
assets so we have a video here of one of
our customers Rodeo who has a really
nice Apple pay funding flow where you
can you know purchase uh balance that
allows you to Mint nfts in the rodeo app
using Apple pay and you know once you
once you have your credits as they're
framing it here you could just go and
collect the asset and it feels familiar
and leverages you know payment methods
you're already familiar
with so those are some of the attributes
of these Crypton native experiences that
are targeting mainstream users and then
there's this parallel trend of
products that were built you know
without crypto in mind that are
leveraging crypto infra to accomplish
things that wouldn't have been possible
without it and this is one of the most
exciting things we're seeing at privy
right now and it's accelerating a ton
where many many
fintechs in particular are starting to
leverage crypto for payment rail
benefits and and we'll get into some the
other attributes um but this is this is
this parallel Trend where these products
already have a ton of reach they have
tens hundreds of millions of users and
they're giving them access to crypto
rails and the attributes that a lot of
these projects have in common are
one they're looking to use crypto rails
to give users access to USD balance so
this this is a product delar they're uh
one of the most most popular Neo banks
in Latin America and they're using
crypto infra to give people in Mexico
and Argentina access to USD balance um
but you would never you would never know
there's a trace of crypto infra in the
app it just feels like you have a dollar
balance you can you know earn your
paycheck in USD which is a great store
of value and then spend it you know with
a card attached to the account anywhere
you know merchants accept card
so that's a really cool Trend we're
seeing another is that mainstream apps
are are starting to use crypto as just a
more efficient payment rail so this is
an announcement from deal the payroll
company which allows any contractor on
the platform to accept their payroll in
usdc and so not only are you know
contractors getting faster access to the
payment but they're not dealing with a
lot of the kind of big FX hits you take
on both sides of the transaction uh if
you know you were converting from uh
payment in USD to you know a foreign
currency and the bank would you know
take a pretty big fee on the FX
conversion so that's a really exciting
Trend as well and then the last Trend
we're seeing with mainstream products
and experiences building on crypto rails
is some of the interoperability you
benefits you get from building onchain
so earlier this year at
Coachella users who had specific assets
that they bought on openc could then go
on to the Coachella website and Link um
link the same wallet they used to
buy the assets on openc and unlock VIP
passes and there was a special kind of
section of the Coachella venue where
users could go and you know get access
if they had this nft and their in their
wallet and this is like a very early
example of some of the Cross app
experiences where users can users can
take history or purchases they've made
in in one crypto app or one thing on
chain and unlock things completely
elsewhere so the two trends that we're
really excited about that we think will
unlock the next wave of crypto usage are
one you know these very kind of crypto
deliberate products that are finding
ways to attract uh mainstream user base
with poly Market as like a great example
of this we think that's going to
continue accelerating and then on the
other hand you have all of these
products fintech and and largely fintech
but over time we expect many more that
are looking to build on crypto rails to
unlock some of the interoperability and
payment benefits you get
and in our view these are Moment In Time
distinctions eventually you know we're
just going to talk about crypto as an
enabling technology that products build
on and so this you know crypto native
vers mainstream product is a very moment
in time distinction we think you know
these two Trends will converge and
everyone will start building on crypto
rails in order to access the things you
get that make crypto special
we think kind of as that plays out it's
important
to keep your keep your focus on the
things we get from crypto and what we're
all building toward and
not you know concern ourselves with okay
I believe crypto needs to evolve in you
know whether it's this chain or this
user base or that user base and just
really focus on what are the unique
benefits we get from building on crypto
rails and you know the last thing we'll
leave with is you know we really believe
there's never been a better time to be
building products on chain you have all
the infrastructure coming together you
have all of the energy behind crypto the
visibility we're getting as a market and
we're really excited to see the next
wave of products that that come so thank
you all very much for the time and if
there are any questions happy to take
them thanks Max I hope everyone took
some notes on how to build a popular
product so without further Ado let's go
talk about some of the questions so we
can look right here the first one is
what is an example of a popular feature
that drove massive adoption for a
project
yeah one of the most kind of Novel
things we saw in a
product since starting privy was how
friendch really leaned into to an
existing social graph to make the first
time user
experience a much richer experience um
you had a bootstrapped so to to rewind
for a second frch when you signed up
asked users to link their Twitter
accounts and then there was a populated
social graph and you know users that you
were familiar with and that kind of
immediately gave the app experience some
more life you had kind of friends and
recognizable faces on the app and I
think that is one of the patterns that
that team introduced that you know we
still see everywhere today that made for
a much richer experience agreed so the
next one would be why is most web tree
adoption focused on speculative platform
like poly markets or memec coin is the
trend overshadowed the development of
real world utility in the web tree
space yeah well
because the crypto rails make for easy
transaction experience
is you know facilitating whether it's
trades or or bets is like a very kind of
easy to standup use case we we have a we
have a framing at privy uh where there's
sort of we we call it the carrot in the
stick and up until very Rec
recently
because the ux around crypto experiences
was a bit tougher it was a bit kind of
more Hoops to jump through to get up and
running in the
app apps needed to incentivize you know
why should I use this app with a little
bit more of a carrot whether that's like
speculation or or yield to get the user
to drump through the the hoops and we
think kind of as the ux improves
you can have less speculative use cases
because it's you know the same reason
why I would get up and start using any
product um I can just kind of use the
crypto product and enjoy whatever the
real world experience is behind
it okay so the next one is the tradeoffs
required to enable ux things like Google
login wallet seems to stretch Definition
of non-custodial is it really
non-custodial if I need to log in to a
specific provider yeah so this one gets
a little bit into like the mechanics of
how privy works but when a user creates
a wallet with privy we split the user's
private key into different
shares and they're assembled in a way
that you know neither privy nor the
customer we're working with has the
ability to access the user's private key
the user is the only party that can
actually you know assemble the key on
their device and control the wallet and
so even though you know Google is the
signin method that's only one the the
kind of oth link is only one out of the
three shares that we split the key into
and so you know that doesn't kind of
make the wallet experience
custodial okay so we have time for one
last question this pretty interesting
one as well what's the industry that you
think will onboard the most users on
chain in the next 5 years
yeah we're really excited about what
we're seeing in the fintech and payments
market so seeing you know all of these
Neo Banks really starting to lean into
crypto payment rails to give users
access to USD faster cheaper payments
you know potentially better Financial
products over time we think that's a
really powerful driver of adoption and
you know if every banking product over
the next 5 years somehow incorporates a
crypto payment Rail and gets their users
wallets that's a really massive Tailwind
for usage in the
market Thanks Max can we give him a
round of applause for the insightful
conversation they
had stay tuned we'll be right back at
thank
you thanks man
J
okay hello hello
so all of you who haven't there will be
a QR code that you can scan and it will
allow you to ask questions um it will
allow you to collect a stamp that you
actually have been here so please do
that don't miss it out there will be Q
section after this and the next speaker
is Rebecca Kinski and she will tell us
about how to streamline Mass adoption by
uh detecting common mistakes in web tree
design give it up for
Rebecca SW we're going to be jumping
into bootstrapping your dapex but first
I want to ask two questions
who here has struggled to make a complex
crypto app feel simple to new
users and who feels that resource
constraints on their team have made it
difficult to create an ideal user
experience if you face these challenges
you're not alone together we'll be
discussing how we can Implement best
practices to help you overcome these
challenges and bring the next billion on
chain now before we dive into Solutions
allow me to introduce myself you might
know me as the crypto bride about three
and a half years ago I exchanged nft
wedding rings with my now husband on
ethereum Main net uh we used of course
we overpaid in gas this was before any
layer twos existed but you know what
they say love is
priceless and about me professionally
I've been designing and leading teams
for the past 15
years most recently I led the design of
coinbase Commerce where I help
businesses use crypto
payments now as a defi design consultant
I help businesses that are tackling the
same challenges that you're facing so
with that let's dive in to how we can
bring those next billion on
chain to guide us I want to introduce
you to a framework that I developed
through through analyzing dozens of
popular defi apps I call it the DAP
funnel it outlines the key stages people
go through when interacting with
decentralized applications from their
first interaction to transacting and
Beyond the stages are connect configure
transact and
track each stage represents an
opportunity to either engage people or
lose them
let's begin with the first stage
connect this is all about connecting
with a
wallet as I was doing my research I
discovered that where to start is often
unclear best practice number one make
connect
obvious let me start with what not to do
don't don't mislead with interactive
zero state so here's here's an example
on B you can see that I can enter an
amount to deposit but the button is
disabled and I don't know what to
do another common mistake is what we see
here on pancake swap where somebody
comes in wanting to do an action such as
swap but the call to action button says
connect wallet so any kind of benefit to
surfacing this interactivity is negated
by this disconnect
what's better is how Zora and Lido and a
few others are proactively surfacing the
login
screen best practice number two
streamline
options is anyone here designing cross
chain
daps awesome here's another example of
what not to do don't combine Network
selection with wallet selection it's
just too much information it could be
handled in multiple
steps stay Time by implementing a
ready-made wallet plugin there's so many
options out there that will simplify
onboarding another great option is to
combine the disclosures with your wallet
screen um people who are familiar with
web 2 will likely click on the upper
right corner and they logged in account
don't do what curve does and a few
others that instantly log out it's quite
jarring disorienting and instead um
offer an interstitial menu this is an
example from arbitrum bridge where
people can access their settings and
other
options rounding out this topic of
connect consider using a pass key this
is a really awesome Innovation that
we're seeing more people adopt um and I
hope to see further
streamline techniques as we move
forward all right moving forward to
configure this step is all about setting
up the transaction it's about selecting
the asset entering an amount and
choosing a network and sometimes
configuring more advanced
options and here the two themes are to
many choices being overwhelming and
using technical jargon can can
intimidate
users let's start with
personalization Pop Quiz do you notice a
difference between the logged out stage
and the logged in
stage if you answered no you are
correct uh this is a missed opportunity
unfortunately on boring Dow's part where
uh it's not suggesting a token or a
network instead do what Unis swap does
here where it's suggesting tokens in my
wallet and even suggesting prior
searches from previous sessions so it
really feels like they know
me another thoughtful approach is
personalizing by Persona so look at here
how blur has two different user types
there's the trader who wants a more
information dense View and The Collector
who wants a more curated
experience similarly similarly on bridge
there's an expert mode um and this is
great if you feel like you might be
alienating some of your power users by
simplifying too much this way they can
easily access those more advanced
features starting with good defaults
should minimize the cognitive load but
what happens when people encounter
errors we need to enable better recovery
and hopefully prevent them let me start
with a great example of error prevention
here on Hop it suggesting a minimum
amount for me to send so I don't get an
insuff insufficient funds error
be sure to check your error messages
this is a a really great example of how
somebody may have forgotten to translate
this into something that makes sense
explaining what happened and what the
user needs to do to fix
it and double check that what you're
saying to fix it actually
works instead deep link into the wallet
to overcome that issue recover here
as igen layer does by switching to a
supported Network in this
case I recommend Progressive disclosure
also to simplify the
interface here on llamas swap the
slippage options are visible at all
times which it it makes the interface
too cluttered and it can increase the
drop off
right here's another example on beefy
where it's showing the increments from 0
to 100 100 probably not a widely used
feature and it makes it look a little
messy instead check out how Thor swap
buries those options underneath the max
button so for the items that are visible
in your interface I recommend showing
some education providing more context to
increase confidence in the
transaction so let's avoid using jargon
here's an example from rocket pool where
it's using a term that probably everyone
in this room knows main net but it
doesn't map to an option within most
wallets so instead use straightforward
language tool tips are a great option to
explain in
detail everything that a transaction uh
has I also recommend including a
confirmation screen that gives the user
an opportunity to review all of the
details before moving
forward assuming all the details in that
transaction look good we're ready to
transact this is the core of all dii
applications um it's where people
authorize access to their funds and
transfer it's critical that people feel
safe
here unfortunately lengthy approvals can
scare and
confus the best antidote antidote to
that is to convey progress
ress okay who's used a in this room
probably everyone right it's like one of
the oldest most popular daps out there
but unfortunately it uses buttons in a
very non-standard way this is not the
best component for showing a multi-step
transaction you see how they appear and
disappear without any kind of
confirmation what's a better pattern is
what Unis swap does a stepper right it
those what are the actions that are
required what are the status pending and
confirmed I also recommend showing in
context feedback through toast messages
as Aerodrome does
here don't misrepresent status so here's
an example from Lio which is
optimistically
presenting modals saying you are
unlocking you are wrapping uh but it's
before I've even had an opportunity to
confirm in my wallet so it's not really
accurate and it reduces my trust in
their
system instead uh do as as moonwell does
which encourages once I've reached the
pending status to continue using the
application okay this one's a little
controversial but rounding out the
transact phase um let's not do infinite
approvals you see this long scary Red
text uh this you know with the current
constraints we're in right now um maybe
a lot of this will be solved with smart
wallets uh but until then let's use
exact amounts so that it maps to what
the user entered into the system and
it's also more
secure now the final stage track this is
all about monitoring the status so
people know what happened and what they
can do
next here we observe limited access to
historical and ongoing
performance here are the three stages of
the tracking life cycle in most staffs
There's real time ongoing historical let
me break it
down for real time we covered that in
the previous section transact and this
is all about in the moment when you're
investing you receive that feedback de
right but ongoing is missing right we we
want to understand the day-to-day
performance of Investments including
returns and the yield uh the patterns we
see here are dashboards and
notifications um this helps people make
investment decisions what to do
next and then the history we're this is
all about
recordkeeping um of the past
transactions account statements and this
enables accounting
it's critical that we support each step
of this journey in our
dep so how do we support ongoing
performance
tracking let's provide apy history uh
this is an example from a it's very rare
I did not see many of these in my audit
please share examples if you have them
um you know anecdotally a friend of mine
takes screenshots of the apps where he's
invested
uh to see whether or not his apy has
gone down which is not
ideal let's also summarize the portfolio
insights this is from Aerodrome a
dashboard that shows kind of the return
and the emissions and other things that
earned this is definitely not the best
but I I challenge you to provide better
examples um I want to leave rounding out
this ongoing performance topic I feel
like a missed opportunity here is push
notifications for crypto I think there
are a few Solutions out there but it's
very much lacking um here's an example
from a trafi account I received a an
email notifying me that the yield went
down on one of my accounts um you know
how do we know if we're about to get
wrecked that's that's kind of a core use
case for a
notification um and I I I welcome some
solutions there
finally raise your hand if you've ever
tried doing taxes on your
crypto it's a nightmare
right uh so on uniswap you could see
that there's transaction history but
this is not a common feature in most
apps and here on dbank you can see an
example of aggregating statuses but
again this is this is a third party it's
a little lagging and it this source of
Truth should be on your dap
itself all right so we covered all of
that woo so here's the big takeaway here
I hope that you can Implement some of
these best practices in your dab today
to enable better adoption and
retention well I'll let people finish
taking their pictures um U please share
your feedback on on X but first first I
want to leave you with one final idea
what could we build together if we're
not building in
silos I propose that we align on web 3
design standards imagine a world where
every dap developer had access to
plug-and-play components that were fully
user tested responsive open
source right it would enable greater
efficiency you could focus on your core
project area it's a proven model we've
seen this with Android and iOS and also
the very popular bootstrap
framework and finally it's ecosystem
strengthening it would help on board the
next billion because they would become
familiar with the patterns across every
single deck rather than learning bespoke
implementation there are a number of
tools that exist today um you know
they're pros and
cons of the wallet Integrations and sdks
out there you know some of them are
promoting certain wallets or chains um
but I think we need a neutral
community-driven
solution so I'm looking for people to
build this together with me frontend
developers designers researchers please
reach out if you'd like to be a part of
this thank you so much kapunka
great
talk amazing Rebecca okay let's uh ask
some questions uh if you guys have a
question uh you have to you you have to
use the code to post it on the app and I
will read it out okay let's start with
the most voted a question so first one
is about using tool tips on mobile what
is this alternative because it's hard to
use tool tips on Mobile H it's a good
question um I've seen different patterns
Implement like a mobile version which
would be like a
modal uh or like a bottom sheet I guess
if it's a native
app okay uh do you think wallet
popups so are this is fair you know
actually I uh what was the stat only
like 10% of the most popular daps
actually do have uh a mobile optimized
experience so definitely it's an
opportunity for us to build more
responsive libraries
um I think you know they're different
use cases right there's some serious
traders who prefer desktop um you know
and so my audits were desktop components
but clearly there's uh definitely a lot
of Need For Mobile as well so sorry this
the wallet popups for approval or B um
so the next question is don't you need
product Market fit before you can
consider
uix oh that is a great question I I
definitely agree on that and there's
there there was a really great talk um
yesterday about how to quickly validate
ideas by just really mocking up two
parts of the flow the point of Discovery
and then the point of value
um and then you can decide whether or
not to build the middle of the product
experience so it could save you
potentially a lot of
effort okay the next question is should
user know uh they are using crypto
yeah there um so many great topics about
this uh or talks about this at this
conference specifically uh I think
longer term as we're looking at
onboarding the next billion it's not
necessarily what I shared today it's it
is abstracting it and making it so
simple probably likely
behind um you know a very simple
interface okay um next question is about
using tables on mobile how do you
approach
that there are various options I
guess uh you could either stack I don't
there I'm not sure if I'm the best
person to share this right now but yeah
they're they're different patterns that
you can look up okay uh when you think
uh when do you think chain OB section
will be the new normal in
defi
try m i wonder if it's a h what's the
hindrance I'm not quite sure about that
I guess is
this who wrote just want to somebody
what is hindrance oh yeah like what is
the hindrance
of what is preventing people from
distracting is somebody who asked this
question here maybe
oh okay so this is kind of like the
other question around it
being like all of the uh complexity
being hidden
okay yeah I'm with you I think it
there's that is the future and I think
we'll see a lot of advancements when
Petra is upgraded in q1 so let's stay
tuned I think what I shared today was
focused on the technology that's
available right now what you can build
today but that's definitely soon and
then later I think is the standards
where we kind of as a community agree on
the best practices and how to implement
common patterns okay uh next question is
should we be moving towards um embedded
wallets uh inside apps that are less
portable or continue to push in portable
horizontal wallet
uh which are not perfectly suited for
each app which are not what perfectly
suitable for each app yeah like metamask
versus um you know the wallets that you
get inside of your application yeah I I
watched one of the talks about this and
I guess like right now it seems
like they you know wall some wallets
like privy and others that will create
per uh D but but the vision I think is
to consolidate
across okay the focus of this was daap
ux not wallet so okay I think that's uh
it for the time for the Q&amp;A uh thank you
very much Rebecca thank you everybody
who asked questions and uh next uh talk
is in 5 minutes see you okay
sh
welcome to the session where all your
questions about uh embedded wallets are
going to be answered and for that we
have here Cindy and Greg please give it
up for Cindy and Greg
hi everybody it's good to be
here so today we're giving a talk about
what evolving standards um different
account models and how that changes
usability okay this talk is basically
going to be about endgame wallets and
the connection between wallets and
deps am I okay
sorry all right so a little bit of
background of what the ux looks like
today is that dap ux today is
constrained by the concept of the
account model so what that usually means
is that when you visit a dab the purpose
in life of that dab is constrained by
the thing that you're trying to do on
chain and also um the private key
signatures and like how you interact
with that
dab all right there are a lot of account
abstraction talks I realize at this
conference so I don't want to spend too
much time but these are properties that
you get when you're um signing with a
single signature so you know your entire
account gets connected Key Management is
all on you no native batching and yeah
you have to have native gas
tokens these are the common pitfalls
that I think most of us are familiar
with so no recovery upgrades signing
message for virtually every action that
you have to do and also having blocked
experiences on daps where you need to
connect your wallet to be able to see a
quote or you need to be able to connect
before you do
anything all right so what's at stake
here is something that I'd like to call
the app ification of daps so instead of
like the DAP experience being one thing
and then using like a legacy app and
being another thing it would be great if
they're more
Blended and the properties of that would
be enhanced security smooth onboarding
and what I want to say convergent
applications where you're blending
onchain offchain and cross-chain
component
on oh I'm blocking the QR code I'm so
sorry maybe I'll come over
here all right so what I want to do now
is give a tiny glimpse into what greater
programmability and security on Smart
contract while it's actually looks like
on a UI I don't want it to be too um
detailed or implementation specific so
these are just general examples of what
can be done in the future all right so
it with smart contract wallets they can
run code and with that you can get
conditional logic one use case that I
think would be pretty interesting is
like let's say that you are a ADB and
you manage portfolios and you want to
add a security service that says if
there is an onchain condition that is
met and we are able to prove that there
is an exploit or there's a vulnerability
in this stab please remove my exposure
and unwind my positions so in order to
do this you have to pre-sign it and then
you would be waiting for the condition
to be met and then you won't have to
unwind it manually as you do
today other things you get with smart
contract wallets you can do cross-chain
calling and balance aggregation because
you can query the state of other
contracts as a smart contract wallet so
this means that let's say I want to buy
an nft on Zora and I only have funds on
optimism and mainnet this doesn't have
to be a problem because we can aggregate
the balance and Bridge it for the user
on their behalf so this means that the
click path is getting much lower so
you're not clicking as much and
approving everything looking for which
Bridge has the liquidity that you want
and numerous other things that we have
to do
today okay this use case is this example
is the most important one to get right
because user Ops are not like highly
adopted right now it's still pretty
early so the thing that we need to nail
is the onboarding and the issuing of the
smart wallet I mean the smart account so
so what I say here is modular
authentication allows users to define
the daps level of access so this is not
unlike when you sign in with Google and
Google's telling you oh when you're
going to calendly I'd like to see your
contacts and your calendar and what you
have set up there we could do this on
chain as well with smart accounts so in
this example I want to show that um it's
looking for a specific domain that you
have set and then it wants to request
access to um a spend limit or maybe
usage of modules that this DB wants to
use okay so those are some very
highlevel examples of what can be done
in the future or even now so the upshot
of all of this is that you can get
better blending of offchain onchain and
cross-chain components this is the a nod
to the convergent application thing that
I was talking about so that daps don't
feel as single
purpose the thing is though like many
comple Le Lex systems when you introduce
new Solutions you can also risk
introducing new frictions and I'll gloss
over this very quickly is that now that
we want fewer approvals currently right
now with the standards that we have is
that you do migrate to a new account and
funds get fragmented even though there's
fewer approvals um that is a user
friction that we might have to deal with
obviously the evolving standards and
there's different ways in which that we
can try to deal with this so there's
also enhanced programmability this means
like uh they the contract can run code
it's like currently the EA they don't
have um like it can't actually read
state or anything like that so uh EA is
still initial signer for it so that's
another user fiction that is possible
gas abstraction paying gas and other
tokens other than the native token of
the network this is not gas optimized
yet because we are uh we're still prior
to 7702 being on pectra I think and then
we have account recovery these can
introduce unfamiliar user patterns so
the one that I again like the one that I
want to focus on is the onboarding
aspect which would be the modular
authentication because there's a
plethora of solutions that um you can
choose from for implementing the
onboarding of smart accounts and so I
want to hand it over to Greg so that he
can show you some best practices of how
to implement a helpful
experience thank you Sydney
sorry okay perfect sorry I forgot where
we were at um how many uh how many
people here are familiar with like The
Capes chain agnostic Improvement
proposals this is good we need to change
that how many of you are familiar with
eips keep your hand up how many of you
actively check the eips of the
erc's how many of you are wallet
Developers
how many of your applications as boy
smart contract
account yeah we have to change all this
basically in order to get any of this
done we need to start focusing on
standards more and so I'm going to
verbally assault you all with some very
important erc's and show you exactly how
we get to frankly what's probably the
endgame wallet to DAP interaction where
those pieces fit together and how we do
it it's going to take a couple RC's
capes um to get there fr frankly though
they're all available they're live and
there's other versions being iterated on
so we're not too far away it's just
going to take some work because we need
more people actively working and looking
at standards um these are the main ones
we're going to be talking
about uh I 275 4337 which we should all
be familiar with 7702
cover let's start though with some like
visual stuff um and then I'll kind of
stitch it together at the end when you
first go this is a website that's live
basement.
fun um launched by B3 team
when you first go to the website you get
to experience the entire website without
ever needing to get a log wallet prompt
without needing to actually install
anything without even needing your funds
the way they do that is by embedding a
embed uh they put an embedded wallet
behind the scenes for you and there's a
reason they go with the embedded wallet
behind the scenes
it's because you don't have to actually
they don't want to force you into a
smart contract account right at the
beginning because that would just cause
further fragmentation if you come to the
app later with your own account that has
a smart contract wallet enabled now we
now we're already just fragmenting we're
splitting up your accounts where they
don't know about each other so now
you're having to maintain effectively
two separate bank accounts I don't know
if anyone's done banking with two bank
accounts but it's like unenjoyable so I
don't know why we'd Force our users to
do it similar which is 7 tri5 and Cape
mobile app developers here maybe mobile
game developers have you ever tried to
actually connect to somebody else's
smart account or even someone else's
external wallet it's borderline
impossible and that's because you can't
discover the ability to discover a
wallet and then know where it's deployed
is practically impossible that's what
Cape 275 tries to do it's the idea that
you basically look up Greg the greek.
eth and and instantaneously I'll figure
out where the address is what type of
account is it eoa smart account safe
account is it someone else's isoteric
implementation and we can then use a
wire protocol which is the o one to
basically go and connect to them
because we do know everyone's familiar
with pass Keys we know that that's
probably the best way to remove seed
phrases but how many of you know that
your pass key is scoped to the website
you issued it from or the app you issued
it from
that means if I generate a public key
from the pass key it's only going to be
found there if I go to chainsa doio and
I issue pass keys that way if I go to
then Sprinter dotech and try to issue a
pass key there I'll never get the same
Pub address and this is a fundamentally
big problem because we're all issuing
pass keys with our smart
accounts so we need to create a way to
bridge that Gap and that's what 75 aims
to do and I'll get into it a little
about we're going to stitch this all
together don't worry it's going to be
less confusing us a promise 7715 this is
pretty this is also an interesting one
because what we do is we start to say
hey if I'm going to remote into somebody
else's smart account and I'm going to
ask to use that smart account with a
pass key that I don't
have I don't want to constantly go back
and forth the ux breaks you're
constantly flipping out of like a mobile
game that's supposed to be pretty like
non keep you in the game and now you're
going out to sign every single time you
need to do something so what 7715 tries
to do is it basically says hey we're
going to let a random key AKA this is
where we tie the embedded wallet back
into the picture the embedded wallet can
now act as Aigner to the wallet for a
given period of time and if you're
thinking about the web 2 model this is a
JWT token all we've done is brought back
the JWT and said put some cryptographic
properties to it and that's how we can
maintain it so you can maintain your ux
in the app and use an embedded wallet
now you don't need to deploy them a
smart contract account you can use what
they already have in pre-exist exting
infrastructure finally
want a smart account features there's
stuff that the smart account doesn't
actually provide you it's simply a
plugin build it as a plugin you tell the
wallet to register the plugin you get
the full benefit of deploying a smart
contract account for someone without
fragmenting their balance you get you
remain the existing experience and the
and the big thing to discuss here is
which I'll get into and then is it the
next slide no uh oh yeah it is the next
slide perfect
and so this is these are all the eips
erc's um that Stitch it together what
we'll do is we'll go through a little
interactive game of actually stitching
together to show you kind of like how
the endgame in one to two years time
will actually look like because we have
a lot of teams that are doing really
good infrastructure work at the
application layer but frankly because we
don't have the all of these things
plumbed in we're we are frankly setting
up the applications for a little bit of
failure and there's going to be be a
period in time where we're going to see
Mass migration of like self- deploying
app infrastructure outwards and my main
argument I have for this is there exists
two spectrums of ux that we need to
maintain as an app developer there's
your local app which we have full
control over and that's why we're
suggesting you deploy with embedded
wallets because you can fully control it
you can make your per decks that's fully
on chain look and feel exactly like
Robin Hood you get all the benefits so
there's no reason to go anywhere else
the other thing is we have wallet land
ux and most after flers think we don't
have control over this and that's where
we're hoping to tell you something else
because you do you have to control that
you don't change it the minute you go
and change someone else's experience of
how they Bank effectively you know with
your app it's breaking it and when you
deploy a smart account into the
application layer we've gone back to the
old principle of you know think about
like uh like Starbucks you have to put
money into the Starbucks app your bank
now no longer knows how much money if
you moved $100 in there you don't know
that you have your bank account Value
Plus $100 that you have unspent in
Starbucks you just have minus 100 we
have the ability to not do that we have
the ability to not fragment and deposit
funds but rather borrow funds directly
from the bank with a scoped permission
and that's where we're going to acheve
cheve here so what do we need to do to
get this done the whole pipeline is
going to be looked like this we want
people and wallet INF for teams to
deploy 4337 we want them to be the smart
account issuer if they're not the smart
account issuer if the app ends up being
the smart account issuer you need to be
able to rage let the user rage quit you
need to be able to set permissions like
are you comfortable as an app developer
saying oh yeah I want to make sure when
I get into a chain abstracted
multi-chain
future that the user always has one
Ethan main net because they always want
to make sure they have gas to pull out
some a positions or compound positions
that I don't know about they might want
that preference but are you really ready
to actually deploy all that info or do
you just want to focus on your app let
the wallet handle that
part we then always pass keys are the
way to go it's going to it's already
like this today and it's only going to
get better we have solutions to do like
multiac account pass keys where the
address
persists the wallet the app is where
you're going to deploy the embedded
wallet within that app we see Cape 275
come in and I want to think about clicks
so keep your hand up thinking about the
clicks we're going to do here when the
user first offs onto your website
they're going to type in their
identifier email phone number Ens name
they'll click enter once I'll then go
and look up in the you then look up in
the registry you figure out who issued
it who their provider is the smartcon
account provider and you go to that
website directly this is now going to
look like an iframe this is what 77 75
does think about that iframe you're used
to you know when Google says hey can you
someone says can you log in with Google
so I can get access to your calendar
information it's the exact same flow
that's going to pop up the you know the
destination where the smart account is
it might be the NOA safe website once
you get in there along with that message
we're going to pass in
per desk I want to trade a th000 usdc
every hour for the next 24 hours that
means your total bound is 24K worth of
usdc that could be you know taken by
this application but it's definely
strictly defined the same way Google
strictly defines your login
process 7579 I talked before you know
you want that extra smart contract
functionality on the same wire protocol
the same 75 wire protocol that should be
else you need you need that extra
functionality as a plugin it's it's
simple you just added in the OA screen
shows the exact same you know same view
you probably haven't seen this yet it
came out like a few days ago but like
the simple thing is you know when you're
an
app do you how many of you develop your
app and then go okay cool step one R hit
the RPC for like every available token
balance that this user has there's no
need it's already been done for you the
wallet knows what the user has available
and in a cross-chain multi-chain world
the wallet also know how much is a
available against other chains as well
as what the spending power is I have
usdc I need to use eth to go buy an
nft it knows that I can convert uscc the
app doesn't need to know about that so
this makes an extension for it there's a
pleural of other ones we can add on to
here but if you think about it at the
end of the day what happens with this
experience remember how I said to think
about the number of clicks we did for
the user here there's
two we've reduced it to two
you go from looking up your account
automatically generating the popup
iframe if anybody's used coinbase which
is bases wallet recently there's that if
frame that pops up that's your ooth
window the user clicks one click ooth
windows up one more click to confirm and
now you have the full power of that
smart account locally while only using
an embedded wallet and you can ensure
the security remains constant because
the permissions are there in place and
you have the full flexibility you never
had to deploy account any sort of wallet
infra you don't have to care about the
wallet infra you don't have to even care
about what app what type of
implementation do they have because you
can attach the plugin you need so you
can ensure even as long as they're 4337
compatible you can boot in anything else
you want you don't have to go and deploy
them a custom implementation your
onboarding experience just 10 X's right
out of the gate this is what the endgame
realistically will look like how close
are we we started with 7
tri5 realized we needed 715 this one's
almost done there's a few last little
things needed modules by rhinestone has
been done forever and frankly if you
haven't looked at them you should this
will be pretty quick 275 is live lits
using
it and we already know we've got pass
keys and 437 we just need the
permissions module to finish and we need
to get the main wall providers to start
adopting the slugs so that we can have
those popups happen and you have a full
ooth Journey that when you go to onboard
your grandmother it just looks or your
mother it looks exactly like how they do
by logging with Google and you can issue
all the infra underneath blindly and so
that's this is the end game for wallets
this is how we envision it um and
frankly you know we need more people
looking at standards and helping just
like see what's out there and realize
like what they can do with what's
available cuz all this already exists we
can have this we can have a two click
journey and you get a smart account
without ever having to deal with that
INF for
yourself um oh there's more
slides
ah yeah time for you want to do that I
don't know yeah like yeah time for
Ground Zero good dab
experience thank you guys let's keep in
touch okay we have uh time for questions
so if you have questions you still uh
can ask them we have two questions
already uh so first question is what is
that we missing or need to change on
layer one in order to enable better
experiences for every and not just a
specific Layer
Two native account abstraction that
doesn't look like
that actually achieved its goal there's
a lot of uh chains that actually have
that at the base layer and uh 7702 is
good it's a migration tool it's a stop
Gap we're going to have to release more
account abstraction features down the
road natively um but unfortunately
that's like the biggest
one okay so uh next question is about
pys you said that the problem with them
is being scoped to specific sites uh but
later you said they're actually good
that we should use them so what is the
solution here two separate problems so
the one prom is that when I issue a pass
key you get a public key like when you
do a pass key authentication you know
face Touch ID whatever it may be that
issues you a public address and it it
works the same way that a UB key works
what happens is they basically say cool
what's like the DNS record and they
match that DNS record to a new publicy
generated on the pass keychain so the
problem is if I go to another website
it's going to make either get a new one
or create a new Pass Key and so you can
never have that same address persisted
through and so that's why you have to
push outwards if you want access to the
signing key of the smart account you
actually need to go to whoever generated
the pass key in the first place and
that's why we need that ooth Windows the
same way Google doesn't let you just
like ooth inside of like an API call
inside some random website it would just
be very
insecure okay uh next question is um if
we connect our wallets to apps in this
way that you describe and there's all
our savings on these wallets is it going
to be safe enough how many of you trust
no is safe or
safe lovely do you trust safe to provide
you the UI you need to ensure you're
signing the right
message this isn't
rhetorical okay good in that case if you
trust them to provide you the correct UI
when you sign a message why would they
not provide you the correct UI when they
say hey by the way this thing's going to
drain your
account instead it's going to say hey it
just wants to spend like a th usdc for
the next like two hours and then it the
token expires and they have to refresh
that token same thing as a JWT with your
bank if you trust the people providing
you the wallet then you should have no
problem actually using it in this system
it's the same problem with like it's
exactly why I said you you as an app
developer are you actually comfortable
deploying all this infra even the per
the person giving you the smart account
are they giving you all the infra you
need to ensure your users are safe push
the barrier to the wallet
there's a last question I think um next
question uh in the end game are token
Ballance is still held on external
wallet or smart contract address
account okay and uh Banks often have the
backup of support uh will the wallets
provide the same
backup I mean pick a good
provider metam Mass support's pretty
good on Twitter
I don't know I think this question is
really interesting I it's more like an
insurance type of question because I
think banks are like they have FDIC is
the quest it seems like this question is
asking about like support of user funds
which I think is external to wallets
themselves or recovery mechanisms yeah
exactly okay if there are no more
questions uh that's it please give it a
round of applause for Greg and
Cindy thank you
you know I I was
and in this session we have Andrew Leu
and DC por telling us about how we can
use intent addresses for cross chain
interactions welcome on stage
hi
everyone really glad to be here today my
name is Andrew and this is my this is my
coworker DC Posh and we are from the do
team over the past few days there has
been a lot of talk around um the
fragmentation of ethereum and how all
the l2s are separate and creates a bad
user experience for trying to interrupt
between these
l2s the past few months we've been
working on something new at da that
we're excited to show you today this is
a step forward towards unifying ethereum
using technology that already exists
today while maintaining the core values
of permissionless and
trustless and let's get started with DC
introducing the problem of segmentation
and what it looks like today sounds
great hey everyone yes I didn't for get
about this by the way they scheduled us
back to back so I just got off of a
panel on the next stage over came
straight here glad to see you all um
let's talk about this
so we're gonna oh see do you have the
clicker yeah perfect thank you so the
problem we're going to talk about today
is one that I think many of you are
going to be very familiar with uh how
many of you here have used poly
Market how many of you here have ever
seen a screen that says something like
you know only send this token on this
chain other funds might be
lost all right more than half for sure
um and this is a very common ux right
now so it's like select polygon as the
network not polygon ZK evm or you may
lose funds um and it's also a problem
that you've probably heard a lot at
Devcon where it's like a lot of the
talks here like about uh rollup
fragmentation and about chain
abstraction and about things like that
and I think the aspect of what we're
about to show you that we're really
excited about is that we're going to
only talk about things today that work
today um so so I think there's a lot of
interesting sort of forward-looking
things that people are talking about
around things like uh chain specific
addresses around things like uh wallets
that have bridging built into them uh
but we're going to talk talk about
things that work right now with wallets
sort of on any chain um and even with
you know custodial apps like coinbase
like binance like lemon um yeah what
we're what we're shooting for is
something like this is from one of
vitalik's recent pieces this idea of one
ethereum something that feels like a
cohesive ecosystem and what we're
shooting for is something that feels as
easy to use as smooth as something like
Apple pay so you have you know like one
action you click Send and it does
whatever you wanted it to do
yeah I'm going to talk very briefly
about sort of the background of like
create to about cross-chain accounts
about sort of the ideas that inspired
this um and then we're going to talk
about intent addresses which is the new
thing we're presenting today um how many
people here have heard of or like know
what create 2
is oh hey wow that is okay very
technical audience that's great perfect
yeah so it lets us commit to a uh it
lets us commit to a contract we can make
an ad address that only one specific
contract with specific functionality can
exist at that address the sort of
original main use case for this what a
lot of it has been so far is these
cross-chain accounts um so we should do
the next slide with the diagram on it
yeah perfect so this is this idea of
like okay EAS work everywhere you have
things that only work on certain chains
um so for example like if you heard of
the winter mute hack two years ago um
where they had a a Nosa safe that hadn't
yet been deployed on a different chain
and then someone sent funds to it it was
a s time um with this you know with like
uh cross chain accounts Universal
accounts you can use create 2 and 4337
to make an account that just works on
every chain um and even like new evm
chains that don't exist yet that one
specific contract will be Deployable
there um there's a whole nice design
space around that and we thought what if
we could go one level deeper what if we
could make this more General
um and so what an intent address is um
let's do yes perfect so intent address
lets you accomplish an arbitrary action
just by sending funds to that
address um so if you can imagine like
let's say I want to put $70 into poly
Market we can generate an address that
represents that intent and then if I
send $70 worth of any coin on any chain
to that address then reers will be able
to come in and permissionless do the
rest but only that so there's no you
know counterparty risk you're not
necessarily trusting anyone um it's just
by sending money to this address you're
expressing an intent of like I want $70
to show up in this uh you know uh other
place on this specific
chain and so these are the kinds of
things so sending funds via a transfer
via a permit and you can accomplish all
kinds of things like a deposit that was
the example that I started with you can
do swapping and bridging you can even do
arbitrary contract calls um on the
receiving side we did a really nice
launch with our friends at ethereum OS
uh Freedom Factory you know they make a
new uh a new kind of Hardware wallet and
the pre-sale for that involves like
minting a pre-order nft and that's an
arbitrary contract call but you can
still do it via a single
transfer um yeah with that I'm going to
hand it back to Andrew and he's going to
walk you through the difference steps of
like how we can do progressively more
with intent
addresses one way you can think of
intent addresses that would make it
easier is think of it as sending funds
to someone's wallet address and they
execute a contract call on your behalf
now this sounds kind of worrying you're
sending tokens to someone that you
potentially don't trust and they can do
anything on chain with your
funds this is what the problem that
intent addresses solve you send
uh tokens to an intent address and this
intent address permissionless and
trustless guarantees that only one
action can be executed on chain how do
we do this we we use create 2 like DC
mentioned to do this for those of you
that don't know create two um is a way
of deploying smart
contracts it takes a hash of your
contract code and generates a
deterministic address that you know
beforehand if you change the code you
change the address that the contract is
deployed to this way you know beforehand
exactly what the contract is going to do
when you send the tokens to this
address so we'll use an example here of
minting an nft on using
usdc so I transfer tokens to this create
in deploy the contract to the address
and this contract can only do one thing
it can only mint an nft with a contract
you specify it mints the nft by sending
tokens to that contract and gives the
nft back to the
user now what's the point of doing all
this to all this fancy stuff with create
the first thing it enables is a single
wallet popup to uh execute this contract
interaction the normal flow has always
been approve the contract then uh
execute the contract call this is
something we' become numb to in ethereum
and a terrible ux for users that we've
just accepted as something that we have
to deal with with intent addresses if
you noticed all you have to do all the
user has to sign is one transfer
interaction no more two pop-ups just a
single popup to uh execute an on- train
call another benefit this gives you is
it allows people to pay or to interact
with contracts on chain using an
exchange so you can now mint and nft
interact with any contract on chain with
a coinbase or a binance account you
transfer funds to a predetermined create
uh contract call on your
behalf now how does this move us towards
a unified
ethereum one really cool thing uh intent
addresses enable you to do is arbitrary
bridging so you can set an intent
address which sends the funds into a
bridge and then on the other side
retrieves the funds out from the bridge
here's an example of how we can do that
so now let's say I want to maintain nft
on base but I only have ethereum on
optimism what can I do with intent
addresses to do this I'll first transfer
my ethereum to an intent address
a relayer comes in
trustly and swaps the ethereum for me
and sends it to a bridge in the contract
I can guarantee that at least X dollar
of usdc must come out of the swap
otherwise the contract reverts and the
relayer relayer can't execute that
function so the relayer completes the
swap sends it into a bridge like
cctp and the later later on the
destination chain this is is the cool
part I can now trustless execute the
contract call on the destination chain
how do we do this when the bridge
completes it transfers usdc to the same
intent address on the destination chain
this contract because um optimism and
base are both evm
chains I can use the same contract code
and have it hash to the same create 2
address on both chains so the contract
on the destination chain will
now approve the nft contract and make a
call with
usdc you've just seen how I trustless
sent funds to an intent address and had
my intent completed on the on a separate
chain completely separate chain fully
trustless fully permissionless anyone
can come to complete this contract call
and your funds will never be stuck
because you yourself can complete it
what does this enable for you well I
don't need uh as a user I don't need to
have gas on the destination chain if
someone was building an app with intent
addresses the relayer holds gas on both
chains and the user only needs to hold
gas on the source chain this is because
the relayer completes the contract call
for you on the destination
chain what's next from
here well cctp and other Bridges often
take a few minutes for example cctp can
take up to 20 minutes to complete the
bridge how can we do this instantly I
want to do something on another chain
and have it instantly
complete here's how fast finish and
claiming
works on the source chain the flow is
the same I send eth to a contract a
relayer comes in swaps it and initiates
a bridge for
me now on the destination chain the
relayer will as soon as they start that
Source transaction they have a guarantee
that if the bridge if they trust the
bridge 20 minutes later the funds will
arrive so what they can do is they will
they can immediately execute the
contract call for me so they call um a
fast finish function on an escro
contract and this mins the nft for the
user what the escrow contract does is it
tracks who finished this um this
contract call for the user
and then later when the bridge completes
instead of sending that to the contract
or to the user you send it to the
relayer who finished the contract call
on behalf of the user so if you look at
the funds of the relayer on the
destination chain they execute the
contract call they're down let's say 100
usdc to Mint the nft and then 20 minutes
later when the bridge arrives they get
paid back for that 100 usdc that
um they did they executed on behalf of
user so 20 minutes later the bridge
completes the bridge transfers the usdc
to in uh the intent address and then now
the relayer can deploy the intent
address and because the relayer address
is tracked in the escrow
contract the intent address knows to
send the funds to the relayer instead of
the user
to summarize what intent addresses does
for unifying ethereum it builds a better
user experience no more two wallet
roundtrips only a single wallet popup
you can pay with your coinbase account
or your binance and this enables a
larger user base to interact with your
app you sponsor gas on the destination
chain so your user no longer has to hold
gas on Two Chains to interact with your
contract better interoperability
your user can pay you with any coin on
any chain and have trustless and
permissionless guarantees that the
intended uh intended action they wanted
to execute gets
executed funds will never be stuck
because the user can thems can complete
the action if no relayer comes in and
does it for
them how have we used this in the real
world now one of our partners small
brain Games built this app called
tomorrow news it's a prediction mark
that lets you bet on tomorrow's New York
Times
headline you enter in what you think the
New York Times headline is and the more
accurate it is the more you get paid
out however they only accept
ethereum what we did for them is we
built a a deposit flow that allows users
to send any coin on any chain and it
automatically Bridges and swaps using
the intent address mechanism to deposit
funds into the app
another one of our partners is freedom
Factory they're building an open- Source
open Hardware Hardware phone Hardware
wallet that runs on
ethereum they have a checkout page that
only accepts usdc on base and what we
allow enable them to do is accept um any
coin on any chain to pay for their
wallet if a user doesn't have ether dgen
on base they can pay with their coins on
optimism their coins on ethereum their
coins on um binance smart
chain yeah let's play the demo um I
think they've got
it here's a quick demo of intent
addresses so oh it's got no audio I'll
I'll just narrate it um so this is this
is the the uh like an example of an
intent address in action so we're going
to click any crypto this is actually uh
the Diop pay modal um this is our our
what we've built around intent addresses
shows all of the different tokens we're
going to do a single transfer in in one
token oh over to this side okay deal
um and almost immediately you should see
the safe payment completed as soon as
that shows the fast finish on the
destination chain has already cleared um
rollup ethereum is really fast and cheap
now we have one cent one second
transactions really beautiful and so you
can see this is already done and then
under the hood 20 minutes later the real
ler will get paid back via
cctp that's all we've got
there sweet should we do the the
bonuses um perfect uh we have a few
bonus round things where we're going to
show some other things we can do with
intent addresses beyond all of the stuff
we just showed you so the core of it is
like make an experience that kind of
feels as nice as like Apple pay or
Google pay but it lets you do anything
on ethereum from one transfer um but
what if you don't even have gas on the
source chain we talked about not having
gas on the destination chain um for
assets that support it like usdc uh we
can do entirely gasless intense this way
by just having the users sign a message
that is a permit for example a usdc
permit message um and then the relayer
does everything else then uh another
interesting place that we can go with
so intent addresses have this property
that they are ephemeral um so we create
an intent address representing one
specific action and then once that
action is done that contract doesn't
need to exist anymore uh self-destruct
some of you are probably familiar with
the history but it's been like a problem
up code in the past um it it used to
have a gas refund associated with it
that was deleted because it caused
problems but at this point self-destruct
only exists within atomically within a
single transaction you can create a
contract you can self-destruct it later
within that same transaction so we
actually think that there's no more
reason to not have the refund and having
the refund would be really nice for use
cases like this it would make intent
addresses a bit cheaper and it would
incentivize anyone who's using ephemeral
addresses like this to clean up after
themselves and not pollute the state
tree um and then lastly uh you know once
this is more um once this idea has more
mileage on it and we know the common use
patter patterns right now it's is a new
thing it's exciting once it's sort of uh
more Lindy we could write an ERC that
allows a really beautiful Progressive ux
where wallets that support it can show
the intent where I say I'm sending you
know what I'm actually proposing is a
transfer to an address but it will show
you yeah you're actually sending you
know this much usdc to vitalic over on
you know optimism this other chain um it
can surface that to you and then for
wallets that don't support it it'll just
show as a transfer to a be address but
it degrades gracefully it still
works uh I think that's just about all
we've got let's go to let's go to
questions wow guys you have 15 questions
lined up yeah this is so interesting so
let's start with the first one uh what
is the incentive for relayer to deploy
the create two wallet since deploy
contract is usually
expensive you want to do that so there
are two ways you can do this um if
you're running an app and want to use
intent addresses for your app you can
run your own relay to provide a better
user experience for your users your
users won't have to pay gas and you can
do cross chain um cross-chain actions on
their behalf another way you can
incentivize relays is to have um a
tipping mechanism so the user sends some
tokens to the contract and then you can
bake into the contract that the relayer
collects like a 3% fee or however much
you want to incentivize relayer to to
pick pick up these uh intents and
complete them for the
user yeah another thing i' would say is
deploying contract is actually not that
expensive on L2 um which is this system
is definitely built for for you know the
the the rollup Universe um one nice
thing there is that these contracts are
very small because uh we're doing you
know like minimalist proxy you know uh
uh contracts that point to like an
immutable implementation contract and
they just have Constructor arguments
that basically encode the parameters of
the action of the transfer the payment
whatever it is and so the size of
contract code that you're deploying for
one of these intent addresses is fairly
small um I'll answer this next one
because it's closely related do intent
addresses lead to increased chain State
bloat this is why we would like the self
self-destruct refund back um we actually
run our intent addresses currently
without chain State bloat with
self-destruct at the end uh but there's
currently no incentive to do that you
don't actually gain anything from it um
and so having that also come with like a
Bas effectively like a gas discount for
cleaning up after yourself would be
great okay next question is if multiple
people transfer tokens to an intent
address uh how can the contract know who
sent what and in order to reward them
separately
totally so the intended way an intent
address is to be used is um you generate
like an intent address per user or per
interaction and this way you know like
which user is going to send tokens to
the contract and if other people send it
it could be like funding for um the user
so for example with the nft example for
each user that wants to Mint the nft in
your app you could generate a new intent
address specifying them as the recipient
and then you could also for example
purchase a gift for your friend and
transfer tokens to that intent address
but the intended way it's to be used is
once per interaction per user totally
and that said it does support multiple
assets going in so you can do this very
nice thing let's say I want to do an
action that takes $100 I want to place a
poly Market bet I can send you know $50
wor worth of token a and $50 worth of
token B to an intent address over here
on on Bas for example and any re can
come in you know swap those however it
needs the intent address is just going
to guarantee that like whatever they do
$100 of usdc have to go into the bridge
and then fast finish it on the other
side so you can do multi payments but
yeah it's it's not there there's they're
one per action okay next question is uh
do these intent addresses look like
accounts on a salana except for the
relayer the taker is eth I I don't know
about that okay
um how much gas would it cost to incur
the trigger uh to to start to trigger
the the action on um intent address
assume it's just erc20
transfer so in our experience uh in
particular on l2s it's really cheap to
use this intent contract mechanism so
for the gas cost you pay as a relayer is
the cost to deploy the contract and then
the cost to execute the function on the
contract so for in irk 20 transfer
that's like much less than a Cent and
the cost of deploying the contract is
also less than a cent so in our
experience on l2s it's been less than an
incent to use uh intent
addresses totally this is connected to
the next question which is uh what is
the additional cost of deploying
contract code for every
transaction um yeah actually I have a
two-part answer to this so uh
currently we know we're seeing these
intent addresses these intents going
through for for you know on the order of
a scent in gas costs if blobs go more
into price Discovery and blobs become
more expensive the interesting thing
here is uh you know all of the other
things you know compute contract
deployment all of these things actually
stay cheap on L2 the
one scarce resource at that point is
call data and there's some really nice
things we can do to optimize how much
call data we use so we we anticipate
this going to Stage okay that's it times
up thank you very much thank you every
everyone thanks for coming and see you
in 5 minutes
and in this this session you will learn
about chain obstruction master plan by
Stefan Goslin please give him warm
welcome
wow I remember uh the first Devcon in
value is so good now um hey everyone uh
super excited to be here my talk is
titled the chain
abstraction master plan um so I'll talk
about a few Concepts that uh that we
started a company to explore um and try
to go into what we think we can achieve
by by uh by using these things um so
let's dive right into it um to set the
context I want to go back into sort of
the what I would consider the main
phases of ethereum and uh the challenges
that we sort of had to explore and face
along the way um initially when when
ethereum came out the idea was that it
would be the world computer you would
have a synchronous environment there
would be one blockchain and you would
put everything on it um and so I would I
would Derm this to be the big
ethereum uh stage of of
ethereum then something happened in 2020
which is the chin ended up being uh
unusable uh because gas prices spiked to
an insane level um I think this was sort
of the the start of of defi summer and
yield farming and all this fun stuff um
and so the new idea came out which was
let's actually put everything on a
handful of Roll-Ups um and I would call
this the the big rollup phase of of E
um and then more recently uh We've sort
of seen that the rollups themselves
started to uh split up into their own
thing um and so now the idea is you have
uh sort of an app that's on its own
rollup and so you have clusters of uh of
rollups now my claim is that this is
sort of fundamentally broken for all the
reasons that uh that people experience
with
fragmentation um and there's a
particular solution that that's needed
to be able to enact it um and that
solution is called resource locks so
resource locks is really the thing that
one balance was founded to uh to explore
uh and propagate and our goal is to
really uh bring this as a fundamental
component to the entire uh ethereum
stack um so let's go into resource locks
let's talk about intents and let's talk
about how it helps achieve Atomic
interop um this is a a graphic of the
resource lock stack we published an
article called the cake framework that
explores some of this um and uh the
resource locks is just this piece in the
middle here so it's one of the many uh
messages and interfaces that need to be
introduced to be able to achieve a fully
chain abstracted uh sort of uh endgame
for uh for ethereum um and it only works
when you have some of these other
components that are being added to the
system the thing to notice here is that
this is an intent-based architecture
right so it uses solvers to be able to
execute transaction on chain on behalf
of users um and then proving the
execution back to wherever the the
execution originated from now the magic
behind resource locks is really what
allows us to achieve this seamless
interoperability in uh in
ethereum so let's go into talking about
what a resource lock is it's really
composed of two things um and there's
many shapes and sizes of resource locks
um so it's finality protection and
equivocation protection and this is
actually one of the core properties that
blockchains offer just the problem is
that blockchains offer it in a very very
expensive way so if you sort of abstract
away the concept of these two things and
then you add them up with the concept of
an intent which is specifying input
State and output State um you can
achieve something that we refer to as
resource lock intents um and so this is
what we sort of believe is a fundamental
messaging uh format for anything that
will be cross-chain if we want all of uh
ethereum and all chains to operate as a
unified uh
component we can explore how uh intense
and resource intense uh compare to some
of the other interop uh approaches and
their and their trade-off so canonical
bridge this is how do you pass a message
between two l2s in the most secure way
possible you have to start the message
on the uh first L2 send it through uh
the fraud proof mechanism wait seven
days and then pass it up through the
canonical bridge on the other L2 uh for
messaging and the core thing you have to
wait for here is full finality over the
message passing which is why it takes up
to seven days for for optimistic rollups
how can we go faster well one way that
we can go faster is just be optimistic
about the finality so when you deposit
crypto inside of a custodial exchange
you don't wait for the full finality
often times you wait for some optimistic
version of finality so for an L2 deposit
usually you'll just wait for for a
single rollup blob to be posted to the
chain and the exchange FL considers that
to be final final enough to be secure uh
but you still have to wait for this sort
of full rollup blob to be uh put in so
how do we go faster well intent Bridges
have become much more popular which is
an approach to actually um uh send the
message through a solver have the
execution happen uh on chain um and then
uh uh uh prove that back to the origin
chain that it was successfully included
the problem here is that you're still
relying on the source chain for
providing the resource lock which means
that you still have to have uh inclusion
times on the origin chain before the
solver can do the inclusion on the
destination chain so you're still
fundamentally two inclusion times away
from uh from uh from Atomic
execution and then resource locks take
away that requirement for execution on
the source chain and says actually all
you need is a signature from the user
user and you can automatically in
instantaneously go and execute on the
destination chain um so this is sort of
fundamentally the fastest way that you
could do interop because you're always
operating at the destination chain
speed so um This falls under a category
of interrup that that we call sort of
atomic interrup or Atomic execution
interop um as opposed to Atomic
inclusion or Atomic composability and I
want to compare it with some of the
other approaches that are being
discussed for uh for Atomic interop
so if you look at sort of in cluster
introp between the ZK rollup land and
the optimistic rollup land you'll see
some of this terminology come up um so
agay and elastic are are both uh ZK
rollup clusters um and they uh they are
limited by some fundamental constraints
so one is the proving speed of the
rollup itself so you cannot send a
message within this introp uh system
faster than the proving speed of uh of a
of a ZK uh a zare proof um and if you
were to assume that you had real-time
proofs which is sort of like a standard
that we're that we're looking for even
that uh in that world you're constrained
by the fact that you can have cascading
reorgs across two different rollups so
if for whatever reason the L1 that
you're posting your your blobs to or
your proofs to ends up reorg away that
uh that blob and you end up posting a
different uh set of transaction any
other rollup within this interupt
ecosystem that's listening to that post
will have to also reorg and so you sort
of have these um these security
assumptions that are conditional on
other uh other uh security environments
so it's not ideal um super chain and ARB
clusters have very similar sort of
guarantee requirements so it requires a
super Builder which is just a a
sequencer that's going to be sequencing
uh both the any of the rollups are being
touched by uh by the multi-chain message
and the implic of that is that you're
completely forgoing uh chain sovereignty
um which means that every single rollup
within this optimistic uh interop
cluster need to behave according to
exact same rules and need to upgrade uh
following the same assumptions and so if
you have you know within the super chain
environment uh the unit chain and the
base chain any upgrade to the sequencer
their behaviors would have to be
coordinated and have to be mutually
trusted because the risk is that if the
unit chain has a fault for whatever
reason and produces invalid message it
could cause also a reorg on the base
chain and so these cascading reorgs make
it very very difficult to achieve this
um in a in a scalable way um what about
resource lock intents do these have any
trade-offs well yes they also have
trade-offs while they don't uh they're
not susceptible to some of these uh
reorg issues because of the resour loic
nature of it they're constrained by the
liquidity that's available through uh
through solvers and they also are
susceptible to Black Swan risk for
example
if uh all the liquidity ends up moving
in One Direction at the same time you
know the the liquidity providers could
shut down and you would be unable to
actually um execute the the transaction
that you're looking
for so where does sort of one balance
fit in um well I hope I made a case for
why resource lock is like a useful
primitive for Atomic uh interop on uh
between l2s um and our approach is
really to provide a toolkit for any apps
and wallets who want to benefit from
this instant cross chain execution to be
able to do so um this Pro this provides
basically the full chain abstraction uh
experience for these wallets right a
completely chain-free Bridge free and
gas-free uh user experience and we have
an app that you can go and try out that
has uh cross chain swaps um and uh and
experience what this feels like um the
other uh product that we have is what we
call resource locks as a service so this
is a product really tailored towards uh
infrastructure providers and it provides
these guarantees of reorg and
equivocation protection it really allows
for a completely trust minimize uh
destination chain speed execution um we
also implemented just before Devcon what
we call teleport so this is a token
wrapper for eth that allows you to
instantaneously uh send eth to any other
uh chain or rollup without having to
wait for inclusion time um and so yeah
it's a it's a really cool uh way to be
able to transact on any chain at the
speed of uh of that destination chain
um I have this slide uh as a bit of a
troll to uh a slide that we saw earlier
this uh this week uh which is you know I
think it's important for us to be
ambitious about solving the problems
that ethereum has uh sooner rather than
later and Achieve sort of the ux gains
that uh that we want uh given the the
environment that we're in and so what's
the timeline for this well it's already
live right like this chain abstraction
stuff is is uh is sort of built out Tech
and it's ready for anyone that wants to
experiment with it and uh build it into
their applications in prod uh for them
to do so um and so yeah they encourage
uh everyone that's thinking about uh
operating and building apps or wallets
to uh to look into resource locks and
and understand what are really the
benefits that uh that they bring so
that's it thank you so much for uh for
listening to
me okay we have three
questions um so first question is why
does everything need to be fast as
can we leverage the better Channel
capacity usage by load
balancing uh I you know fast as is
uh the optimal goal right you could say
that like what is the actual time that
you're looking for from like a ux
perspective um I think like a two-c goal
of like being able to execute is is
pretty good now you can say okay can you
uh achieve that through like regular
other channels uh that I've described in
in the in the in the framework um maybe
but you're still susceptible to all of
those trade-offs that I explained um and
so even if you have
like seemingly uh faster uh uh channel
uh messaging you still have a bunch of
trade-offs included which why I think
resource locks on top of it will always
be
used okay the next question is uh do Rel
layers need to have liquidity on every
chain and rebalance accordingly in is
this a problem uh yes and no so instead
of relayer I like to use the uh solver
terminology um and you can have solvers
that have inventory which you know you
would refer to as market makers or
solvers that don't have any inventory
and the ones that don't have any
inventory essentially pull the liquidity
from liquidity pools on uh destination
chains the other thing that you can have
is you can have native bridged assets so
realistically the majority of the volume
when you go uh in a cross chain setting
is going to be eth or some stable coin
stable coins benefit from being natively
minable on any of the chains and so you
don't actually need to hold inventory on
that token in those chains you can
instantly mint it there and there's also
work being done on the eth side to be
able to make canonical minting of eth on
any rollup um and that will also prevent
the need from having uh um inventory on
those rollup for
solvers okay uh what are the security
guarantees of source chain signature
validation by the reers on the
destination versus systems like
more signature validation by the relays
on the destination versus
system okay I don't get the middle part
of this question but I can I can say
like okay what's the difference in the
resource locks between an intent bridge
and a resource Lock Bridge um so 7683 is
like this intent standard uh and it
provides some of the uh the fields that
you would have when you're trying to do
uh uh resource lock resolution on chain
um I think it doesn't specify anything
about the uh commitments that are being
made about the state of the account when
you're inputting it it just so happens
that right now we're doing this by
putting it on the source chain um but
there's a bunch of mechanisms that you
can do to secure resource locks that are
fully offchain I won't get into them in
this presentation but I would just point
you to uh to our e research post about
resource
locks okay seems times up um that's it
there are more questions and you can
find him here um thank you thank you
need
now we have Nicolas Sara who will tell
us of well hard learned lessons that
rollups on ethereum can learn from
Cosmos give it up for Nicholas
um hello everyone so um Sonia was
supposed to present this talk he
couldn't be here today so I'm going to
be presenting on his behalf uh my name
is Nicholas Lara and I work at osmosis
which is the lead index and liquidity
venue of the cosmos
ecosystem and since this is an ethereum
conference uh I'm going to first do a
quick introduction of the cosmos
ecosystem in case some of you are not
familiar with it the cosmos ecosystem is
a network of independent blockchains
that are generally but not always built
with the cosmos SDK and the main things
that they interact with each other using
this protocol called the inter
blockchain communication
protocol now this is how the network
looks right now it's a bunch of chains
they're following pretty much every
crypto use case that you want to build
there's a chain for it and uh the
central idea that we've been building
around is that each of these chains can
make all their engineering decisions
based specifically on this use case that
they're trying to build around so you
have chains that are a de a privacy
chain liquidity um chains you could have
da layers and all of those could
customize sometimes small things like
block times or block sizes but it could
be bigger things could be different
execution VMS could be different mles
consensus algorithms or it could be
using the MPC capabilities of the
validator set
so um
Okay so we've been building in this
heterogeneous environment for a long
time which means we have to think about
all these different types of chains and
like all these differences that appear
on them have these protocols that are
higher level so if you're building
applications that interact with all of
them then you uh cannot really rely in
all of them being the same and this is
what this talks about like the problems
they have Arisen when dealing with this
in Cosmos the solutions that we buil to
to address them and the open issues that
we're still trying to
solve so uh there we go why does this
matter for the ethereum ecosystem so the
idea of l2s is not really new it's been
around since forever but the amount of
l2s and like the difference between them
and how much they're inter interupting
with each other and like the different
ways in which they communicate has been
growing a lot lately and I don't think
anybody really believes in this idea
that one chain will actually win
outright and that you will have
everything happen in one place we're
instead building these apps at a higher
level that have to interact with
multiple chains to be able to do what
you want to provide to users so the
first thing you need to build when doing
uh something like this is a message
passing protocol and that's what IBC
is uh I'm not going to go into all the
details of how IBC Works internally but
basically IBC uses light client
verification of the counterparty chain
State and offchain uh Rel layers that
update the light clients and notifi
chains of posted messages there are
other designs of General message passing
there's like notably layer zero aelor
GMP and hyperlane and they all serve as
this B base layer but I think IBC is one
of the most secure and general
architectures for this and a new version
of this is actually been developed this
code named Eureka right now and um
that's actually going to make it easier
to bring IVC to EVMS because it
simplifies the protocol a
lot now one of the first things that you
implement once you have a token trans um
a general message passing protocol is
token transfer right the general way you
implement token transfers you lock it in
one place you pass the message to the
other chain you let them know that that
has happened the other chain can mint
token now one thing that I've seen even
for like the more advanced intent based
token transfers that are still being
proposed is nobody thinks about
implementing multiple token transfers
that's a lesson that we've painfully
learned they spent countless hours in
people like trying to work around the
fact that you can only transfer one
token at a time that was done wrong in
the initial implementation for this and
IBC it's been like rectified on the
newer
one but once you start transferring
value then one thing you have to think
about is like what do your accounts look
like right in this heterogeneous
environment your accounts don't
necessarily look the same everywhere you
cannot assume that just uh this type of
address is going to represent you
everywhere and so one thing we do in
Cosmos simple we add we encode this as
spec 32 we add the chain name at the
beginning and that there are trade-offs
that makes it harder to recognize the
address directly you look at it you
don't you're not really sure if that's
your address or not cuz there this
checks on bites at the end
and uh there's actually a really good
solution for this on uh on evm that is
this ERC just stick the name of the
chain in front of
it but
um the problem with this is that you
actually don't really know who owns this
account who actually controls it because
this might be true but even for EO for
EAS you could have a chain that has
implemented that account derivation
differently so even if you control that
account on one chain you're not sure
that you can't control it on the other
and that gets even more complex when you
consider something like smart contract
account or uh even just something as
simple as a multi sake you would end up
with something like the winter mute hack
where somebody sent tokens to an account
that they supposedly controlled but was
not initialized on the receiving chain
so a hacker was able to snap uh to snipe
it so uh what we can do instead to avoid
these issues is to lean heavily on
Registries we've tried a couple of
registry designs in Cosmos none of them
has actually Stu so I'm guessing this
means that the design of this protocol
is not as good as it could be uh but you
actually do have a de facto standard in
ens domains and I think this is the best
bet that we have to have a general
registry system that you can use across
all of U all
chains but of course I think it should
evolve a little bit you need to have
there are three important parts that you
need to have that is like the top level
owner of an account you need to have sub
accounts and you need to know which
chain you're interacting with so having
something like that it generally would
help you identify the account but it
will lead to one very obvious problem
that is like you're linking all of your
accounts and yes you could use
statistical methods to determine which
accounts are linked to each other but
that uh becomes a lot easier when you're
just giving that information
away so I think is that you could use
this concept of asymmetric names
asymmetric names is when you have these
names that are interactively verified so
you could it generate a accounts on the
Fly that are used only as a receiver and
you have a way uh those are all derived
from your private keys and they're all
controlled by you so it becomes kind of
like a utxo model but something that's
even better is that you can then take H
th that to those tokens that you have
received there and they could be just
streamed through a privacy layer to the
account where they're actually supposed
to live at rest and in something like
Cosmos this would go through a set of
different chains before it lands where
you need to have
it now when you once you introduce H
abstract accounts or smart contact
accounts you end up in the situation
where
you have created the of complex
permissions that you have on one chain
and you want those permissions like this
is how you interact with your uh
accounts you don't want to have to have
that in every chain
so once you have have set this up you
don't really want to have to transfer
that to every chain and once you want to
change your permissions then you would
have to actually adapt it on every chain
that you've interacted with instead one
solution from Cosmos is this idea of
interchain accounts interchain accounts
use this controller host architecture
that
um allows you to create an account from
one chain to the other so like your
account on one chain can have an account
on the second chain and you can control
that only by sending messages from the
controller on the controller
chain now uh there we go there's one big
problem with this and is latency right
if you have a one account that is your
main account that is controlling
everything else once you want to do an
interaction with any other chain you
would actually have to initiate it on
your controller account and even if that
is a very fast chain you would end up
having a latency of like at best uh 1
second and that's probably not good
enough for what we want to build
so even when you do that there are like
even if you're okay with one second and
controlling everything from one account
you have two other problems one is that
you need to initialize your accounts in
every chain you cannot just start using
a chain that you haven't used before
without creating an account there and
the even more important problem is
compossibility you normally want to
interact with three different accounts
uh sorry three different chains and in
all of those chains you want to execute
different actions if you wanted to do
that by controlling your chains from one
um Central account chain then you would
end up having to sign all these messages
and you have to do this offchain
coordination of which order things are
going to happen what happens with
failures and instead what we want to do
is we want to have this General model of
cross chain execution you want to start
interactions in any chain and as you do
that the interaction should
automatically move through all the steps
that are needed to complete so if you
want to send tokens to a chain swap swap
them there then send those two tokens to
another chain and LP there you should
just be able to sign one message and ex
and express that you want to execute
that and all the other execution should
just happen
automatically and that is something that
we've built for Cosmos and we've built
it in this way of having nested messages
where you specify what is going to be um
happening on each on each step each one
of these messages is either a token
transfer or a contract execution and
it's followed by another of these um
operations and if you zoom out to what
this is this is actually just a mon
right like this is just one big
operation that gets processed and as the
operation is processed it returns you
two of the same operations one for
success and one for failure if you
succeeded you execute success if you
failed you execute failure and um as you
have that that is just a general model
of computation that you can use to do
basically any sort of execution across
all
chains now there are challenges for this
right once you're dealing with these two
chains um who's doing the execution you
initiated the action in one chain what
account is doing the execution on the
second one and the way we've solved this
is we've created uh the as you transfer
tokens One account gets created for you
automatically on the receiving chain
that is only existing there for this
particular execution now that account
has received the tokens and can act on
them as that account sends the token
somewhere else or executes new actions
new accounts get created for that so
those can only be controlled for this
particular execution now this has a nice
side effect that you actually have to
send your tokens along with your
transfers so you can you don't have to
rely on like having tokens be there in
those accounts
beforehand now who's paying for it in
Cosmos unfortunately right now this is
altruistic Rel layers um in ethland you
actually could just use a pay Master for
this which is really good and we're
working on like a fee uh system for
getting around this in Cosmos right now
now you're posting the execution data on
chain like as you start your execution
you're saying this is what I want to do
and you're getting that on chain that
can be pretty costly in some chains so
what you want to do is you want to try
to avoid that and if you think this is
costly you could just instead of posting
the whole execution you could just post
a commitment to it just post a hash and
when you relay your messages you can
include the execution uh information now
you have to deal with Dynamic
information that is really difficult I
think the best solution we have for this
is having some sort of query language
that you can actually use to act on the
previous executions results but this not
something we've implemented it's like
too complex and like the advantages are
not good
enough um I've mentioned before
cross-chain latency and the cross chain
latency here is not the same that I was
talking about before before you had this
issue of when you start your execution
you have to wait for the execution to
start until the second chain receiv
receives it whether here the latency is
just the amount of time this execution
needs to take anyway if your actions
requires three token transfers and three
actions on each chain that's the minimum
amount of time that they should
take um and of course if you are
um saying what you want to execute on
the first step and then things are going
happen say a minute later on a different
chain you'll have this meev issue right
but first I think this is not something
that you need to solve with this
execution layer you need to solve it
more of a privacy layer and the simplest
way to get around this is just what I
said before for execut execution data
being on chain you don't post all of it
you just post your commitment your hash
and then as you execute uh you actually
reveal what needs to
happen um there are some standards that
I think would be really useful in E to
implement all of these but like the hard
part even after we have this is what is
the top level protocol that we're going
to implement that is going to allow us
to communicate both with uh evm chains
but also with Cosmos and also with
Solana that's like an way of um
specifying your cross-chain interactions
that you can use across all these
chains now even when you've taken care
of with that and you can do this
execution across chains one big issue
that we have in terms of ux is this idea
of asset fragmentation what users
actually care about is which underlying
assets you're interacting with uh what
risk you're incurring on and being able
to just use those assets on applications
right so if you have an application that
works across multiple chains you end up
having many different Varian of one
asset that are spread out in different
chains and they may or may not have the
same name
and they also may not have the same
liquidity they may not be able to be
used in every application so um
centralized exchanges do the opposite
right they show you just one version of
the asset and they just don't expose the
risk at all you just don't know what's
under underlining there you assume it's
variance of the same asset and hopefully
it is but you don't really know it and
at osmosis we've developed this concept
of alloyed assets allo assets is just
basically a pool of all these variants
they can be swapped one to one
so uh then the lp token of this pool
actually becomes the canonical version
of the asset in this case you would have
like a Bitcoin that is the
representation of Bitcoin on asmosis is
just the union of all these variants of
Bitcoin that have been bridged now this
is of course socializing the risk but
users can also choose to use the
variance directly if that's what they
want and and certain applications that
don't want to use this alloyed asset can
also choose to just use one variant now
one cool thing is that the original
issuer of this token if you have onchain
governance or even with offchain
governance you could be the one that
decides which variants are allowed in
this alloy right like you could have for
example the ethereum foundation St these
polls in different places and say these
are the tokens that are allowed here
other people will provide liquidity but
these are the tokens that are allowed as
canonical eth and the same way could be
like for that have onchain governance
onchain governance can decide which
assets will be part of this now a cool
thing with this thing is that it doesn't
really need to be something that only
exists on one chain you would be tempted
to just take this asset and like send it
everywhere but then you're basically
just creating one more variant of the
asset right so what you can do instead
is just have these pools exist on every
chain and that is what is considered
across all chains the canonical version
of one asset so everywhere when you're
referencing Bitcoin you would be
referencing this thing that is a version
of Bitcoin that has been bridged through
these 10 bridges that we through social
consensus consider to be valid bridges
Bitcoin
um and yeah and and those could also be
just rebalanced across
themselves uh and I think a lot of this
that I've been going through is
basically that we need better
cross-chain standards something that
doesn't work just Within in one
ecosystem and that works with chains
that are very different to one another
and yeah this probably leads to standard
proliferation but I feel like do some
standards do win out it's not
necessarily true that the more standards
you you add the more standards you have
eventually people will move towards the
better ones
and um I think with in general we want
to move more towards this user Cent view
blockchains you users want to have
accounts that are easy to identify they
want to see all their assets across all
chains they want to have better
execution across all chains that they
can easily specify they want have
protocols for asset identity so you know
which assets you're interacting with but
without having to you yourself go into
all the details about the risks and they
want to be able to share their account
permissions between chains we're trying
to apply all these lessons to our new
product that is called Polaris and
Polaris is a token portal to trade all
assets on all chains through one app and
we're hoping to be able to build better
cross chain standards along the way
we're going to be interacting with
pretty much every chain out there so
when there are no good standards uh out
there we want to help build it so uh
yeah if you have good or bad experiences
either building or using cross-chain
applications just please come talk to me
because I'd love to hear
what you think and try to work together
in like making better standards and
unifying them and improving
them thank you for your
time okay thank you Nicholas let's see
the questions so we have three questions
for now um first one is how do you see
the lack of middleware functionality in
many bridges compared to ibc's ability
to execute commands through middleware
and IBC memo impacting Mass adoption and
ux in Cross chain echos yeah yeah we
need better
Bridges we we need callbacks on Bridges
um IBC is I I obviously I believe in IBC
everywhere but yeah if we don't have IBC
everywhere if we use other Bridges let's
use the ones that have callbacks and I
think as we start implementing
functionality that use these type of
like middlewares and callbacks then th
that's the ones that people are going to
use because they just provide a better
like possibil better possibilities for
building applications
okay uh next question is is there a
cosmos version of the ERC 7683 standard
uh since I'm not an eth person you
somebody if somebody can tell me the
name of 7683 then I can probably answer
that is there anybody who I I don't know
so yeah um who has question is is it a
cran intents or they're shy okay uh you
can answer this later in discussion yeah
okay uh next question is what is the
biggest benefit of having a standardized
interoperability standard across the
ecosystem versus various bridges in
ethereum
MH so I think there are two different
things like the interoperability
standard it would be for being able to
like regardless of whether you have one
Bridge or multiple Bridges you could
have one interoperability standard built
on top of that so um and I think the
advantage is applications can build
using basically this language and then
if a new bridge that is better comes
along you could your application will
still work there now um versus having
various Bridges I think it's good to
have various Bridges they have different
properties and yeah if some are better
they'll hopefully
win okay next question is why not use
the EA Crush chain interrupt spec that
was recently released
um I is it
no I'll probably have to look at it like
I think we we worked on the if it's
recently released I guess the answer is
we built this before
so oh wonderful yeah i' yeah I'd love to
look into that okay uh next question is
you mentioned the Privacy layer before a
transfer from uh up chain to another one
isn't it possible to end uh to end up
sorry yeah we lost the question uh is it
to ends up being targeted by the
governments like Tado uh sure yeah I
mean I feel like everything can get
targeted uh even just like blockchains
in general
but that's why I so I like the idea of
having this as an optional layer that
you can have like in the case of these
femal accounts I was thinking like so
your uh your name registry actually
provide this different set of accounts
that you can interact with right like
things get pushed to them and then you
have again basically an utxo model right
like you have all this things that you
control and you can move through there
and that gives you some sort of privacy
now if you actually want this to be
streamed through a privacy layer then
what would happens you have something
that is slowly moving this thing to
another chain that does privacy and then
moving out of it uh yeah if that chain
gets shut down then you probably would
have to do privacy somewhere else and um
yeah I think other privacy Solutions uh
would come
out okay next question is um how will
Polaris handle the reorgs of layer
twos um how Polaris will handle reorgs
l2s um I don't know that's a good
question uh we yeah so Polaris is
working at a higher abstraction level so
I believe like
whatever our provider apis are doing
there is what we'll do like for evm
chains
um but yeah I again good question um
give me your opinion out
there okay um we have 20 seconds but
it's not enough to answer the next
question so you can take it uh there and
thank you a lot yeah
thank you
for e
we have now five uh or four very short
lightning talks and uh most probably for
some of them we won't take questions on
the app there won't be q&amp;as but you can
catch the speaker afterwards and ask
them your questions so first up we have
Marshall and he will talk about
interoperability between layer
twos awesome uh so I have a lot of
information to get through um so I'm
just going to get right into it this is
specifically about trustless
interoperability between l2s bit of a
wordy title so I just decided to keep it
here but basically the motivation for
this talk today is when I joined the
space somewhat recently um I decided to
kind of look at the interoperability
problem immediately and right upon doing
so you can see everybody kind of has
different definitions for how they talk
about these things we see Atomic
inclusion Atomic composability
synchronous Atomic composability um
asynchronous composability these are
very confusing things so my aim today is
to sort of clear this up and figure out
what we actually need to make these
things happen so I came up what I with
what I call the six level framework for
discussing interoperability
trustless um this is a broad overview uh
in the interest of time I'm going to
move Beyond this but I'll give you a
second to take some photos and uh and
just get an understanding of what is
sort of the impact of each of these
levels so uh getting right into it this
is the default case this is what we have
right now if you want to move between
rollups you can't really interrupt you
have to withdraw you have to wait once
your funds are out then you can deposit
in in the next destination rollup that
you want to go to but this
sucks Atomic conclusion um this is where
things start to get a little bit more
interesting I think the way to
understand this is we have a bundle of
transactions and we have some sh shed
shared sequencer that can guarantee
inclusion but it can't tell us whether
things are going to execute successfully
or not so we can see over in the bottom
here roll at B might revert one of the
transactions so the impact of this is
that it's actually really difficult to
take advantage of any sort of system
with just Atomic inclusion guarantees
because if you want to create a bundle
of dependent transactions uh you can't
because if one reverts then this is
going to have issues on the whole system
so uh the necessary infrastructure would
be somewhat of a lazy shared sequencer
and we can go into the technical nuances
after if you have questions so um I'll
just keep moving on the third layer is
where things definitely get a lot more
interesting this is shared settlement
and this is what we're going to see a
lot of in the next year so so things
like the a layer for polygon ZK syns
elastic chain super chain they are all
doing this and the definition is having
multiple rollups all settle to the same
shared Bridge contract uh there's
usually a proof aggregation step
involved in the middle as well um but
that's technically not necessary and
we'll get into why uh maybe afterward
and so the advantages and capabilities
of having shared settlement is that you
don't have to wrap assets to go across
chain because we're sharing the same
Bridge contract uh we don't have to
worry about managing the accountant
counting on all these different Bridge
contracts on the L1 so that's great we
can go native eth to eth and that's all
in the Protocol no bridging required um
so we need a share Bridge contract we
optionally need relays again not going
to get into the Nuance of that um and we
need proof aggregation to do this as
well so next we have Atomic execution uh
and the idea here is the exact same as
atomic inclusion but now we can
guarantee that these transactions will
execute when I say execute that means
they're going to create the required
State change that they were intended to
create create on the chain that they
were intended to go to uh and this is
really really important because now for
things like cross rollup Arbitrage we
have guarantees if you don't have
guarantees you might get involved in a
case where one of your Arbitrage
transactions goes through the other does
not you don't actually profit uh people
do this right now this is kind of what
sexex ARB is for the most part I mean if
you don't get top of block space but
it's suboptimal so we you know we want
to have something like this that
guarantees that transaction bundle to go
through and now we start to need more
Shar components in the middle we need a
shared sequencer we need a super Builder
technically talk to me after um and a
soft finality
later technically talk to me after um
this is where I want to spend a little
bit more time so this is what I think
should be the goal for now at least and
this is Block Level composability this
is a really crazy diagram and I'm not
going to go through every single step of
it right now U but basically the idea
here is that we can compose between
rollups within a single block so a lot
of times on Twitter you'll so people
talking about oh we need synchronous
composability
what does that mean uh this is one way
that they mean that where you can have
this dependent cross rollup bundle of
transactions uh and this is really
important because now you can do things
like single block cross roll up swaps
and limit orders trustless Le and the
trustless component means that you don't
need a liquidity Bridge you don't need
to trust any sketchy intermediaries you
can do this all with minting and burning
in a in a safe way uh you do need a
shared sequencer uh or super Builder
again I
keep we'll talk after if you're curious
about why I keep going or superb Builder
it's actually pretty nuanced and really
interesting um and then the soft
confirmation layer again not strictly
necessary but this ensures the validity
of the bundle so you can think about
creating this cross rollet bundle of
dependent transactions as uh a somewhat
risky thing to do but if you have this
soft confirmation layer that ensures hey
all these transactions were well uh well
formed and we've simulated them we can
give a pre-confirmation on that bundle
so we can ensure that we can do what we
want to
do this is the final step and this is
technically the Holy Grail of cross
rollup interaction this is basically a
smart contract to Smart contract layer
uh of interop for these rollups now uh
the really interesting thing about this
case is that it basically ensures that
any state change prior to any call can
be reverted if the call reverts so this
is what we want in smart contracts right
now you make a call call out to another
smart contract the call reverts for
whatever reason any state change that
happened prior to that call must also be
reverted and that's really really
important for the developer experience
because you can't take advantage of any
cross rollup opportunities if you don't
have that because you don't want to act
on state that did not occur in the
domain that you wanted it to occur in so
this would be like the Holy Grail best
case version this is amazing but it's
really difficult to get um and yeah so
the advantages and capabilities smart
contract like experience across all
rollups this is amazing we can guarantee
that any state change can be reverted
cross roll up flash loans are possible
we need VM level changes we need a
shared sequencer we need superb Builder
we kind of need as much shared State as
possible without literally being on the
same rollup so what's the takeaway Block
Level compos composability is the right
goal we should not be optimizing for
cross chain flash loans um we need
shared state to compose so we need a
shared sequencer we need a shared superb
Builder some sort of shared state to go
back and forth here um and the last
Point I've got 7 seconds left uh rollup
clusters you're going to hear a lot of
people talk badly about these because
they're walled Gardens they're fantastic
they're really good for the middle
ground and we're going to work up to a
place where we can bridge between all of
them so thank
you thank you Marshall that's it we are
not taking questions uh if you have
questions please find him here uh next
up is Joshua and he will talk about
advancing ethereum scalability he will
explain EIP
Joshua sorry
all right thank you thanks for having me
so I'm going to give you uh five minutes
five minutes to explain the whole
history of blockchain architecture uh
it's going to be a lightning thing it's
not going to be difficult it's going to
be diagrams uh and let's walk it
through okay a little bit history lesson
so Bitcoin was the first ever
implementation of of the blockchain now
he didn't really say it but there three
key things that everyone who jumps into
blockchain needs to think about in terms
of how architecture is designed so
firstly you have state so state is like
how much money do you have what has
happened is it a yes or is it a no for a
contract or stuff like this you will
have uh block space and processing so
what that means is uh you have state but
this state needs to change and you
collect transactions uh and these
transactions then need to walk through
its path uh towards a new State uh so
you you do need some kind of a place to
put these transactions and you need a
place to put these transactions on the
Chain so that everyone can see uh in
Bitcoin it was always that same one node
at a P2P level uh that same architecture
that's shared across many many many
nodes uh and essentially the third part
is okay uh we have a state this state is
moving over time we call that blockchain
and then the third thing is uh which uh
chain which chain uh which what we call
F F rule which chain is the the the
truth of the data uh and we call it uh
consensus you can think of it this way
there are true finite uh Concepts in
life there's Capital that's finite
there's machines that's finite so one
way or another with finite machines or
Capital that's going to vote on which is
the true state of things uh that's
that's the way forward and you can see
that large area is kind of like how much
that capital or economic sority is so
over time like people were like okay
let's let's find more use cases so and
when they did that you know they they
just like initially it wasn't too
interesting so things were like you know
just for for Bitcoin uh Implement
similar ideas around State transitions
box based processes and cryptoeconomic
security now that's where ethereum comes
in right so that's where cryptoeconomic
security has a very new lens right so
cryptoeconomics security is not just
about uh the stake that's been done by
validators um Now with uh applications
that live on the chain that stay
actually on the application Level with
ERC 20s and all sorts of different
assets uh funable assets non- funable
assets they become like new areas of
cryptoeconomic uh Capital that has to be
secured by the fundamental layer uh
that's where we talk about rollups right
so rollups is where that uh fundamental
Capital that sits on on the on the L1
then gets in into a position where okay
it's kind of like being used to choose
uh for fullness of the layer two rollup
so you would think that the layer two
itself there's also a block space and
co-processor there's also a state and
that state requires some transaction
function across a set of blocks uh yeah
and initially this was really expensive
because we put all data or into what we
call call data and that's on uh a place
right directly onto ethereum
subsequently we develop um this thing
called blobs which kind of like a data
layer that's uh a first class citizen uh
where it's sort like a separate fee
Market from General transactions and it
only lasts for like a short period of
time bunch of weeks before it's
destroyed so that way you can prove
things with these blobs uh to move the
chain forward but you don't need to keep
all the data on chain uh that's when we
actually have new kinds of data
availability as well there are new l1s
created like Celestia which have their
own own State transitions but their goal
is to keep data temporary um that is all
like uh you know and yet again looks
like a fork uh and then subsequently we
have like IG layer and uh symbiotic and
kak which then talk about reate Capital
where then they use reate Capital as a
way to then create new protocols uh and
that creates things like a data
availability on like a now all these
being said made fees really cheap so the
issue is that all the l2s have really
cheap but what about the fees on the L1
so new types of designs like base rollup
architecture help sequencing on the L1
so to collect more fees and me uh and
these things are like still in in
progress the question is profitability
of Base rollups uh whether this will be
something sustainable over time yeah uh
but with that it creates new ways to use
the restate Capital that I talked about
so you can imagine ethereum is a 12C
block time but you want a
pre-confirmation something that's really
fast just like the two three second you
find on manal network um and so the way
to do it is like restate capital from IG
layer and symbiotic that can then be
included in some kind of an inclusion
list yeah with that that's where we are
inclusion list base rollups question
mark uh standard rollups l2s optimums
and uh validium are different kinds of
ways for offchain data and we are truly
infinite uh Garden where there's so many
architectures this ecosystem is so many
and we we will continue to push the best
architecture for this ecosystem thank
you wow that was on the spot um we are
going to take a couple of questions for
this session so uh you can ask ask them
through the application or just raise
your hand and ask and I'll repeat into
microphone so is anybody here have a
question okay if not they can find you
later and ask you anything thank you a
lot
sorry
Happ
ah okay come on
on
few
please welcome M kvki co-founder of cell
who will share how they transition from
layer one to Layer Two welcome mik
hey
everyone my name is mar oepi and once
again we're going to be talking about um
cell's transition from an L1 to an L2 uh
you've probably heard that we're making
this big transition and we really hope
that we can become a case study for
other l1s to follow suit and so today
will be a talk really targeting those
other l1s with our learnings and I tried
to make this fun for you all so uh I
made this in the style of Zelda any any
Zelda players in the
audience cool we got a few hands up
great well hopefully you'll enjoy the
slides um and so what does cell
transition to an L2 look like it it
looks like us taking our evm core which
is shown here as kind of our little
protagonist uh and all of the nice
additional features that we've built
into the sell blockchain like the
ability to pay for gas with tokens like
the ability to send value to phone
numbers and of course Ultra green money
this um mechanism that offsets all of
the carbon that the network produces
every time you transact and we've taken
all of this and we've repackaged it into
an OP stack base L2 that's sitting on
top of
ethereum and so once again we really
hope that this transition that we're
going through can be a really nice case
study for other l1s to potentially
follow suit as well and this talk is
really um almost a map you could say
um of you know five learnings from our
journey that that these other l1s can
learn from okay so learning number
one um First Learning is if you're going
to do this transition you should do it
as a hard Fork you know when when many
people think about doing this transition
they um immediately think okay this is
the way to do it right let's just launch
a second L2 chain um and uh and then we
can have our users figure out how to
migrate from the L1 to the L2 and this
is you know maybe appealing because it's
not much work to do but it's it's a lot
of work for the end users and for
developers building on these chains and
so this is not what we're doing uh
instead we're actually hard forking to
become an L2 Network at a certain block
height where um before that block height
the network will be progressing as an L1
and then after that block height the
network will change to a new client
that will then um run as an actual
L2 and you know we've learned over this
period where we've been building this
out that this is in fact quite difficult
um you know we like to say that this is
is actually more than just a hard Fork
it's actually a hard hard Fork two rocks
and a fork and it's hard you know for
all of the obvious reasons right like
you're um you know the metaphor of
rebuilding a plane while it's flying at
cruising altitude you know I think is
very apt you know we're literally moving
engines um back and forth um rebuilding
the plane while it's in the air and you
know the advantage of this is that in
the end only full nodes really need to
do any work around this migration only
they need to actually
upgrade and um participate in in this
transition your end users and developers
building on top of the chain they don't
have to do any work right all of this is
transparent for them really only the
full nodes have to do that work and
again the people who are running these
full nodes they're technical they have
experience with hard Forks this is not
something that's too complicated for
them they can handle
that so on to learning number two
learning number two is to use an
existing L2 stack you know we thought
early on hey why don't we build our own
L2 stack let's just upgrade our existing
client into a new L2 stack but we didn't
want to increase the number of L2 Stacks
that exist in ethereum there's already a
lot out there it's a lot of
fragmentation that this is causing and
we concluded that it's actually better
to just pick an existing stack and so we
ended up choosing op stack and igda for
data availability of course we'd
recommend that you uh do your own due
diligence and figure out which stack is
best for you um but certainly I think
picking an existing stack not
introducing more fragmentation I think
is the way to go
this of course means that you know we're
effectively switching clients at the
time of the uh upgrade so there'll be an
L1 client that's running today and an L2
client that will be running after the
hard fork and you know this again means
that there's a little bit more
complexity around this hard Fork right
full node operators will have to
actually shut down one client and start
a new client and this again adds to the
hardness of this hard Fork but again we
think it's we think it's worth
it there's
bit of additional complexity for archive
node operators because archive nodes of
course should be able to respond to
queries about all uh blocks and all data
from the whole history and so archive
node operators will actually have to run
two clients that are connected to each
other so that they can respond in unison
to RPC requests across all time
periods okay on to learning number
three this is related to the last one um
when you have a new client you run into
the situation where the new client has
to somehow be able to interpret the
chain data from the first client and you
can either modify the new client to be
able to do that or you can migrate your
chain data so that it it fits a format
that the new client can understand and
we think that this is the way to go and
so that's exactly what we're doing at
the point of the hard Fork we're going
to be running a chain data migration
script that repackages the data in a way
that's compatible with the new client
and this dramatically simplifies um a
lot of work the new client doesn't have
to um be Rewritten to understand the
chain data of the old
client okay learning number
four Embrace ethereum so after we
announced that we wanted to make this
migration um there were a few other L1
chains that also made similar
announcements but if you looked a little
closer it was clear that they were not
really embracing this idea of settling
on ethereum becoming a true L2 instead
they were talking about you know
canonical Bridges and things that looked
a little bit more like halfway towards
actually creating L2 and so our advice
for for these folks is you know just
take the leap of faith Embrace ethereum
um you know I think your communities are
going to be excited and and the ethereum
community has been really welcoming of
us and we don't think that you're going
to regret it related to this I think you
you might have some differences from
ethereum in your
protocol and and our advice here is to
really distill those differences down to
a patch Q on top of
gu okay the final learning learning
number five is to rethink where your
token lives um this was a big one for us
um you know as an L2 you have the choice
to actually have a token that lives on
ethereum in addition to the L2 and so
that's what we're going to be doing
we're going to be deploying a new token
on ethereum uh with the max Supply and
then we're going to put the entire
supply of that token into the native
Bridge uh so that it's there already in
escrow backing in effect all of the
tokens that exist on the L2 and so this
is a really interesting design we think
that um it's one that others should
should follow and we're really excited
about
it okay so final thoughts if you are
thinking about uh transitioning to an L2
um then our recommendation for you is
just do it you're not going to regret it
uh take the leap of faith um you know we
did and and we're thrilled about it we
highly recommend doing the same and if
you want to follow our progress um you
know we have one more test net that
we're going to be upgrading next month
and then at the beginning of next year
mid January we'll be hopefully upgrading
our main net if everything goes well
with that test net upgrade and so yeah U
mainnet is coming and we hope you'll uh
be excited for it thank you so much
thank you mik if you have questions for
mik please find him uh beside the stage
thank you a lot
thought thank you
so for this talk we have 10 minutes talk
and then five minutes Q&amp;A so open your
apps and be ready to ask your questions
um we have Peter who will talk about um
how smart contracts can read uh data
from layer one if they're on Layer Two
um he'll go into it in deeper thank you
and welcome
Peter
hello thanks a lot for coming I'm very
happy to see so many of you here tonight
I know it's been a long day and this is
the last two talks so thanks for staying
here so my name is Peter I'm a protocol
engineer at scroll and today I want to
tell you about a recent rollup
Improvement proposal that is called A1 s
load so let's start by talking about
what is A1 s
load essentially A1 s load is a
pre-compile that is deployed on l2s like
scroll and other l2s that you as a de
developer who deploys your dep on L2 can
use to read State directory from
L1 so if there's any solidity devs
around here this is how it looks so this
is the contract that you would Deploy on
L2 it's very simple you can just take
the L1 contract address you can provide
one two or up to five storage Keys you
encode it and then call this pre-compile
and then at the end you get the result
back that you can decode and use in your
application
logic uh what happens under the hood is
that the sequencer fetches this data for
you through adjacent RPC
request or it can even look uh as simple
as this if if you provide some higher
level uh libraries you you know just
call the i1s load uh read onsite intent
there you can use the data in your out2
contract
now today today at the venue I pass this
door and I like this kind of as a
metaphor uh so Alan esto is essentially
about keeping the door to storage open
to your L2
dep before we go into the implementation
uh let me highlight some use cases that
we've discovered because we've been
running this through some hackathons in
the last few months uh one of my
favorites is this cross layer tornado
cache imagine that you can deposit some
tokens into the shielded set on L1 and
then you can rraw on L2 uh very seamless
experience or imagine that you deploy
your D on an L2 that doesn't have enss
in this case you could just uh use i1s
Lo to directly look up uh names from the
i1
ens another example is defi so you could
create a defi dep where you can borrow
on L2 d by directly using collateral on
L1 without bridging this from L1 to
L2 and for account obstruction will lets
you might have heard about key stores
the idea is that you manage all your
keys on one chain let's say on i1 and
when you update your keys you add or
delete a key uh this update is
automatically propagated to all your
Wallets on all the
chains so this last example would look
like this uh in the L1 contract you
would most likely have some kind of a
mapping where you store the authorized
signers and on L2 it's very simple you
just calculate the story slot that
you're interested in and then you can
call aanas read bull the sequence answer
fet is the data for you and you can
decide in your L2 wallet whether this
signer is authorized or not so l1s load
makes this very easy to implement and
also very easy to use as a as a
developer uh now that you have a general
understanding of what is a slow and what
are some use cases let me talk about why
do I think we need to provide this in
the sequencer level and the way I think
about this is that this is a a service
that the sequencer provides to you
basically MPT proofs as a service uh
because this is all doable already
without relying on this pre-compile but
it's very complex as a developer first
of all relaying the state root
information from L1 to L2 in a
verifiable way is very complex and then
for any interaction on L2 providing this
MPT proof is costly and also complex to
develop so let's just do the sequencer
and the pro do the heavy lifting so that
you as the da developer can focus on the
cool application logic that you want to
develop
there have been some serious there have
been some alternative proposals to aan
asot in the past few years uh two that
we know of our L1 call and remote static
call and these are more powerful in a
way so from your al2 contract you can
directly call A View function on L1
basically execute a full evm uh function
but these are in our experience not very
friendly to zare La so uh the proving is
costly and also for instance Scrolls
execution environment for which we have
aover is like slightly different from L
one so if within that prover you would
need to implement another execution
environment for ethereum cuse and that
makes this very hard to develop on
zaps on the other hand aan asot has the
the issue that you know if you interact
with a contract and it's upgraded and
the storage slots change that might be a
challenge or that might be an issue so
this is something you need to consider
as a developer in that regard A1 call
would be more
powerful all right now let's let me show
you how this is implemented in in our
reference implementation in the
sequencer there are two prerequisites
before we jump into the implementation
the first prerequisite is what I call
trustless block has relay so the L2
Network scroll in this example needs to
have a notion of uh what is the latest
L1 block basically it needs to have a
view of the L1 chain including the state
rout because you need the state root to
to verify these proofs uh some rollups
already support this uh
the way it works in our system although
it's not launched on Main at yet is the
sequencer optimistically relays blocks
from L1 to L2 we verify that these
indeed form a chain of blocks and then
when we finalize this back on ethereum
uh we check that the sequencer relate
the correct data so if the sequencer
tries to cheat then it will be unable to
finalize this on El one so this is
doable but this is one of the
prerequisites the other prerequisite is
that any L2 node including nonsequential
nodes so follow nodes must connect to an
L1 node because as I mentioned this
precom by call is translated into an RPC
query So currently not all rollups
enforce this uh you might just follow
the unsafe chain from the peer-to-peer
layer from the sequencer but if you want
to support l1s load then all nodes need
to connect to an i1
node given these prerequisites it's
actually quite simple the execution part
of the promile is quite simple uh I
copied the example from our go ethereum
Fork so you would just need to extend
your evm implementation to add a new
pre-compile and what it does is first of
all it needs it needs to read the latest
layer one block that we know of in our
case this is stored in States but this
might be implemented in other ways then
it needs to parse the inputs that the
developer provided uh execute to batch
RPC call so even if you read five
storage slots the latency is the same
because we can batch these queries and
then resume execution and return control
to the evm
execution so that was the execution and
on the very verification side as I
mentioned we need to verify uh the block
hash relay so verify the al1 header
chain and verify that the sequencer
relate the correct information and then
as part of the proving process the
sequencer also fetches these MPT proofs
uh so that you as the developer don't
need to do that and insideover we need
to verify all these lay one MPT proofs
and make sure that these were all
correct now we have this rollup
Improvement proposal but this is still a
draft and there are still some open
questions and the main goal of this talk
is to involve more people so if you're a
developer who might be interested in
using this then we love to hear for you
hear from you see what you need uh and
if you are an L2 protocol maintainer you
know you're maintaining a sequencer note
then you're interested in adopting this
then we also love to hear from you to
share your
input so I want to highlight three open
questions uh one open question that we
received from devs actually is that like
do we want to allow L2 to read A1 State
at arbitrary height so not just the
latest A1 height but maybe older State
definitely for some applications this is
required but this also has some
drawbacks for instance if you allow
reading old States then the nodes must
connect to an archive L1 node and for
some L1 nodes like WTH I believe this is
not even possible because it cannot
serve historical uh G proof
request another question is how do you
deal with with RPC errors and latency
when you execute uh these calls to the
L1 SL load pre-compile latency is a big
question mark to me because if there's a
latency between the L2 node and the L1
node you know the RPC query that might
affect the throughput of the system that
might slow your system down so you need
to consider that when you price this
pre-compile and if you encounter an
error you need to decide do I retry or
do I drop this
transaction and finally defining the gas
cost is also tricky so in our proposal
we have a very simple pricing mechanism
basically a fixed cost per pre- compi
call and variable cost um or another
fixed cost per the number of slots that
you're querying but this is not all you
also have to pay for producing and
verifying these MPT proofs uh that is
probably you can do some benchmarking to
price that and what's kind of tricky is
to price this RPC latency like what is
the cost of doing this RPC query on the
sequencer as opposed to processing other
transactions
so we still have some way to go this rip
was proposed in June and uh it's now
gaining some traction we've been
exploring some use cases but the next
step would be to involve more uh add to
dep developers and L2 protocol teams so
as I mentioned we'd love to hear from
you uh just recently we set up a working
group telegram channel so if you're
interested in joining the discussion
feel free to join if you cannot join for
some reason then feel free to message me
on Twitter here and I add you and I
really hope that we get support from at
least one other L2 team and that we can
ship this feature on at least two l2s
maybe in
have some resources both uh the
reference implementation the E magicians
link and we also have some uh resources
for devs uh devet and some example codes
that you can use to get some
inspiration that's all I have for today
and I'm looking forward to your
questions thank you
thank you Peter we have a few questions
so first question is what happens when I
load a state from L1 but then L1
reorgs yeah that's a good question so
the question is uh when does the
sequencer relay this if the sequencer is
conservative and it waits for L1 to
finalize then this won't happen but then
the user experience is not very good
because the latency is uh 12 to 15
minutes if the sequencer uh relays it
earlier maybe after a couple of minutes
then us ASD L2 need to be reor aware so
you need to detect reorgs and you need
to reorg along uh with the one most
likely but I think this is the same
problem that l2s have with uh deposits
so any information that relate from L1
to L2 be it L1 s load or deposit
transactions have the same
issue okay NE next question is what is
the latency of data relay from ethereum
to L2
yeah so that's essentially it boils down
to the same question like if you want to
be conservative just wait for
finalization if not you need to reor
along with L1 um in reality it's not
terrible because I think L1 hasn't had a
reor deeper than seven slots or is
extremely unlikely so as long as you
have a mechanism to reorg if there's a
deeper reorg then this won't really be
triggered in most scenarios uh but
there's still the issue on L1 of the
inactivity leak what if L1 doesn't
finalize for a long time in this case
definitely uh being more aggressive and
not waiting for finalization would be
the way to go otherwise user experience
would
suffer okay next question is why is it
only limited to five
Keys yeah that's a good question do you
need more than five keys if yes then
please let us know five is was just an
arbitrary number we didn't want to make
it unbounded uh for most application use
case that we explored five or less was
enough but if you think it's not enough
then uh this is still draft so we can
still change
it okay uh which state or block does
this op code load form uh is it the
latest ethereum
block it is the latest ethereum block
that this L2 blockchain knows of so um
there needs to be on this L2 Network it
has multiple notes sequencer and follow
notes they need to have a consensus
about what is the latest L1 block that
they see otherwise uh execution to ca to
this pre compile would diverge but this
could be implemented in different ways I
mentioned this as uh one of the
prerequisites and I would say this is
not in the scope uh of this RP but it's
a prerequisite that could be implemented
in different ways for different
rollups okay uh what happens if there is
a small reorg for the specific L1 node
at the tip then the L2 sequencer would
process incorrect data to the L2 how
would execution continue on the
L2 yeah same question as before so you
would need to most likely reor along
one okay how do you configure switching
the RPC node on a live
sequencer how do you configure
switching well I mean you can get fancy
I mean the easiest solution is to just
compare connect to one node but
obviously that's not robust what if the
node is down so I ideally you would set
up multiple L1 RPC nodes U ideally
multiple types of L1 clients and then
have a load balancer and then you can
dynamically switch off and add nodes uh
that's robust for the sequencer and for
L2 nodes probably it's enough to just uh
run a sing Single I one
Noe okay um is this the same as the
previous questions or is this separate
question when I load L1 stage should I
specify L1 block number it's a different
question in theur current version of the
spec you cannot specify an L1 number in
a previous version you could so as I
mentioned this is one of the open
questions and I guess we need to learn
more for from developers to decide which
way to
go okay uh when we when will s L1 s load
be available on Main net soon I hope so
but this is not very useful if only one
rollup ships it so I hope at least two
rollups can ship it next year
somebody wants to know what is
Rip so RP stands for rollup Improvement
proposal this is similar to the EIP
process that is for L1 and we have a
less binding kind of collaborative
process for l2s that is called Rip oh
time's up um thank you and if anybody
has any more questions uh please find
him uh by the stage thank you thank
you for
so for this talk we will again have Q&amp;A
at the end so open your phones and get
your questions ready and now we have
Umar Roy and she will talk about full
vality proving on the op stack welcome
Uma
hello uh my name is Zuma I'm one of the
co-founders of succinct and today I'm
going to be telling you guys about uh
introducing full ZK validity proving
into the op
stack so let's start off with kind of
motivating the problem which is why are
ZK rollups interesting and important to
the ethereum
endgame so today the ethereum rollup
Centric road map is how ethereum is
going to scale and within that I think
it's common commonly acknowledged that
ZK Roll-Ups are the only way that a lot
of the problems we're facing today as an
ecosystem will get solved for example
we'll get fast finality we'll get
interoperability across all the rollups
uh unified liquidity for users and
overall it'll help improve ux
greatly inherently we can kind of think
of why ZK helps solve all these problems
because decentralization with all the
different ethereum nodes rerunning and
re-executing transactions inherently has
some overhead and ZK by giving us
verifiability fixes
this so ZK rollups have been around for
a long time historically we've known
that ZK has been very important but
until recently ZK rollups have been
really challenging uh you'd have to
write in specialized languages SDK and
dsls to actually encode an ethereum evm
State transition function in a ZK
circuit to be able to prove it and then
in general there were a lot of
compromises you had type one type two
type three uh where you can't use the
native ethereum storage format or
sometimes even be B code compatible due
to the limitations of
ZK so how are we solving this well it's
synct we're building a ZK VM not ZK evm
a ZK virtual machine where you can just
write rust and then use ZK so what does
that mean uh as a developer you can just
take arbitrary rust code behind the
scenes it gets compiled to risk 5 which
is say standard instruction set and then
we prove the execution of risk 5 code
and get out a ZK proof and sp1 is really
really fast and I'll talk about this a
bit later um and that's kind of one of
its big Innovations uh that enables the
future of ZK
rollups so if you use sp1 and you take
it in the context of ZK rollups let's
kind of examine the before and after
before sp1 it was very difficult to make
a ZK rollup right uh you had to have a
lot of specialized expertise A
specialized cryptography team now with
sp1 you can just write your evm state
transition function in normal code and
then get ZK proofs of that before sp1 to
actually make a ZK rollup it took a lot
of customization it was hard to maintain
add pre-compiled and customized it in
any way and then when the evm upgraded
you'd have to write all your custom
circuits and upgrade them to which was a
huge developer burden with sp1 I like to
joke it's as simple as cargo update ref
or cargo update revm and you get all the
latest changes uh to the
evm additionally with sp1 the security
surface area is a lot smaller because
you're able to reuse existing libraries
and components like WTH and Revan in the
rust ethereum ecosystem you get evm
compatibility by default so it's just
type one and then it's also pretty cheap
as I'll discuss in a little bit which is
also awesome so with sp1 uh and this
idea of a general purpose ZK VM that can
be used to execute rust code to write in
evm state transition function ZK rollups
are now pretty
awesome so that's kind of the high level
of Y SPN so great um and now let's
actually kind of go through building a
ZK rollup with
sp1 so step one is actually proving the
block execution of an ethereum block
using sp1 so how do we actually do this
behind the scenes will we take ref which
is a rust implementation of an ethereum
client and then you actually take a w
program you execute a block so you
verify all the signers of a transaction
you process those transactions um in
Rust code and then you use sp1 to gener
a ZK proof of that so in more detail
what does this mean first we get all
relevant Merkel proofs and storage slots
and accounts and state needed to execute
block then we construct an input with
all these relevant Witnesses so that
includes the entire state that we need
to execute the block and it requires all
Merkel proofs to actually check this
State against the parent block hash to
make sure it's
verified and then we actually execute
that block within a program that we run
within sp1 and that's actually a pretty
simple program because again we can just
use ref and uh execute the block itself
and then finally we generate the proof
and we actually did this using sp1 and
wrote all these programs that I'm
describing in the above steps and it was
around 1 thousand lines of code so it's
pretty simple kind of a weekend project
level thing of actually proving ethereum
block execution with sp1 and this is
something that used to take teams of
people years and years and now on medor
weekend project kind of illustrating in
practice why it's so
awesome uh one thing that people always
like to ask is you know how much does
this actually all cost it sounds so
simple um but is it actually practical
and the answer is yes so from
benchmarking on SP sp1 on a cloud prover
you can see that the costs are actually
in the range of T of Cent per
transaction and these are actually some
numbers that are kind of out older uh in
the more recent months we've improve
these numbers even further and so it's
actually very practical to prove
transactions in ethereum blocks using
sp1
today uh I also want to discuss why sp1
uh intuitively is so good at these types
of workloads so in normally executing an
ethereum block uh even on a normal
computer you spend a lot of time in
these cryptographic operations like
kjack and secp 256 K1 and sp1 has this
system where you can have custom
circuits for those operations
interconnected with a nor our normal
risk 5 CPU circuit and that really
accelerates the proving of those
computations by an order of magnitude we
also implemented an optimized GPU prover
and we have a bunch of other algorithmic
and cryptographic optimizations uh that
make sp1 very performant and kind of
give the costs that I had on the
previous
slide so the main takeaways from kind of
this exercise are that the costs are
really cheap cheap you know tents of a
cent to proove each transaction uh it's
easily customizable the lines of code is
really small it's upgradeable it kind of
satisfies all the awesome properties
we'd want of making a ZK
rollup so now I want to cover kind of
now that we've been able to prove the
execution of ethereum block and
transactions what's the next step of
fitting it into an actual
rollup and I kind of like to say that
executing an ethereum block and
generating a proof of that is one of the
easiest parts of making the rollup
there's actually a lot more steps
involved now thankfully we can take sp1
and we can insert it into an existing
open- Source rollup stack op stack to
make a full-fledged ZK rollup so what is
op stack at a high level it's a as I
mentioned this open source rollup stack
and it has a bunch of different
components um like a sequencer for
taking user transactions and posting it
to ather
a bridge contract optimism portal where
users deposit funds and withdraw funds
and finally it has this L2 output Oracle
that today um you have a proposer that
proposes the state route and then
there's a fault prooof game uh that we
know as the optimistic fall proof system
that kind of is responsible for making
sure that the posted State Route is
correct and that has the 7-Day
withdrawal window and all that other fun
stuff associated with optimistic fault
proofs now how we turn op stack into a
full ZK rollup is we just swap out one
simple component which is that L2 output
Oracle that has the state and instead of
having the fault proof game we just take
that component and now we verify a ZK
proof uh of the op stack rollup State
transition function uh using sp1 and
using our sp1 verifier on
chain and so the upgrade process is
actually really simple to take an
existing op stack rollup and turn it
into a full Z roll up uh we first
upgrade the contract to take in this
proof uh of the state route and then we
have our proposer basically generate
proofs um using sp1 uh behind an API
call and then posting those proofs to
that smart
contract and behind the scenes it's
actually a bit more complicated uh for
the sake of time I won't go super into
detail but actually for we generate
proofs of ranges of blocks at a time and
then once every hour we aggregate all
those proofs together to post to
ethereum and that's kind of the
architecture of how we actually do this
proof
generation so finally I want to talk
about what 1 hour of finality with ZK
validity actually
enables um I think the best thing is
that it enables users to feel
comfortable with actually putting money
into a chain and knowing in the worst
case scenario that they can withdraw
their money within an hour it's also
adds Capital efficiency because Bridges
don't have to rebalance and what's
really great also is that it helps more
rollups become stage one today and so I
think having one hour finality is very
very important uh for the future of ZK
rollups and my final slide is I want to
highlight that all of this is actually
practical today so we have this working
it's running it's integrated with a
bunch of rollup as a service providers
the costs are really cheap as I
mentioned
previously um and yeah we're excited to
kind of see uh the future of all rollups
on it there in BZ ZK rollups with the ZK
VM approach thank
you thank you um uh we have a bunch of
questions for you so let's start with
those um how does OPN verify that
witness matches data committed on
chain um so when we verified the proof
uh on chain uh some the thing that's
passed in as one of the public inputs to
the proof is the L1 block cash from the
L1 block hash op code and against that
L1 block has you can kind of open uh all
parent headers and you can also open
what blobs were posted to the chain and
you can walk back from that block block
hash you know arbitrarily and open all
the blobs that are relevant for deriving
what the L2 blocks
are uh what makes sp1 different from
risk zero
ZK yeah so there's a bunch of uh ZK VM
projects
um so risk zero also proves the
execution of the risk 5 Isa I would say
that what's most different about us
versus their approach is our pre-compile
where we can have specialized circuits
for certain operations like hash
functions like katak and uh signature
elliptic curve verif operations and
verification uh that make it
particularly fast for all these rollup
workloads um so I think our costs are
very very cheap on all these blockchain
workloads today um Z
I I don't know a lot about I think it
was actually only recently announced I
believe they're doing risk 5 but they're
doing the 64-bit variant whereas we do
the 32-bit variant um but I think
they're relatively newer and then
there's some other interesting projects
like jolt um which is developed by
andreon uh they don't use the hash based
schemes that we do um and then there's
another approach um or there's many
approaches some there's one I believe
called vol where they prove an Isa
that's not quite risk 5 but inspired by
risk 5 um
okay um so is op of syn production ready
what's missing before rollups like base
can become a ZK
rollup um yeah so obesa synct is
production ready we have a few test Nets
working today um and some chains that
are excited to take it to production
soon um what's missing before Bas can
become a ZK rollup well I think you know
the technology is still relatively new I
think ZK base only recently added ZK
fault uh sorry fault proofs in general
so um and many of the other op stack
chains still do not have fault proofs um
so it's just this is all like relatively
new tech even though P stack so it just
takes time to like adopt technology
especially when there's billions of
dollars locked in these
contracts okay uh given that sp1 proof
generation is slower than risk zeros why
should I choose
sp1 seems like there's a uh interested
party in the
audience um I think today sp1 is the
only ZK VM that can actually run these
op succinct rollups and we're actually
running them uh so I think the premise
of this question is just false and kind
of a troll question um so yeah you can
choose sp1 cuz it's like working today
with all these OB stack
rollups okay um can we use sp1 to prove
a small part of the execution Trace
instead of proving the whole block
Trace um yeah so you can prove any risk
five program with sp1 so you can prove
you know individual transactions at a
time you can prove parts of a block um
whatever you want you just have to
manually split up your sof and then
perhaps Stitch the proofs together later
okay let's squeeze one more question
there are five more in the line but we
don't have so much time is client side
proving possible with
sp1 um yeah you can run sp1 um on your
phone or on your web browser it'll just
be very very slow so it probably will
not be as fast as you want um but you
can do that today um and that's kind of
an active area that we're excited about
to work on over like the next few months
is make that experience better okay
that's it thank you Uma and if anybody
has questions feel free to ask her uh by
this side of the room and that's it for
today we are done this is this was the
last talk congrats to everybody who
stick with us for the whole day that's
amazing and enjoy the evening
two
two two
two two two
what's
thaten for
my light Sate
obing graphic
but don't fire
huh
oh son
OB
live
s desmon by
uh
session
uh double in
animation uh
pay uh
section MC
q&amp;
session P picture in picture
Q
cind
a okay me
okay for
